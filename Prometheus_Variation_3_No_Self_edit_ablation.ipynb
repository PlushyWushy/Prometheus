{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PlushyWushy/Prometheus/blob/main/Prometheus_Variation_3_No_Self_edit_ablation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5m-ikijRB5E",
        "outputId": "d51c9f2d-1486-4879-b6eb-99b72fbe3bf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: connect to drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVvNku1ioAcg",
        "outputId": "3729b97d-fbd8-4f4f-abeb-763b92703f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.7.9)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.1.2->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wfpE9m5oBDS",
        "outputId": "6f6985e0-812f-4140-96c1-4bd58b2dff71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enabling TensorFloat32 matmul precision for supported GPU.\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "#  ABLATION STUDY VERSION: SELF-EDITING DISABLED\n",
        "# ==============================================================================\n",
        "\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.distributions import Categorical\n",
        "from torch.amp import autocast\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import math\n",
        "import inspect # For debugging\n",
        "import logging\n",
        "import gc # Garbage Collector interface\n",
        "import itertools\n",
        "import traceback\n",
        "import os\n",
        "\n",
        "# Silence verbose logs from the compiler\n",
        "logging.getLogger(\"torch._dynamo\").setLevel(logging.FATAL)\n",
        "logging.getLogger(\"torch._inductor\").setLevel(logging.FATAL)\n",
        "\n",
        "try:\n",
        "    import torch_geometric.nn as pyg_nn\n",
        "    from torch_geometric.data import Data\n",
        "    from torch_geometric.utils import to_undirected\n",
        "    from torch_geometric.nn.dense.linear import Linear as PyGLinear\n",
        "    PYG_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PYG_AVAILABLE = False\n",
        "    print(\"PyTorch Geometric not found. GNN MetaAgent will not be available if used.\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Constants & Configuration\n",
        "# =======================================================================\n",
        "PRE_EPOCHS=1; BATCHES_PER_EPOCH=None; BATCH_SIZE=128\n",
        "BASE_POST_EPOCHS = 25\n",
        "LEARNING_RATE=0.001; MAX_GRAD_NORM=5.0\n",
        "DEVICE=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if DEVICE.type == 'cuda':\n",
        "    if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8:\n",
        "        print(\"Enabling TensorFloat32 matmul precision for supported GPU.\")\n",
        "        torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# --- Action Space with Skip Connections ---\n",
        "EDIT_TYPE_ADD_CONV_BLOCK=0; EDIT_TYPE_RESIZE_LAYER=1; EDIT_TYPE_ADD_SKIP=2; EDIT_TYPE_ADD_LINEAR_BLOCK=3\n",
        "NUM_TARGET_CNN_EDIT_TYPES=4\n",
        "DISCRETE_CH_MULT_ADD=[0.5,1.0,2.0];\n",
        "DISCRETE_RESIZE_FACTORS = [0.25, 0.5, 0.75, 1.25, 1.5, 1.75]\n",
        "NUM_STAGES_TARGET_CNN=3\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "# --- MetaAgent & RL Configuration ---\n",
        "BASE_META_LR = 5e-4\n",
        "MIN_META_LR = 1e-5\n",
        "LR_ACC_BASE_THRESHOLD = 0.80\n",
        "LR_ACC_TARGET_THRESHOLD = 0.93\n",
        "\n",
        "# --- Actions for complexity reduction ---\n",
        "META_EDIT_NONE = 0\n",
        "META_EDIT_DEEPEN_GNN = 1\n",
        "META_EDIT_WIDEN_GNN_HIDDEN = 2\n",
        "META_EDIT_DEEPEN_MLP_HEAD = 3\n",
        "META_EDIT_SHRINK_GNN_HIDDEN = 4\n",
        "META_EDIT_PRUNE_GNN = 5\n",
        "META_EDIT_PRUNE_MLP_HEAD = 6\n",
        "NUM_META_SELF_EDIT_TYPES = 7\n",
        "META_SELF_EDIT_INTERVAL = 5\n",
        "\n",
        "# --- Factors and min/max constraints for two-way search ---\n",
        "META_GNN_WIDEN_FACTOR = 1.5\n",
        "META_GNN_SHRINK_FACTOR = 1.0 / META_GNN_WIDEN_FACTOR # Symmetric shrinking\n",
        "MIN_GNN_LAYERS = 1\n",
        "MIN_GNN_HIDDEN_DIM = 16\n",
        "MIN_MLP_HEAD_SEQUENTIAL_DEPTH = 1\n",
        "INITIAL_GNN_HIDDEN_DIM = 32; INITIAL_NUM_GNN_LAYERS = 2\n",
        "EDIT_TYPE_EMBED_DIM = 16\n",
        "META_AGENT_PRUNE_THRESHOLD = 15000\n",
        "\n",
        "# --- Complexity Penalty Configuration ---\n",
        "COMPLEXITY_PENALTY_THRESHOLD = 20_000_000\n",
        "COMPLEXITY_PENALTY_ALPHA = 0.2\n",
        "\n",
        "# --- Graph & State Representation ---\n",
        "OP_TYPE_IDS = {'conv2d':1,'relu':2,'maxpool2d':3, 'batchnorm2d': 4, 'batchnorm1d': 7, 'add': 8, 'input_placeholder':5, 'linear': 6, 'dropout': 9, 'none':0}\n",
        "NODE_FEATURE_DIM = 7\n",
        "NORMALIZATION_WIDTH_DIVISOR = 512.0; NORMALIZATION_IDX_DIVISOR = 50.0; NORMALIZATION_SPATIAL_DIVISOR = 32.0\n",
        "GLOBAL_SUMMARY_FEATURE_DIM = 3 + 2\n",
        "MAX_GLOBAL_HISTORY_LEN = 5\n",
        "\n",
        "# =======================================================================\n",
        "#  Custom Modules for Dynamic Graph\n",
        "# =======================================================================\n",
        "class AddWithProjection(nn.Module):\n",
        "    def __init__(self, projection_module=None):\n",
        "        super().__init__()\n",
        "        self.projection = projection_module if projection_module is not None else nn.Identity()\n",
        "    def forward(self, x_primary, x_skip):\n",
        "        x_skip_projected = self.projection(x_skip)\n",
        "        if x_primary.shape[2:] != x_skip_projected.shape[2:]:\n",
        "            x_skip_projected = F.interpolate(x_skip_projected, size=x_primary.shape[2:], mode='bilinear', align_corners=False)\n",
        "        return x_primary + x_skip_projected\n",
        "\n",
        "# =======================================================================\n",
        "#  Net2Net Utilities & Masking Helpers\n",
        "# =======================================================================\n",
        "def _valid_resize_indices(old_oc: int):\n",
        "    valid = []\n",
        "    for idx, f_resize in enumerate(DISCRETE_RESIZE_FACTORS):\n",
        "        new_oc_resize = max(1, int(round(old_oc * f_resize)))\n",
        "        if new_oc_resize != old_oc: valid.append(idx)\n",
        "    if not valid and old_oc > 0 :\n",
        "        try: valid.append(DISCRETE_RESIZE_FACTORS.index(1.0))\n",
        "        except ValueError: pass\n",
        "    if not valid: valid.append(0)\n",
        "    return valid\n",
        "def _mask_logits(logits: torch.Tensor, valid_indices: list):\n",
        "    mask_val = torch.full_like(logits, float('-inf'))\n",
        "    if valid_indices:\n",
        "        valid_indices_tensor = torch.tensor(valid_indices, device=logits.device, dtype=torch.long)\n",
        "        if valid_indices_tensor.numel() > 0:\n",
        "            valid_indices_tensor = valid_indices_tensor[valid_indices_tensor < logits.shape[-1]]\n",
        "            if valid_indices_tensor.numel() > 0:\n",
        "                 mask_val[..., valid_indices_tensor] = 0.0\n",
        "    return logits + mask_val\n",
        "\n",
        "def _invalid_meta_indices(agent):\n",
        "    invalid = []\n",
        "\n",
        "    agent_params = sum(p.numel() for p in agent.parameters())\n",
        "    if agent_params < META_AGENT_PRUNE_THRESHOLD:\n",
        "        invalid.extend([META_EDIT_SHRINK_GNN_HIDDEN, META_EDIT_PRUNE_GNN, META_EDIT_PRUNE_MLP_HEAD])\n",
        "\n",
        "    if agent.current_num_gnn_layers <= MIN_GNN_LAYERS:\n",
        "        invalid.append(META_EDIT_PRUNE_GNN)\n",
        "    if agent.current_gnn_hidden_dim <= MIN_GNN_HIDDEN_DIM:\n",
        "        invalid.append(META_EDIT_SHRINK_GNN_HIDDEN)\n",
        "\n",
        "    eligible_heads = agent.get_mlp_head_names()\n",
        "    all_heads_at_min_depth = all(agent.head_depth_counters.get(name, 1) <= MIN_MLP_HEAD_SEQUENTIAL_DEPTH for name in eligible_heads)\n",
        "    if all_heads_at_min_depth:\n",
        "        invalid.append(META_EDIT_PRUNE_MLP_HEAD)\n",
        "\n",
        "    all_heads_at_max_depth = all(agent.head_depth_counters.get(name, 1) >= 8 for name in eligible_heads)\n",
        "    if all_heads_at_max_depth:\n",
        "        invalid.append(META_EDIT_DEEPEN_MLP_HEAD)\n",
        "\n",
        "    return list(set(invalid))\n",
        "\n",
        "def net2wider_conv_output(conv: nn.Conv2d, factor: float, device='cpu') -> nn.Conv2d:\n",
        "    old_oc = conv.out_channels; new_oc = max(1, int(round(old_oc * factor)))\n",
        "    if new_oc == old_oc : return conv\n",
        "    new_conv_module = nn.Conv2d(conv.in_channels, new_oc, conv.kernel_size, stride=conv.stride, padding=conv.padding, groups=conv.groups, bias=(conv.bias is not None)).to(device)\n",
        "    with torch.no_grad():\n",
        "        new_conv_module.weight.data.fill_(0); min_oc = min(old_oc, new_oc)\n",
        "        if old_oc > 0:\n",
        "            new_conv_module.weight.data[:min_oc] = conv.weight.data[:min_oc].clone()\n",
        "            if new_oc > old_oc:\n",
        "                r_widen = float(new_oc) / old_oc\n",
        "                for i in range(old_oc, new_oc):\n",
        "                    new_conv_module.weight.data[i] = conv.weight.data[i % old_oc].clone() / math.sqrt(r_widen)\n",
        "        if conv.bias is not None and new_conv_module.bias is not None:\n",
        "            new_conv_module.bias.data.fill_(0)\n",
        "            if old_oc > 0:\n",
        "                new_conv_module.bias.data[:min_oc] = conv.bias.data[:min_oc].clone()\n",
        "                if new_oc > old_oc:\n",
        "                    for i in range(old_oc, new_oc): new_conv_module.bias.data[i] = conv.bias.data[i % old_oc].clone()\n",
        "            elif new_oc > 0: nn.init.zeros_(new_conv_module.bias.data)\n",
        "        elif new_conv_module.bias is not None: nn.init.zeros_(new_conv_module.bias.data)\n",
        "    return new_conv_module\n",
        "def net2thinner_conv_output(conv: nn.Conv2d, factor: float, device='cpu') -> nn.Conv2d:\n",
        "    old_oc = conv.out_channels; new_oc = max(1, int(round(old_oc * factor)))\n",
        "    if new_oc == old_oc: return conv\n",
        "    new_conv_module = nn.Conv2d(conv.in_channels, new_oc, conv.kernel_size, stride=conv.stride, padding=conv.padding, groups=conv.groups, bias=(conv.bias is not None)).to(device)\n",
        "    with torch.no_grad():\n",
        "        if old_oc > 0 :\n",
        "            new_conv_module.weight.data = conv.weight.data[:new_oc].clone()\n",
        "            if conv.bias is not None and new_conv_module.bias is not None:\n",
        "                 new_conv_module.bias.data = conv.bias.data[:new_oc].clone()\n",
        "            elif new_conv_module.bias is not None: nn.init.zeros_(new_conv_module.bias.data)\n",
        "    return new_conv_module\n",
        "def resize_conv_output(conv: nn.Conv2d, factor: float, device='cpu') -> nn.Conv2d:\n",
        "    if abs(factor - 1.0) < 1e-6 : return conv\n",
        "    old_oc = conv.out_channels; new_oc = max(1, int(round(old_oc * factor)))\n",
        "    if new_oc == old_oc and old_oc > 0: return conv\n",
        "    if new_oc == old_oc and old_oc == 0 and factor != 1.0 : pass\n",
        "    elif new_oc == old_oc: return conv\n",
        "    if new_oc > old_oc: return net2wider_conv_output(conv, float(new_oc)/old_oc if old_oc > 0 else factor, device)\n",
        "    else: return net2thinner_conv_output(conv, float(new_oc)/old_oc if old_oc > 0 else factor, device)\n",
        "def resize_linear_output(linear: nn.Linear, factor: float, device='cpu') -> nn.Linear:\n",
        "    if abs(factor - 1.0) < 1e-6: return linear\n",
        "    old_of = linear.out_features; new_of = max(1, int(round(old_of * factor)))\n",
        "    if new_of == old_of: return linear\n",
        "    new_linear = nn.Linear(linear.in_features, new_of, bias=(linear.bias is not None)).to(device)\n",
        "    with torch.no_grad():\n",
        "        min_of = min(old_of, new_of)\n",
        "        if old_of > 0:\n",
        "            r_widen = float(new_of) / old_of\n",
        "            new_linear.weight.data[:min_of] = linear.weight.data[:min_of].clone()\n",
        "            if new_of > old_of:\n",
        "                for i in range(old_of, new_of):\n",
        "                    new_linear.weight.data[i] = linear.weight.data[i % old_of].clone() / math.sqrt(r_widen)\n",
        "            if linear.bias is not None:\n",
        "                new_linear.bias.data[:min_of] = linear.bias.data[:min_of].clone()\n",
        "                if new_of > old_of:\n",
        "                    for i in range(old_of, new_of):\n",
        "                        new_linear.bias.data[i] = linear.bias.data[i % old_of].clone()\n",
        "    return new_linear\n",
        "def adapt_conv_input_channels(conv: nn.Conv2d, new_in_channels: int, device='cpu') -> nn.Conv2d:\n",
        "    if conv.in_channels == new_in_channels: return conv\n",
        "    new_in_channels = max(1, new_in_channels); old_ic = conv.in_channels\n",
        "    if conv.groups > 1:\n",
        "        if new_in_channels % conv.groups != 0:\n",
        "            print(f\"  INVALID ADAPTATION: Cannot adapt grouped Conv2d to new_in_channels={new_in_channels} with groups={conv.groups}. The edit is invalid.\")\n",
        "            return None\n",
        "    new_conv_module = nn.Conv2d(new_in_channels, conv.out_channels, conv.kernel_size, stride=conv.stride, padding=conv.padding, groups=conv.groups, bias=(conv.bias is not None)).to(device)\n",
        "    with torch.no_grad():\n",
        "        if old_ic == 0: nn.init.kaiming_normal_(new_conv_module.weight, mode='fan_in', nonlinearity='relu')\n",
        "        else:\n",
        "            w_new_conv_adapt = torch.zeros_like(new_conv_module.weight.data)\n",
        "            oc_per_group = conv.out_channels // conv.groups; new_ic_per_group = new_in_channels // conv.groups; old_ic_per_group = old_ic // conv.groups\n",
        "            for g in range(conv.groups):\n",
        "                in_start_new, in_end_new = g * new_ic_per_group, (g + 1) * new_ic_per_group\n",
        "                in_start_old, in_end_old = g * old_ic_per_group, (g + 1) * old_ic_per_group\n",
        "                out_start, out_end = g * oc_per_group, (g + 1) * oc_per_group\n",
        "                for o_idx in range(out_start, out_end):\n",
        "                    for i_idx in range(in_start_new, in_end_new):\n",
        "                        if i_idx < in_end_old: w_new_conv_adapt[o_idx, i_idx].copy_(conv.weight.data[o_idx, i_idx])\n",
        "                        else:\n",
        "                            orig_i_idx = in_start_old + (i_idx - in_start_new) % old_ic_per_group\n",
        "                            w_new_conv_adapt[o_idx, i_idx].copy_(conv.weight.data[o_idx, orig_i_idx])\n",
        "                            w_new_conv_adapt[o_idx, i_idx] /= max(1.0, new_ic_per_group / old_ic_per_group)\n",
        "            new_conv_module.weight.data.copy_(w_new_conv_adapt)\n",
        "        if conv.bias is not None and new_conv_module.bias is not None: new_conv_module.bias.data.copy_(conv.bias.data)\n",
        "        elif new_conv_module.bias is not None: nn.init.zeros_(new_conv_module.bias.data)\n",
        "    return new_conv_module\n",
        "def adapt_linear_input_features(linear: nn.Linear, new_in_features: int, device='cpu') -> nn.Linear:\n",
        "    if linear.in_features == new_in_features: return linear\n",
        "    new_in_features = max(1, new_in_features); old_if = linear.in_features\n",
        "    new_linear = nn.Linear(new_in_features, linear.out_features, bias=(linear.bias is not None)).to(device)\n",
        "    with torch.no_grad():\n",
        "        if old_if == 0: nn.init.kaiming_uniform_(new_linear.weight, a=math.sqrt(5))\n",
        "        else:\n",
        "            min_if = min(old_if, new_in_features)\n",
        "            new_linear.weight.data[:, :min_if] = linear.weight.data[:, :min_if].clone()\n",
        "            if new_in_features > old_if:\n",
        "                for i in range(old_if, new_in_features):\n",
        "                    new_linear.weight.data[:, i] = linear.weight.data[:, i % old_if].clone()\n",
        "                    new_linear.weight.data[:, i] /= max(1.0, new_in_features / old_if)\n",
        "        if linear.bias is not None: new_linear.bias.data.copy_(linear.bias.data)\n",
        "    return new_linear\n",
        "def adapt_batchnorm_features(bn: nn.Module, new_num_features: int, device='cpu') -> nn.Module:\n",
        "    if bn.num_features == new_num_features: return bn\n",
        "    new_bn = type(bn)(new_num_features).to(device)\n",
        "    with torch.no_grad():\n",
        "        min_feat = min(bn.num_features, new_num_features)\n",
        "        if bn.weight is not None:\n",
        "            new_bn.weight.data[:min_feat] = bn.weight.data[:min_feat].clone()\n",
        "            if new_num_features > bn.num_features:\n",
        "                new_bn.weight.data[bn.num_features:] = bn.weight.data[-1].clone() # Replicate last\n",
        "        if bn.bias is not None:\n",
        "            new_bn.bias.data[:min_feat] = bn.bias.data[:min_feat].clone()\n",
        "            if new_num_features > bn.num_features:\n",
        "                new_bn.bias.data[bn.num_features:] = bn.bias.data[-1].clone()\n",
        "        if bn.running_mean is not None:\n",
        "            new_bn.running_mean[:min_feat] = bn.running_mean[:min_feat].clone()\n",
        "            if new_num_features > bn.num_features:\n",
        "                new_bn.running_mean[bn.num_features:] = bn.running_mean[-1].clone()\n",
        "        if bn.running_var is not None:\n",
        "            new_bn.running_var[:min_feat] = bn.running_var[:min_feat].clone()\n",
        "            if new_num_features > bn.num_features:\n",
        "                new_bn.running_var[bn.num_features:] = bn.running_var[-1].clone()\n",
        "    return new_bn\n",
        "def net2deeper_linear_insert_identity(head_module_owner: nn.Module, head_name: str, device='cpu'):\n",
        "    if not hasattr(head_module_owner, head_name): print(f\"Err: Attr {head_name} not found for deepening\"); return False\n",
        "    original_component = getattr(head_module_owner, head_name)\n",
        "    if isinstance(original_component, nn.Linear):\n",
        "        identity_dim = original_component.out_features\n",
        "        if identity_dim <= 0: print(f\"Cannot insert identity for dim {identity_dim} in Linear head {head_name}\"); return False\n",
        "        identity_layer = nn.Linear(identity_dim, identity_dim, bias=True).to(device)\n",
        "        with torch.no_grad(): identity_layer.weight.data.copy_(torch.eye(identity_dim,device=device)); identity_layer.bias.data.fill_(0)\n",
        "        setattr(head_module_owner,head_name,nn.Sequential(original_component,identity_layer).to(device)); print(f\"  Deepened MLP head '{head_name}' (Linear -> Sequential)\")\n",
        "        return True\n",
        "    elif isinstance(original_component, nn.Sequential):\n",
        "        if not original_component or not isinstance(original_component[-1],nn.Linear): print(f\"Cannot deepen Seq head '{head_name}', last not Linear.\"); return False\n",
        "        identity_dim = original_component[-1].in_features\n",
        "        if identity_dim <= 0: print(f\"Cannot insert identity for dim {identity_dim} in Seq head {head_name}\"); return False\n",
        "        identity_layer = nn.Linear(identity_dim, identity_dim, bias=True).to(device)\n",
        "        with torch.no_grad(): identity_layer.weight.data.copy_(torch.eye(identity_dim,device=device)); identity_layer.bias.data.fill_(0)\n",
        "        new_seq_layers = nn.ModuleList([l for l in original_component[:-1]] + [identity_layer, original_component[-1]])\n",
        "        setattr(head_module_owner,head_name,nn.Sequential(*new_seq_layers).to(device)); print(f\"  Deepened Seq head '{head_name}'.\")\n",
        "        return True\n",
        "    print(f\"Err: Head '{head_name}' type {type(original_component)} not Linear/Seq for deepening.\");\n",
        "    return False\n",
        "\n",
        "def net2thinner_linear_remove_layer(head_module_owner: nn.Module, head_name: str, device='cpu'):\n",
        "    if not hasattr(head_module_owner, head_name): print(f\"Err: Attr {head_name} not found for pruning\"); return False\n",
        "    original_component = getattr(head_module_owner, head_name)\n",
        "    if not isinstance(original_component, nn.Sequential) or len(original_component) <= 2:\n",
        "        print(f\"Cannot prune head '{head_name}': not a Sequential module with more than 2 layers.\"); return False\n",
        "\n",
        "    pruned_layers = nn.ModuleList([l for l in original_component[:-2]] + [original_component[-1]])\n",
        "\n",
        "    if len(pruned_layers) == 1:\n",
        "        setattr(head_module_owner, head_name, pruned_layers[0].to(device))\n",
        "        print(f\"  Pruned MLP head '{head_name}' (Sequential -> Linear)\")\n",
        "    else:\n",
        "        setattr(head_module_owner, head_name, nn.Sequential(*pruned_layers).to(device))\n",
        "        print(f\"  Pruned MLP head '{head_name}'.\")\n",
        "    return True\n",
        "\n",
        "def _get_gcn_conv_linear_submodule(gcn_layer):\n",
        "    if hasattr(gcn_layer, 'lin') and (isinstance(gcn_layer.lin, nn.Linear) or (PYG_AVAILABLE and isinstance(gcn_layer.lin, PyGLinear))):\n",
        "        return gcn_layer.lin\n",
        "    return None\n",
        "if PYG_AVAILABLE:\n",
        "    def resize_gcn_conv_hidden(gcn_layer: pyg_nn.GCNConv, new_hidden_dim: int, prev_layer_out_dim: int, device='cpu'):\n",
        "        old_hidden_dim = gcn_layer.out_channels\n",
        "        if new_hidden_dim == old_hidden_dim: return gcn_layer, False\n",
        "        new_gcn = pyg_nn.GCNConv(prev_layer_out_dim,new_hidden_dim,bias=(gcn_layer.bias is not None), improved=gcn_layer.improved,add_self_loops=gcn_layer.add_self_loops, normalize=gcn_layer.normalize).to(device)\n",
        "        with torch.no_grad():\n",
        "            gcn_lin_original = _get_gcn_conv_linear_submodule(gcn_layer)\n",
        "            gcn_lin_new = _get_gcn_conv_linear_submodule(new_gcn)\n",
        "            if gcn_lin_original is None or gcn_lin_new is None: return new_gcn, True\n",
        "            orig_lin_w = gcn_lin_original.weight.data; new_lin_w_target = gcn_lin_new.weight.data\n",
        "            min_out = min(old_hidden_dim,new_hidden_dim); new_lin_w_fill = torch.zeros_like(new_lin_w_target)\n",
        "            new_lin_w_fill[:min_out,:] = orig_lin_w[:min_out,:].clone()\n",
        "            if new_hidden_dim > old_hidden_dim and old_hidden_dim > 0:\n",
        "                for r_idx in range(old_hidden_dim, new_hidden_dim): new_lin_w_fill[r_idx,:]=orig_lin_w[r_idx%old_hidden_dim,:].clone()\n",
        "            new_lin_w_target.copy_(new_lin_w_fill)\n",
        "            if gcn_layer.bias is not None and new_gcn.bias is not None:\n",
        "                orig_gcn_b = gcn_layer.bias.data; new_gcn_b_target = new_gcn.bias.data\n",
        "                new_gcn_b_fill = torch.zeros_like(new_gcn_b_target)\n",
        "                new_gcn_b_fill[:min_out] = orig_gcn_b[:min_out].clone()\n",
        "                if new_hidden_dim > old_hidden_dim and old_hidden_dim > 0:\n",
        "                    for r_idx_bias in range(old_hidden_dim, new_hidden_dim): new_gcn_b_fill[r_idx_bias]=orig_gcn_b[r_idx_bias%old_hidden_dim].clone()\n",
        "                new_gcn_b_target.copy_(new_gcn_b_fill)\n",
        "            elif new_gcn.bias is not None : nn.init.zeros_(new_gcn.bias.data)\n",
        "        return new_gcn,True\n",
        "    def adapt_gcn_conv_input_dim(gcn_layer: pyg_nn.GCNConv, new_input_dim: int, device='cpu'):\n",
        "        old_input_dim = gcn_layer.in_channels\n",
        "        if new_input_dim == old_input_dim: return gcn_layer, False\n",
        "        new_gcn = pyg_nn.GCNConv(new_input_dim,gcn_layer.out_channels,bias=(gcn_layer.bias is not None), improved=gcn_layer.improved,add_self_loops=gcn_layer.add_self_loops,normalize=gcn_layer.normalize).to(device)\n",
        "        with torch.no_grad():\n",
        "            gcn_lin_original_adapt = _get_gcn_conv_linear_submodule(gcn_layer)\n",
        "            gcn_lin_new_adapt = _get_gcn_conv_linear_submodule(new_gcn)\n",
        "            if gcn_lin_original_adapt is None or gcn_lin_new_adapt is None: return new_gcn,True\n",
        "            orig_lin_w_adapt = gcn_lin_original_adapt.weight.data; new_lin_w_target_adapt = gcn_lin_new_adapt.weight.data\n",
        "            min_in_adapt = min(old_input_dim,new_input_dim); new_lin_w_fill_adapt = torch.zeros_like(new_lin_w_target_adapt)\n",
        "            if old_input_dim>0:\n",
        "                new_lin_w_fill_adapt[:,:min_in_adapt] = orig_lin_w_adapt[:,:min_in_adapt].clone()\n",
        "                if new_input_dim > old_input_dim:\n",
        "                    for c_adapt in range(old_input_dim,new_input_dim):\n",
        "                        new_lin_w_fill_adapt[:,c_adapt]=orig_lin_w_adapt[:,c_adapt%old_input_dim].clone()\n",
        "                        new_lin_w_fill_adapt[:,c_adapt]/=max(1.0,(new_input_dim/old_input_dim))\n",
        "                new_lin_w_target_adapt.copy_(new_lin_w_fill_adapt)\n",
        "            if gcn_layer.bias is not None and new_gcn.bias is not None: new_gcn.bias.data.copy_(gcn_layer.bias.data)\n",
        "            elif new_gcn.bias is not None: nn.init.zeros_(new_gcn.bias.data)\n",
        "        return new_gcn, True\n",
        "    def create_identity_gcn_layer(dim: int, device='cpu', **gcn_kwargs):\n",
        "        identity_gcn = pyg_nn.GCNConv(dim,dim,bias=gcn_kwargs.get('bias',True), normalize=gcn_kwargs.get('normalize',True), add_self_loops=gcn_kwargs.get('add_self_loops',True), improved=gcn_kwargs.get('improved',False)).to(device)\n",
        "        with torch.no_grad():\n",
        "            gcn_lin_identity = _get_gcn_conv_linear_submodule(identity_gcn)\n",
        "            if gcn_lin_identity is not None:\n",
        "                if gcn_lin_identity.weight.shape[0] == gcn_lin_identity.weight.shape[1]: gcn_lin_identity.weight.data.copy_(torch.eye(dim,device=device))\n",
        "                else: nn.init.kaiming_uniform_(gcn_lin_identity.weight, a=math.sqrt(5))\n",
        "                if hasattr(gcn_lin_identity, 'bias') and gcn_lin_identity.bias is not None: gcn_lin_identity.bias.data.fill_(0.0)\n",
        "            if identity_gcn.bias is not None: identity_gcn.bias.data.fill_(0.0)\n",
        "        return identity_gcn\n",
        "\n",
        "# =======================================================================\n",
        "#  Dynamic Models (TargetCNN)\n",
        "# =======================================================================\n",
        "class DynamicStageModule(nn.Module):\n",
        "    def __init__(self, stage_idx_dyn, initial_in_channels_dyn, initial_spatial_size_dyn, max_ops_dyn=None):\n",
        "        super().__init__()\n",
        "        self.stage_idx = stage_idx_dyn\n",
        "        self.initial_in_channels = initial_in_channels_dyn\n",
        "        self.initial_spatial_size = initial_spatial_size_dyn\n",
        "        self.max_ops = max_ops_dyn\n",
        "        self.ops = nn.ModuleList()\n",
        "        self.op_descriptions = []\n",
        "        self.dropout = nn.Dropout(p=DROPOUT_RATE)\n",
        "\n",
        "    def add_op(self, op_module_dyn, op_description_dyn, insert_at=None):\n",
        "        if self.max_ops is not None and len(self.ops) >= self.max_ops:\n",
        "            return False\n",
        "        if insert_at is None:\n",
        "            self.ops.append(op_module_dyn)\n",
        "            self.op_descriptions.append(op_description_dyn)\n",
        "        else:\n",
        "            self.ops.insert(insert_at, op_module_dyn)\n",
        "            self.op_descriptions.insert(insert_at, op_description_dyn)\n",
        "        return True\n",
        "\n",
        "    def get_op_output_properties(self, op_idx):\n",
        "        if op_idx == -1:\n",
        "            return self.initial_in_channels, self.initial_spatial_size\n",
        "        if 0 <= op_idx < len(self.op_descriptions):\n",
        "            desc = self.op_descriptions[op_idx]\n",
        "            return desc.get('out_channels', 0), desc.get('out_spatial', 0)\n",
        "        raise IndexError(f\"Operator index {op_idx} out of range for stage {self.stage_idx} with {len(self.ops)} ops.\")\n",
        "\n",
        "    def get_current_out_properties(self):\n",
        "        if not self.op_descriptions:\n",
        "            return self.initial_in_channels, self.initial_spatial_size\n",
        "        return self.get_op_output_properties(len(self.ops) - 1)\n",
        "\n",
        "    def forward(self, x_dyn):\n",
        "        outputs_history_dyn = {-1: x_dyn}\n",
        "        is_first_conv_in_model = (self.stage_idx == 0)\n",
        "\n",
        "        for i_dyn, op_desc_item_dyn in enumerate(self.op_descriptions):\n",
        "            op_module_fwd_dyn = self.ops[i_dyn]\n",
        "            input_indices_dyn = op_desc_item_dyn.get('input_indices', [-1])\n",
        "            if not isinstance(input_indices_dyn, list): input_indices_dyn = [input_indices_dyn]\n",
        "\n",
        "            current_op_inputs_dyn = []\n",
        "            for source_op_local_idx_dyn in input_indices_dyn:\n",
        "                if not (-1 <= source_op_local_idx_dyn < i_dyn):\n",
        "                     source_op_local_idx_dyn = (i_dyn - 1) if i_dyn > 0 else -1\n",
        "\n",
        "                if source_op_local_idx_dyn in outputs_history_dyn:\n",
        "                    current_op_inputs_dyn.append(outputs_history_dyn[source_op_local_idx_dyn])\n",
        "                else:\n",
        "                    default_input_key_dyn = (i_dyn-1) if i_dyn > 0 else -1\n",
        "                    current_op_inputs_dyn.append(outputs_history_dyn.get(default_input_key_dyn, x_dyn))\n",
        "            try:\n",
        "                if not current_op_inputs_dyn: op_output_dyn = op_module_fwd_dyn(x_dyn)\n",
        "                elif len(current_op_inputs_dyn) == 1: op_output_dyn = op_module_fwd_dyn(current_op_inputs_dyn[0])\n",
        "                else: op_output_dyn = op_module_fwd_dyn(*current_op_inputs_dyn)\n",
        "            except Exception as e_dyn_fwd:\n",
        "                print(f\"CRITICAL Error in DynamicStageModule op {i_dyn}, type {op_desc_item_dyn.get('type','Unknown')}, stage {self.stage_idx}: {e_dyn_fwd}\"); raise e_dyn_fwd\n",
        "\n",
        "            if self.training and False: # Dropout disabled as per feedback\n",
        "                if i_dyn > 1 and 'batchnorm' in self.op_descriptions[i_dyn-1]['type'] and 'conv2d' in self.op_descriptions[i_dyn-2]['type']:\n",
        "                    if not is_first_conv_in_model:\n",
        "                        op_output_dyn = self.dropout(op_output_dyn)\n",
        "                    is_first_conv_in_model = False\n",
        "\n",
        "            outputs_history_dyn[i_dyn] = op_output_dyn\n",
        "        return outputs_history_dyn[len(self.ops)-1] if self.ops else x_dyn\n",
        "\n",
        "class TargetCNN(nn.Module):\n",
        "    def __init__(self, num_classes_cnn=10, num_stages_cnn=NUM_STAGES_TARGET_CNN, init_model_ch_cnn=64, input_spatial_size=32):\n",
        "        super().__init__()\n",
        "        self.num_stages = num_stages_cnn\n",
        "        self.stages = nn.ModuleList()\n",
        "        current_channels_cnn = 3 # CIFAR-10 is RGB (3 channels)\n",
        "        current_spatial_size = input_spatial_size\n",
        "        self.input_placeholder_desc = {'type': 'input_placeholder', 'out_channels': current_channels_cnn, 'out_spatial': input_spatial_size, 'input_indices': []}\n",
        "        stage_base_channels_cnn = [init_model_ch_cnn, init_model_ch_cnn * 2, init_model_ch_cnn * 4]\n",
        "        for i_cnn_stage in range(num_stages_cnn):\n",
        "            stage_module_cnn = DynamicStageModule(i_cnn_stage, current_channels_cnn, current_spatial_size, max_ops_dyn=None)\n",
        "            target_stage_out_channels_cnn = stage_base_channels_cnn[i_cnn_stage] if i_cnn_stage < len(stage_base_channels_cnn) else stage_base_channels_cnn[-1]\n",
        "            conv1 = nn.Conv2d(current_channels_cnn, target_stage_out_channels_cnn, 3, 1, 1, bias=False).to(DEVICE)\n",
        "            bn1 = nn.BatchNorm2d(target_stage_out_channels_cnn).to(DEVICE)\n",
        "            relu1 = nn.ReLU(inplace=False).to(DEVICE)\n",
        "            stage_module_cnn.add_op(conv1, {'type': 'conv2d', 'out_channels': target_stage_out_channels_cnn, 'out_spatial': current_spatial_size, 'input_indices': [-1]})\n",
        "            stage_module_cnn.add_op(bn1, {'type': 'batchnorm2d', 'out_channels': target_stage_out_channels_cnn, 'out_spatial': current_spatial_size, 'input_indices': [0]})\n",
        "            stage_module_cnn.add_op(relu1, {'type': 'relu', 'out_channels': target_stage_out_channels_cnn, 'out_spatial': current_spatial_size, 'input_indices': [1]})\n",
        "            current_channels_after_block_cnn, current_spatial_after_block = stage_module_cnn.get_current_out_properties()\n",
        "            if i_cnn_stage < num_stages_cnn - 1 :\n",
        "                pool_cnn = nn.MaxPool2d(2, 2).to(DEVICE)\n",
        "                current_spatial_size //= 2\n",
        "                stage_module_cnn.add_op(pool_cnn, {'type': 'maxpool2d', 'out_channels': current_channels_after_block_cnn, 'out_spatial': current_spatial_size, 'input_indices': [2]})\n",
        "            self.stages.append(stage_module_cnn)\n",
        "            current_channels_cnn, current_spatial_size = stage_module_cnn.get_current_out_properties()\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        fc_in_features_cnn, _ = self.get_last_stage_out_properties()\n",
        "        self.classifier = nn.ModuleList([nn.Linear(max(1, fc_in_features_cnn), num_classes_cnn).to(DEVICE)])\n",
        "        self.classifier_op_descriptions = [{'type': 'linear', 'out_features': num_classes_cnn, 'input_indices': [-1]}]\n",
        "    def forward(self,x_cnn_fwd):\n",
        "        for stage_cnn_fwd in self.stages: x_cnn_fwd=stage_cnn_fwd(x_cnn_fwd)\n",
        "        x_cnn_fwd = self.flatten(self.adaptive_pool(x_cnn_fwd))\n",
        "        for op_module in self.classifier:\n",
        "            x_cnn_fwd = op_module(x_cnn_fwd)\n",
        "        return x_cnn_fwd\n",
        "    def get_last_stage_out_properties(self):\n",
        "        if not self.stages:\n",
        "            return self.input_placeholder_desc['out_channels'], self.input_placeholder_desc['out_spatial']\n",
        "        return self.stages[-1].get_current_out_properties()\n",
        "    def get_classifier_in_features(self):\n",
        "        if not self.classifier: return 0\n",
        "        return self.classifier[0].in_features\n",
        "    def get_classifier_out_features(self):\n",
        "        if not self.classifier: return 0\n",
        "        return self.classifier[-1].out_features\n",
        "\n",
        "# =======================================================================\n",
        "#  GNN MetaAgent\n",
        "# =======================================================================\n",
        "if PYG_AVAILABLE:\n",
        "    class MetaAgentGNN(nn.Module):\n",
        "        def __init__(self, node_feature_dim_agent=NODE_FEATURE_DIM, initial_gnn_hidden_dim_agent=INITIAL_GNN_HIDDEN_DIM, initial_num_gnn_layers_agent=INITIAL_NUM_GNN_LAYERS,\n",
        "                     global_history_dim_flat_agent=GLOBAL_SUMMARY_FEATURE_DIM * MAX_GLOBAL_HISTORY_LEN, device_to_use_agent=DEVICE, **kwargs_agent):\n",
        "            super().__init__()\n",
        "            self.device = device_to_use_agent; self.node_feature_dim = node_feature_dim_agent; self.current_gnn_hidden_dim = initial_gnn_hidden_dim_agent\n",
        "            self.current_num_gnn_layers = initial_num_gnn_layers_agent; self.action_space_sizes = {k: v for k, v in kwargs_agent.items()}; self.head_depth_counters = {}\n",
        "            self.edit_type_embedding = nn.Embedding(self.action_space_sizes['num_edit_types'], EDIT_TYPE_EMBED_DIM).to(self.device)\n",
        "            self.policy_head_names = ['head_target_loc_stage', 'head_target_conv_ch_mult', 'head_target_resize_factor']\n",
        "            self._build_gnn_layers(); self._build_mlp_heads(global_history_dim_flat_agent)\n",
        "        def _build_gnn_layers(self):\n",
        "            self.gnn_layers = nn.ModuleList(); current_in_dim = self.node_feature_dim\n",
        "            if self.current_num_gnn_layers > 0:\n",
        "                for _ in range(self.current_num_gnn_layers):\n",
        "                    out_dim = self.current_gnn_hidden_dim\n",
        "                    self.gnn_layers.append(pyg_nn.GCNConv(current_in_dim, out_dim, bias=True, normalize=True, add_self_loops=True).to(self.device)); current_in_dim = out_dim\n",
        "        def _get_current_gnn_output_dim(self):\n",
        "            if self.current_num_gnn_layers == 0: return self.node_feature_dim\n",
        "            return self.current_gnn_hidden_dim\n",
        "        def _build_mlp_heads(self, global_history_dim_flat):\n",
        "            gnn_output_dim = self._get_current_gnn_output_dim();\n",
        "            base_input_dim = gnn_output_dim + global_history_dim_flat\n",
        "            self.heads_input_dim_global_current = base_input_dim\n",
        "            self.head_target_edit_type = nn.Linear(base_input_dim, self.action_space_sizes['num_edit_types'])\n",
        "            self.head_meta_self_edit_type = nn.Linear(base_input_dim, NUM_META_SELF_EDIT_TYPES)\n",
        "            self.head_value = nn.Linear(base_input_dim, 1)\n",
        "            conditional_input_dim = base_input_dim + EDIT_TYPE_EMBED_DIM\n",
        "            self.head_target_loc_stage = nn.Linear(conditional_input_dim, self.action_space_sizes['num_stages_target'])\n",
        "            self.head_target_conv_ch_mult = nn.Linear(conditional_input_dim, len(DISCRETE_CH_MULT_ADD))\n",
        "            self.head_target_resize_factor = nn.Linear(conditional_input_dim, len(DISCRETE_RESIZE_FACTORS))\n",
        "            self.head_resize_op_selector_scorer = nn.Linear(gnn_output_dim, 1)\n",
        "            self.head_skip_source_scorer = nn.Linear(gnn_output_dim, 1)\n",
        "            self.head_skip_destination_scorer = nn.Linear(gnn_output_dim, 1)\n",
        "            all_head_names = self.policy_head_names + ['head_target_edit_type', 'head_meta_self_edit_type', 'head_value', 'head_resize_op_selector_scorer', 'head_skip_source_scorer', 'head_skip_destination_scorer']\n",
        "            for name, module in self.named_children():\n",
        "                if name in all_head_names or name == 'edit_type_embedding':\n",
        "                    module.to(self.device)\n",
        "            self.head_depth_counters = {name: (len(getattr(self,name)) if isinstance(getattr(self,name),nn.Sequential) else 1) for name in self.get_mlp_head_names()}\n",
        "        def get_mlp_head_names(self):\n",
        "             return self.policy_head_names\n",
        "        def _process_graph_and_state(self, graph_data, global_states_history_flat):\n",
        "            node_features, edge_index = graph_data.x, graph_data.edge_index\n",
        "            embeddings = node_features\n",
        "            if self.current_num_gnn_layers > 0 and graph_data.num_nodes > 0:\n",
        "                for gnn_layer in self.gnn_layers:\n",
        "                    embeddings = F.relu(gnn_layer(embeddings, edge_index))\n",
        "            elif graph_data.num_nodes == 0:\n",
        "                embeddings = torch.empty(0, self._get_current_gnn_output_dim(), device=self.device)\n",
        "            batch_vector = graph_data.batch\n",
        "            if batch_vector is None and embeddings.numel() > 0:\n",
        "                batch_vector = torch.zeros(embeddings.size(0), dtype=torch.long, device=self.device)\n",
        "            graph_embedding = pyg_nn.global_mean_pool(embeddings, batch_vector) if graph_data.num_nodes > 0 else torch.zeros(1, self._get_current_gnn_output_dim(), device=self.device)\n",
        "            if global_states_history_flat.ndim == 1: global_states_history_flat = global_states_history_flat.unsqueeze(0)\n",
        "            if graph_embedding.ndim == 1: graph_embedding = graph_embedding.unsqueeze(0)\n",
        "            combined_features = torch.cat((graph_embedding, global_states_history_flat), dim=1)\n",
        "            return combined_features, embeddings\n",
        "        def forward(self, graph_data, global_states_history_flat):\n",
        "            combined_features, node_embeddings = self._process_graph_and_state(graph_data, global_states_history_flat)\n",
        "            l_te = self.head_target_edit_type(combined_features)\n",
        "            l_mse = self.head_meta_self_edit_type(combined_features)\n",
        "            value_pred = self.head_value(combined_features)\n",
        "            return l_te, l_mse, value_pred, node_embeddings, combined_features\n",
        "        def get_conditional_logits(self, base_state_embedding, chosen_edit_type_tensor):\n",
        "            type_emb = self.edit_type_embedding(chosen_edit_type_tensor)\n",
        "            conditional_state = torch.cat([base_state_embedding, type_emb], dim=1)\n",
        "            logits = {}\n",
        "            edit_type = chosen_edit_type_tensor.item()\n",
        "            if edit_type == EDIT_TYPE_ADD_CONV_BLOCK:\n",
        "                logits['stage'] = self.head_target_loc_stage(conditional_state)\n",
        "                logits['ch_mult'] = self.head_target_conv_ch_mult(conditional_state)\n",
        "            elif edit_type == EDIT_TYPE_RESIZE_LAYER:\n",
        "                logits['stage'] = self.head_target_loc_stage(conditional_state)\n",
        "                logits['resize_factor'] = self.head_target_resize_factor(conditional_state)\n",
        "            elif edit_type == EDIT_TYPE_ADD_SKIP:\n",
        "                logits['stage'] = self.head_target_loc_stage(conditional_state)\n",
        "            return logits\n",
        "\n",
        "        def deepen_gnn(self, device='cpu'):\n",
        "            print(f\"  Deepening MetaAgentGNN: GNN Layers {self.current_num_gnn_layers} -> {self.current_num_gnn_layers + 1}\")\n",
        "            new_layer_in_dim = self._get_current_gnn_output_dim()\n",
        "            if self.current_num_gnn_layers == 0 : new_gcn_layer = pyg_nn.GCNConv(self.node_feature_dim, self.current_gnn_hidden_dim, bias=True, normalize=True, add_self_loops=True).to(device)\n",
        "            else: new_gcn_layer = create_identity_gcn_layer(self.current_gnn_hidden_dim, device=device) if new_layer_in_dim == self.current_gnn_hidden_dim else pyg_nn.GCNConv(new_layer_in_dim, self.current_gnn_hidden_dim, bias=True, normalize=True, add_self_loops=True).to(device)\n",
        "            self.gnn_layers.append(new_gcn_layer); self.current_num_gnn_layers += 1\n",
        "            if self._get_current_gnn_output_dim() + (GLOBAL_SUMMARY_FEATURE_DIM * MAX_GLOBAL_HISTORY_LEN) != self.heads_input_dim_global_current:\n",
        "                 self._build_mlp_heads(GLOBAL_SUMMARY_FEATURE_DIM * MAX_GLOBAL_HISTORY_LEN)\n",
        "            return True\n",
        "\n",
        "        def widen_gnn_hidden_dim(self, factor=META_GNN_WIDEN_FACTOR, device='cpu'):\n",
        "            old_dim = self.current_gnn_hidden_dim; new_dim = max(INITIAL_GNN_HIDDEN_DIM // 2 if INITIAL_GNN_HIDDEN_DIM > 1 else 1 , int(round(old_dim * factor)))\n",
        "            if new_dim == old_dim or self.current_num_gnn_layers == 0: return False\n",
        "            print(f\"  Widening MetaAgentGNN: GNN Hidden Dim {old_dim} -> {new_dim}\")\n",
        "            new_gnn_list = nn.ModuleList(); current_in_dim = self.node_feature_dim; any_changed = False\n",
        "            for i in range(self.current_num_gnn_layers):\n",
        "                original_gcn = self.gnn_layers[i]; temp_gcn = original_gcn\n",
        "                if original_gcn.in_channels != current_in_dim: temp_gcn, chg1 = adapt_gcn_conv_input_dim(original_gcn, current_in_dim, device); any_changed |= chg1\n",
        "                final_gcn, chg2 = resize_gcn_conv_hidden(temp_gcn, new_dim, current_in_dim, device); any_changed |= chg2\n",
        "                new_gnn_list.append(final_gcn); current_in_dim = new_dim\n",
        "            if not any_changed and new_dim != old_dim : return False\n",
        "            self.gnn_layers = new_gnn_list; self.current_gnn_hidden_dim = new_dim; self._build_mlp_heads(GLOBAL_SUMMARY_FEATURE_DIM * MAX_GLOBAL_HISTORY_LEN)\n",
        "            return True\n",
        "\n",
        "        def deepen_one_mlp_head(self, head_attr_name, device='cpu'):\n",
        "            original_comp = getattr(self, head_attr_name, None)\n",
        "            if original_comp is None: return False\n",
        "            current_depth = self.head_depth_counters.get(head_attr_name, 1)\n",
        "            if current_depth >= 8: return False\n",
        "            changed = net2deeper_linear_insert_identity(self, head_attr_name, device=device)\n",
        "            if changed: self.head_depth_counters[head_attr_name] = len(getattr(self, head_attr_name)) if isinstance(getattr(self, head_attr_name), nn.Sequential) else 1\n",
        "            return changed\n",
        "\n",
        "        def shrink_gnn_hidden_dim(self, factor=META_GNN_SHRINK_FACTOR, device='cpu'):\n",
        "            old_dim = self.current_gnn_hidden_dim\n",
        "            new_dim = int(round(old_dim * factor))\n",
        "            new_dim = max(new_dim, MIN_GNN_HIDDEN_DIM)\n",
        "            if new_dim == old_dim or self.current_num_gnn_layers == 0: return False\n",
        "            print(f\"  Shrinking MetaAgentGNN: GNN Hidden Dim {old_dim} -> {new_dim}\")\n",
        "            return self.widen_gnn_hidden_dim(factor=float(new_dim)/old_dim, device=device)\n",
        "\n",
        "        def prune_gnn_layer(self, device='cpu'):\n",
        "            if self.current_num_gnn_layers <= MIN_GNN_LAYERS: return False\n",
        "            print(f\"  Pruning MetaAgentGNN: GNN Layers {self.current_num_gnn_layers} -> {self.current_num_gnn_layers - 1}\")\n",
        "            self.gnn_layers.pop(-1)\n",
        "            self.current_num_gnn_layers -= 1\n",
        "            self._build_mlp_heads(GLOBAL_SUMMARY_FEATURE_DIM * MAX_GLOBAL_HISTORY_LEN)\n",
        "            return True\n",
        "\n",
        "        def prune_one_mlp_head(self, head_attr_name, device='cpu'):\n",
        "            original_comp = getattr(self, head_attr_name, None)\n",
        "            if original_comp is None: return False\n",
        "            current_depth = self.head_depth_counters.get(head_attr_name, 1)\n",
        "            if current_depth <= MIN_MLP_HEAD_SEQUENTIAL_DEPTH: return False\n",
        "            changed = net2thinner_linear_remove_layer(self, head_attr_name, device=device)\n",
        "            if changed:\n",
        "                new_comp = getattr(self, head_attr_name)\n",
        "                self.head_depth_counters[head_attr_name] = len(new_comp) if isinstance(new_comp, nn.Sequential) else 1\n",
        "            return changed\n",
        "\n",
        "# =======================================================================\n",
        "#  Prometheus System\n",
        "# =======================================================================\n",
        "class DEITI:\n",
        "    def __init__(self):\n",
        "        if not PYG_AVAILABLE: raise ImportError(\"PyTorch Geometric required for Prometheus.\")\n",
        "        self.device=DEVICE\n",
        "        self.target_cnn = TargetCNN().to(DEVICE)\n",
        "        self.meta_agent = MetaAgentGNN(\n",
        "            device_to_use_agent=self.device, num_edit_types=NUM_TARGET_CNN_EDIT_TYPES, num_stages_target=NUM_STAGES_TARGET_CNN,\n",
        "            num_ch_mults=len(DISCRETE_CH_MULT_ADD), num_resize_factors=len(DISCRETE_RESIZE_FACTORS),\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        self.criterion_target=nn.CrossEntropyLoss()\n",
        "        self.global_states_history_buffer=[]\n",
        "        self.amp_scaler = torch.amp.GradScaler(enabled=(self.device.type=='cuda'))\n",
        "        self._init_dataloaders()\n",
        "        self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "        self.sched_target = CosineAnnealingLR(self.opt_target, T_max=BASE_POST_EPOCHS)\n",
        "        self.opt_meta = optim.Adam(self.meta_agent.parameters(), lr=BASE_META_LR)\n",
        "\n",
        "        self.frozen_bns = []\n",
        "        self.warmup_state = {'active': False, 'original_lr': LEARNING_RATE, 'param_ratio': 1.0}\n",
        "\n",
        "        self.best_global_accuracy = -1.0\n",
        "        self.best_global_model = None\n",
        "\n",
        "        self.iterations_without_improvement = 0\n",
        "        self.consecutive_dummy_pass_failures = 0\n",
        "\n",
        "    def _init_dataloaders(self):\n",
        "        cifar10_mean, cifar10_std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n",
        "            transforms.RandAugment(num_ops=2, magnitude=9),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(cifar10_mean, cifar10_std),\n",
        "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
        "        ])\n",
        "\n",
        "        val_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "        ])\n",
        "        try:\n",
        "            tr_ds = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
        "            val_ds = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=val_transforms)\n",
        "        except Exception as e:\n",
        "            print(f\"CIFAR-10 download failed: {e}. Using FakeData.\")\n",
        "            fake_transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(cifar10_mean, cifar10_std)\n",
        "            ])\n",
        "            tr_ds = torchvision.datasets.FakeData(size=BATCH_SIZE*50, image_size=(3,32,32), num_classes=10, transform=fake_transform)\n",
        "            val_ds = torchvision.datasets.FakeData(size=BATCH_SIZE*20, image_size=(3,32,32), num_classes=10, transform=fake_transform)\n",
        "\n",
        "        num_workers = 4 if self.device.type == 'cuda' else 0\n",
        "        use_persistent_workers = num_workers > 0\n",
        "        print(f\"Using {num_workers} workers for data loading (persistent: {use_persistent_workers}).\")\n",
        "        self.train_loader = DataLoader(tr_ds, BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=self.device.type=='cuda', drop_last=True, persistent_workers=use_persistent_workers)\n",
        "        self.val_loader = DataLoader(val_ds, BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=self.device.type=='cuda', drop_last=True, persistent_workers=use_persistent_workers)\n",
        "\n",
        "    def _create_target_cnn_graph_data(self):\n",
        "        nodes, src, tgt, op_map, gid = {}, [], [], {}, 0\n",
        "        _, initial_spatial = self.target_cnn.input_placeholder_desc['out_channels'], self.target_cnn.input_placeholder_desc['out_spatial']\n",
        "        current_spatial_map = {-1: initial_spatial}\n",
        "        for si, sm in enumerate(self.target_cnn.stages):\n",
        "            stage_initial_spatial = current_spatial_map.get(si-1, initial_spatial)\n",
        "            op_output_props = {-1: (sm.initial_in_channels, stage_initial_spatial)}\n",
        "            for oi, od in enumerate(sm.op_descriptions):\n",
        "                op_map[(si, oi)] = gid\n",
        "                op_type_str = od.get('type', 'none')\n",
        "                input_indices = od.get('input_indices', [-1])\n",
        "                input_indices = input_indices if isinstance(input_indices, list) else [input_indices]\n",
        "                prev_op_idx = input_indices[0]\n",
        "                _, expected_in_spatial = op_output_props.get(prev_op_idx, (sm.initial_in_channels, stage_initial_spatial))\n",
        "                is_conv = 1.0 if op_type_str == 'conv2d' else 0.0\n",
        "                out_spatial = expected_in_spatial\n",
        "                stride_val = 1\n",
        "                if op_type_str == 'maxpool2d':\n",
        "                    stride_val = sm.ops[oi].stride if hasattr(sm.ops[oi], 'stride') else 1\n",
        "                    out_spatial //= stride_val\n",
        "                elif op_type_str == 'conv2d':\n",
        "                    current_op = sm.ops[oi]\n",
        "                    stride_val = current_op.stride[0] if isinstance(current_op.stride, tuple) else current_op.stride\n",
        "                    out_spatial //= stride_val\n",
        "                op_output_props[oi] = (od.get('out_channels', 0), out_spatial)\n",
        "                od['out_spatial'] = out_spatial\n",
        "                nf = [\n",
        "                    float(OP_TYPE_IDS.get(op_type_str, 0)),\n",
        "                    float(od.get('out_channels', 0)) / NORMALIZATION_WIDTH_DIVISOR,\n",
        "                    float(si) / max(1, NUM_STAGES_TARGET_CNN - 1),\n",
        "                    float(oi) / max(1, len(sm.ops) - 1),\n",
        "                    is_conv,\n",
        "                    float(stride_val -1),\n",
        "                    float(out_spatial) / NORMALIZATION_SPATIAL_DIVISOR,\n",
        "                ]\n",
        "                nodes[gid] = nf\n",
        "                gid += 1\n",
        "            if sm.op_descriptions:\n",
        "                 current_spatial_map[si] = op_output_props[len(sm.ops)-1][1]\n",
        "            else:\n",
        "                 current_spatial_map[si] = stage_initial_spatial\n",
        "        s_out_gid_map = {s: op_map.get((s, len(sm_loop.ops) - 1), -1) for s, sm_loop in enumerate(self.target_cnn.stages) if sm_loop.ops}\n",
        "        last_conv_gid = s_out_gid_map.get(len(self.target_cnn.stages) - 1, -1)\n",
        "        for oi, od in enumerate(self.target_cnn.classifier_op_descriptions):\n",
        "            op_map[('classifier', oi)] = gid\n",
        "            op_type_str = od.get('type', 'none')\n",
        "            nf = [\n",
        "                float(OP_TYPE_IDS.get(op_type_str, 0)),\n",
        "                float(od.get('out_features', 0)) / NORMALIZATION_WIDTH_DIVISOR,\n",
        "                1.0, float(oi) / max(1, len(self.target_cnn.classifier) - 1),\n",
        "                0.0, 0.0, 0.0\n",
        "            ]\n",
        "            nodes[gid] = nf\n",
        "            gid += 1\n",
        "        for si, sm in enumerate(self.target_cnn.stages):\n",
        "            for oi, od in enumerate(sm.op_descriptions):\n",
        "                cur_gid = op_map.get((si, oi), -1)\n",
        "                if cur_gid == -1: continue\n",
        "                in_ids = od.get('input_indices', [-1] if oi == 0 else [oi - 1])\n",
        "                in_ids = in_ids if isinstance(in_ids, list) else [in_ids]\n",
        "                for lsid in in_ids:\n",
        "                    if lsid == -1: sgid = s_out_gid_map.get(si - 1, -1) if si > 0 else -1\n",
        "                    else: sgid = op_map.get((si, lsid), -1)\n",
        "                    if sgid != -1: src.append(sgid); tgt.append(cur_gid)\n",
        "        prev_gid = last_conv_gid\n",
        "        for oi, od in enumerate(self.target_cnn.classifier_op_descriptions):\n",
        "            cur_gid = op_map.get(('classifier', oi), -1)\n",
        "            if cur_gid != -1 and prev_gid != -1:\n",
        "                src.append(prev_gid)\n",
        "                tgt.append(cur_gid)\n",
        "            prev_gid = cur_gid\n",
        "        x = torch.tensor([nodes[i] for i in range(gid)] if gid > 0 else [[0.] * NODE_FEATURE_DIM], dtype=torch.float32, device=self.device)\n",
        "        eidx = torch.tensor([src, tgt], dtype=torch.long, device=self.device) if src else torch.empty((2, 0), dtype=torch.long, device=self.device)\n",
        "        return Data(x=x, edge_index=eidx, batch=torch.zeros(x.size(0), dtype=torch.long, device=self.device) if x.size(0) > 0 else None), op_map, s_out_gid_map\n",
        "\n",
        "    def _ensure_target_cnn_consistency(self):\n",
        "        current_channels, current_spatial = self.target_cnn.input_placeholder_desc['out_channels'], self.target_cnn.input_placeholder_desc['out_spatial']\n",
        "        for stage_module in self.target_cnn.stages:\n",
        "            stage_module.initial_in_channels = current_channels\n",
        "            stage_module.initial_spatial_size = current_spatial\n",
        "            op_output_props = {-1: (current_channels, current_spatial)}\n",
        "            for i, op in enumerate(stage_module.ops):\n",
        "                desc = stage_module.op_descriptions[i]\n",
        "                input_indices = desc.get('input_indices', [-1]); input_indices = input_indices if isinstance(input_indices, list) else [input_indices]\n",
        "                prev_op_idx = input_indices[0] if input_indices else -1\n",
        "                expected_in_channels, expected_in_spatial = op_output_props.get(prev_op_idx, (current_channels, current_spatial))\n",
        "                new_op = None\n",
        "                if isinstance(op, nn.Conv2d):\n",
        "                    if op.in_channels != expected_in_channels: new_op = adapt_conv_input_channels(op, expected_in_channels, self.device)\n",
        "                    if new_op is None and op.in_channels != expected_in_channels: return False\n",
        "                    desc['out_channels'] = op.out_channels if new_op is None else new_op.out_channels\n",
        "                    stride_val = op.stride[0] if isinstance(op.stride, tuple) else op.stride\n",
        "                    desc['out_spatial'] = expected_in_spatial // stride_val\n",
        "                elif isinstance(op, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                    if op.num_features != expected_in_channels: new_op = adapt_batchnorm_features(op, expected_in_channels, self.device)\n",
        "                    desc['out_channels'] = expected_in_channels\n",
        "                    desc['out_spatial'] = expected_in_spatial\n",
        "                elif isinstance(op, nn.ReLU):\n",
        "                    desc['out_channels'] = expected_in_channels; desc['out_spatial'] = expected_in_spatial\n",
        "                elif isinstance(op, nn.MaxPool2d):\n",
        "                    stride_val = op.stride if isinstance(op.stride, int) else op.stride[0]\n",
        "                    desc['out_channels'] = expected_in_channels; desc['out_spatial'] = expected_in_spatial // stride_val\n",
        "                elif isinstance(op, AddWithProjection):\n",
        "                    primary_ch, primary_sp = op_output_props[input_indices[0]]; skip_ch, _ = op_output_props[input_indices[1]]\n",
        "                    if primary_ch != skip_ch: op.projection = nn.Sequential(nn.Conv2d(skip_ch, primary_ch, kernel_size=1, bias=False), nn.BatchNorm2d(primary_ch)).to(self.device)\n",
        "                    else: op.projection = nn.Identity()\n",
        "                    desc['out_channels'], desc['out_spatial'] = primary_ch, primary_sp\n",
        "                if new_op is not None: stage_module.ops[i] = new_op\n",
        "                op_output_props[i] = (desc.get('out_channels'), desc.get('out_spatial'))\n",
        "            current_channels, current_spatial = stage_module.get_current_out_properties()\n",
        "        last_conv_channels, _ = self.target_cnn.get_last_stage_out_properties()\n",
        "        current_features = max(1, last_conv_channels)\n",
        "        for i, op in enumerate(self.target_cnn.classifier):\n",
        "            desc = self.target_cnn.classifier_op_descriptions[i]\n",
        "            new_op = None\n",
        "            if isinstance(op, nn.Linear):\n",
        "                if op.in_features != current_features: new_op = adapt_linear_input_features(op, current_features, self.device)\n",
        "                current_features = op.out_features if new_op is None else new_op.out_features\n",
        "                desc['out_features'] = current_features\n",
        "            elif isinstance(op, nn.BatchNorm1d):\n",
        "                if op.num_features != current_features: new_op = adapt_batchnorm_features(op, current_features, self.device)\n",
        "            elif isinstance(op, nn.ReLU):\n",
        "                pass\n",
        "            if new_op is not None: self.target_cnn.classifier[i] = new_op\n",
        "        return True\n",
        "\n",
        "    def _apply_target_cnn_edit(self, actions):\n",
        "        edit_type = actions['target_edit_type'].item(); changed = False\n",
        "        newly_added_bns = []\n",
        "\n",
        "        if edit_type == EDIT_TYPE_ADD_LINEAR_BLOCK:\n",
        "            prev_out_features = -1\n",
        "            for op in reversed(self.target_cnn.classifier[:-1]):\n",
        "                if hasattr(op, 'out_features'):\n",
        "                    prev_out_features = op.out_features\n",
        "                    break\n",
        "            if prev_out_features == -1:\n",
        "                prev_out_features = self.target_cnn.get_classifier_in_features()\n",
        "\n",
        "            new_linear = nn.Linear(prev_out_features, prev_out_features).to(self.device)\n",
        "            nn.init.eye_(new_linear.weight)\n",
        "            if new_linear.bias is not None: nn.init.zeros_(new_linear.bias)\n",
        "\n",
        "            bn = nn.BatchNorm1d(prev_out_features, momentum=0.1).to(self.device)\n",
        "            with torch.no_grad(): bn.weight.data.fill_(1.0); bn.bias.data.zero_()\n",
        "            bn.eval(); newly_added_bns.append(bn)\n",
        "\n",
        "            new_relu = nn.ReLU(inplace=False).to(self.device)\n",
        "            insert_idx = len(self.target_cnn.classifier) - 1\n",
        "            self.target_cnn.classifier.insert(insert_idx, new_linear); self.target_cnn.classifier.insert(insert_idx + 1, bn); self.target_cnn.classifier.insert(insert_idx + 2, new_relu)\n",
        "            self.target_cnn.classifier_op_descriptions.insert(insert_idx, {'type': 'linear', 'out_features': new_linear.out_features})\n",
        "            self.target_cnn.classifier_op_descriptions.insert(insert_idx + 1, {'type': 'batchnorm1d', 'out_features': new_linear.out_features})\n",
        "            self.target_cnn.classifier_op_descriptions.insert(insert_idx + 2, {'type': 'relu', 'out_features': new_linear.out_features})\n",
        "            changed = True\n",
        "\n",
        "        elif edit_type == EDIT_TYPE_ADD_CONV_BLOCK:\n",
        "            stage_idx = actions['target_loc_stage'].item()\n",
        "            if not (0 <= stage_idx < len(self.target_cnn.stages)): return False, []\n",
        "            stage = self.target_cnn.stages[stage_idx]\n",
        "            in_ch, in_sp = stage.get_current_out_properties(); in_ch = max(1, in_ch)\n",
        "\n",
        "            k = 3; s = 1\n",
        "            identity_conv = nn.Conv2d(in_ch, in_ch, k, stride=s, padding=(k-1)//2, bias=False).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                identity_conv.weight.data.zero_()\n",
        "                center = k // 2\n",
        "                for i in range(in_ch): identity_conv.weight.data[i, i, center, center] = 1.0\n",
        "\n",
        "            bn = nn.BatchNorm2d(in_ch, momentum=0.1).to(self.device)\n",
        "            with torch.no_grad():\n",
        "                bn.weight.data.fill_(1.0)\n",
        "                bn.bias.data.zero_()\n",
        "            bn.eval()\n",
        "            newly_added_bns.append(bn)\n",
        "            relu = nn.ReLU(inplace=False).to(self.device)\n",
        "\n",
        "            insert_idx = len(stage.ops)\n",
        "            in_indices = [-1] if insert_idx == 0 else [insert_idx-1]\n",
        "            stage.add_op(identity_conv, {'type':'conv2d', 'out_channels': in_ch, 'out_spatial': in_sp, 'input_indices':in_indices}, insert_at=insert_idx)\n",
        "            stage.add_op(bn, {'type':'batchnorm2d', 'out_channels': in_ch, 'out_spatial': in_sp, 'input_indices':[insert_idx]}, insert_at=insert_idx+1)\n",
        "            stage.add_op(relu, {'type':'relu', 'out_channels': in_ch, 'out_spatial': in_sp, 'input_indices':[insert_idx+1]}, insert_at=insert_idx+2)\n",
        "\n",
        "            m = DISCRETE_CH_MULT_ADD[actions['target_conv_ch_mult_idx'].item()]\n",
        "            target_out_ch = max(1, int(round(in_ch * m)))\n",
        "\n",
        "            if in_ch != target_out_ch:\n",
        "                factor = float(target_out_ch) / in_ch\n",
        "                widened_conv = resize_conv_output(stage.ops[insert_idx], factor, self.device)\n",
        "                widened_bn = adapt_batchnorm_features(stage.ops[insert_idx+1], widened_conv.out_channels, self.device)\n",
        "\n",
        "                stage.ops[insert_idx] = widened_conv\n",
        "                stage.ops[insert_idx+1] = widened_bn\n",
        "\n",
        "                stage.op_descriptions[insert_idx]['out_channels'] = widened_conv.out_channels\n",
        "                stage.op_descriptions[insert_idx+1]['out_channels'] = widened_conv.out_channels\n",
        "                stage.op_descriptions[insert_idx+2]['out_channels'] = widened_conv.out_channels\n",
        "\n",
        "            changed = True\n",
        "\n",
        "        elif edit_type == EDIT_TYPE_RESIZE_LAYER:\n",
        "            stage_idx = actions['target_loc_stage'].item()\n",
        "            if not (0 <= stage_idx < len(self.target_cnn.stages)): return False, []\n",
        "            stage = self.target_cnn.stages[stage_idx]\n",
        "            op_idx = actions.get('target_actual_op_idx_in_stage', -1)\n",
        "            if op_idx != -1 and 0 <= op_idx < len(stage.ops):\n",
        "                op_mod = stage.ops[op_idx]\n",
        "                factor = DISCRETE_RESIZE_FACTORS[actions['target_resize_factor_idx'].item()]\n",
        "                if isinstance(op_mod, nn.Conv2d):\n",
        "                    new_op = resize_conv_output(op_mod, factor, self.device)\n",
        "                    if new_op is not op_mod: stage.ops[op_idx] = new_op; stage.op_descriptions[op_idx]['out_channels'] = new_op.out_channels; changed = True\n",
        "                elif isinstance(op_mod, nn.Linear):\n",
        "                    new_op = resize_linear_output(op_mod, factor, self.device)\n",
        "                    if new_op is not op_mod: stage.ops[op_idx] = new_op; stage.op_descriptions[op_idx]['out_features'] = new_op.out_features; changed = True\n",
        "        elif edit_type == EDIT_TYPE_ADD_SKIP:\n",
        "            stage_idx = actions['target_loc_stage'].item()\n",
        "            if not (0 <= stage_idx < len(self.target_cnn.stages)): return False, []\n",
        "            stage = self.target_cnn.stages[stage_idx]\n",
        "            source_op_idx = actions.get('source_op_idx', -1); dest_op_idx = actions.get('dest_op_idx', -1)\n",
        "            if source_op_idx != -1 and dest_op_idx != -1:\n",
        "                add_op = AddWithProjection().to(self.device)\n",
        "                _, dest_sp = stage.get_op_output_properties(dest_op_idx)\n",
        "                dest_ch, _ = stage.get_op_output_properties(dest_op_idx)\n",
        "                add_desc = {'type': 'add', 'out_channels': dest_ch, 'out_spatial': dest_sp, 'input_indices': [dest_op_idx, source_op_idx]}\n",
        "                insert_at_idx = dest_op_idx + 1\n",
        "                stage.add_op(add_op, add_desc, insert_at=insert_at_idx)\n",
        "                for i in range(insert_at_idx, len(stage.ops)):\n",
        "                    if stage.op_descriptions[i].get('input_indices') == [dest_op_idx]:\n",
        "                        stage.op_descriptions[i]['input_indices'] = [insert_at_idx]; break\n",
        "                changed = True\n",
        "\n",
        "        if changed:\n",
        "            consistency_ok = self._ensure_target_cnn_consistency()\n",
        "            return consistency_ok, newly_added_bns\n",
        "\n",
        "        return False, []\n",
        "\n",
        "    def _apply_meta_self_edit(self, action):\n",
        "        edit_type = action.item()\n",
        "        changed = False\n",
        "        if edit_type == META_EDIT_DEEPEN_GNN:\n",
        "            changed = self.meta_agent.deepen_gnn(device=self.device)\n",
        "        elif edit_type == META_EDIT_WIDEN_GNN_HIDDEN:\n",
        "            changed = self.meta_agent.widen_gnn_hidden_dim(factor=META_GNN_WIDEN_FACTOR, device=self.device)\n",
        "        elif edit_type == META_EDIT_DEEPEN_MLP_HEAD:\n",
        "            head_names = self.meta_agent.get_mlp_head_names()\n",
        "            if head_names:\n",
        "                changed = self.meta_agent.deepen_one_mlp_head(np.random.choice(head_names), device=self.device)\n",
        "        elif edit_type == META_EDIT_SHRINK_GNN_HIDDEN:\n",
        "            changed = self.meta_agent.shrink_gnn_hidden_dim(factor=META_GNN_SHRINK_FACTOR, device=self.device)\n",
        "        elif edit_type == META_EDIT_PRUNE_GNN:\n",
        "            changed = self.meta_agent.prune_gnn_layer(device=self.device)\n",
        "        elif edit_type == META_EDIT_PRUNE_MLP_HEAD:\n",
        "            head_names = self.meta_agent.get_mlp_head_names()\n",
        "            prunable_heads = [h for h in head_names if self.meta_agent.head_depth_counters.get(h, 1) > MIN_MLP_HEAD_SEQUENTIAL_DEPTH]\n",
        "            if prunable_heads:\n",
        "                changed = self.meta_agent.prune_one_mlp_head(np.random.choice(prunable_heads), device=self.device)\n",
        "\n",
        "        if changed:\n",
        "            print(f\"MetaAgentGNN arch changed. New Params: {sum(p.numel() for p in self.meta_agent.parameters())}. Re-init optimizer.\")\n",
        "            current_lr = self.opt_meta.param_groups[0]['lr']\n",
        "            del self.opt_meta\n",
        "            gc.collect(); torch.cuda.empty_cache()\n",
        "            self.opt_meta = optim.Adam(self.meta_agent.parameters(), lr=current_lr)\n",
        "        return changed\n",
        "\n",
        "    def _sanitize_bn_stats(self):\n",
        "        for m in self.target_cnn.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                m.running_mean.nan_to_num_(nan=0.0, posinf=1e4, neginf=-1e4)\n",
        "                m.running_var.nan_to_num_(nan=1.0, posinf=1e4, neginf=1e-4)\n",
        "                m.running_var.clamp_(min=1e-5)\n",
        "\n",
        "    def _train_target_one_epoch(self, loader, optimizer, scheduler, name=\"Tr\", current_epoch=0):\n",
        "        self.target_cnn.train()\n",
        "\n",
        "        warmup_total_epochs = 5\n",
        "        if self.warmup_state['active']:\n",
        "            if current_epoch < warmup_total_epochs:\n",
        "                lr_scale = (current_epoch + 1) / warmup_total_epochs\n",
        "                lr_scale /= math.sqrt(self.warmup_state['param_ratio'])\n",
        "                for g in optimizer.param_groups:\n",
        "                    g['lr'] = self.warmup_state['original_lr'] * lr_scale\n",
        "\n",
        "            if current_epoch >= warmup_total_epochs:\n",
        "                print(f\"  Warmup complete. Restoring LR to {self.warmup_state['original_lr']:.2e}.\")\n",
        "                for g in optimizer.param_groups: g['lr'] = self.warmup_state['original_lr']\n",
        "                self.warmup_state['active'] = False\n",
        "\n",
        "        if self.frozen_bns and current_epoch >= warmup_total_epochs:\n",
        "            print(f\"  Unfreezing {len(self.frozen_bns)} new BatchNorm layers.\")\n",
        "            for bn in self.frozen_bns:\n",
        "                bn.train()\n",
        "            self.frozen_bns = []\n",
        "\n",
        "        loss_sum, n_batches, correct, total = 0, 0, 0, 0\n",
        "        data_iterator = itertools.islice(loader, BATCHES_PER_EPOCH) if BATCHES_PER_EPOCH is not None else loader\n",
        "        for x,y in data_iterator:\n",
        "            if x.size(0) <= 1: continue\n",
        "            x,y=x.to(self.device),y.to(self.device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast(self.device.type,enabled=(self.device.type=='cuda')):\n",
        "                logits=self.target_cnn(x); loss = self.criterion_target(logits, y)\n",
        "\n",
        "            if torch.isnan(loss) or torch.isinf(loss):\n",
        "                continue\n",
        "\n",
        "            self.amp_scaler.scale(loss).backward()\n",
        "            self.amp_scaler.unscale_(optimizer)\n",
        "            clip_grad_norm_(self.target_cnn.parameters(), MAX_GRAD_NORM)\n",
        "            self.amp_scaler.step(optimizer)\n",
        "            self.amp_scaler.update()\n",
        "\n",
        "            loss_sum+=loss.item(); _,pred=logits.max(1); total+=y.size(0); correct+=pred.eq(y).sum().item(); n_batches+=1\n",
        "\n",
        "        if scheduler and not self.warmup_state['active']:\n",
        "            scheduler.step()\n",
        "\n",
        "        self._sanitize_bn_stats()\n",
        "\n",
        "        return loss_sum/max(1,n_batches), correct/max(1,total)\n",
        "\n",
        "    def _validate_target(self, loader):\n",
        "        self.target_cnn.eval()\n",
        "        loss_sum, correct, total, n_batches = 0,0,0,0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        data_iterator = itertools.islice(loader, BATCHES_PER_EPOCH) if BATCHES_PER_EPOCH is not None else loader\n",
        "        with torch.no_grad():\n",
        "            for x,y in data_iterator:\n",
        "                if x.size(0) <= 1: continue\n",
        "                x,y=x.to(self.device),y.to(self.device)\n",
        "                logits=self.target_cnn(x); loss=criterion(logits,y)\n",
        "                if torch.isnan(loss) or torch.isinf(loss): continue\n",
        "                loss_sum+=loss.item(); _,pred=logits.max(1); total+=y.size(0); correct+=pred.eq(y).sum().item(); n_batches+=1\n",
        "        return loss_sum/max(1,n_batches), correct/max(1,total)\n",
        "\n",
        "    def _validate_edit_with_dummy_pass(self):\n",
        "        self.target_cnn.eval()\n",
        "        try:\n",
        "            dummy_x, _ = next(iter(self.val_loader))\n",
        "            dummy_x = dummy_x.to(self.device)\n",
        "\n",
        "            with torch.no_grad(), autocast(self.device.type, enabled=(self.device.type=='cuda')):\n",
        "                output = self.target_cnn(dummy_x)\n",
        "\n",
        "            if torch.isnan(output).any() or torch.isinf(output).any():\n",
        "                print(\"  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\")\n",
        "                return False\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"  !!! Dummy pass failed with exception: {e}. Edit is invalid. !!!\")\n",
        "            traceback.print_exc()\n",
        "            return False\n",
        "        finally:\n",
        "            self.target_cnn.train()\n",
        "\n",
        "    def train_loop(self, iterations=100):\n",
        "        for itr in range(iterations):\n",
        "            print(f\"\\n===== Iteration {itr+1}/{iterations} =====\")\n",
        "            print(f\"Current MetaAgentGNN: GNN Layers={self.meta_agent.current_num_gnn_layers}, GNN Hidden={self.meta_agent.current_gnn_hidden_dim}, Params: {sum(p.numel() for p in self.meta_agent.parameters()):,}\")\n",
        "            print(f\"Current Global Best Accuracy: {self.best_global_accuracy:.4f}\")\n",
        "\n",
        "            if self.opt_target is None:\n",
        "                self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "            for pre_ep in range(PRE_EPOCHS):\n",
        "                self._train_target_one_epoch(self.train_loader, self.opt_target, None, f\"PreE{pre_ep+1}\", current_epoch=pre_ep)\n",
        "            val_loss_b, acc_b = self._validate_target(self.val_loader)\n",
        "            print(f\"PreVal: ValidL={val_loss_b:.4f}, ValidA={acc_b:.4f}\")\n",
        "\n",
        "            pre_edit_model_backup = copy.deepcopy(self.target_cnn)\n",
        "            old_params = sum(p.numel() for p in self.target_cnn.parameters() if p.requires_grad)\n",
        "\n",
        "            graph, op_map, s_out_gid_map = self._create_target_cnn_graph_data()\n",
        "            target_params_M = sum(p.numel() for p in self.target_cnn.parameters() if p.requires_grad)/1e6\n",
        "            norm_m_gl=self.meta_agent.current_num_gnn_layers / (MIN_GNN_LAYERS + 5)\n",
        "            norm_m_gh=self.meta_agent.current_gnn_hidden_dim / (MIN_GNN_HIDDEN_DIM + 256)\n",
        "            g_state=[val_loss_b,acc_b,target_params_M,norm_m_gl,norm_m_gh]; self.global_states_history_buffer.append(g_state)\n",
        "            if len(self.global_states_history_buffer)>MAX_GLOBAL_HISTORY_LEN: self.global_states_history_buffer.pop(0)\n",
        "            hist = list(self.global_states_history_buffer);\n",
        "            while len(hist)<MAX_GLOBAL_HISTORY_LEN: hist.insert(0,[0.]*GLOBAL_SUMMARY_FEATURE_DIM)\n",
        "            g_hist_flat=torch.tensor(hist,dtype=torch.float32,device=self.device).view(1,-1)\n",
        "            actions = {}; lp_t, en_t = 0.0, 0.0\n",
        "            l_te, l_mse, val_p, fne, base_state_embed = self.meta_agent(graph, g_hist_flat)\n",
        "            dist_te = Categorical(logits=l_te); s_te = dist_te.sample()\n",
        "            actions['target_edit_type'] = s_te; lp_t += dist_te.log_prob(s_te); en_t += dist_te.entropy().mean()\n",
        "            edit_type = s_te.item()\n",
        "            conditional_logits = self.meta_agent.get_conditional_logits(base_state_embed, s_te)\n",
        "            if edit_type != EDIT_TYPE_ADD_LINEAR_BLOCK:\n",
        "                l_ts = conditional_logits['stage']; dist_ts = Categorical(logits=l_ts); s_ts = dist_ts.sample()\n",
        "                actions['target_loc_stage'] = s_ts; lp_t += dist_ts.log_prob(s_ts); en_t += dist_ts.entropy().mean()\n",
        "            if edit_type == EDIT_TYPE_ADD_CONV_BLOCK:\n",
        "                l_tc = conditional_logits['ch_mult']; dist_tc = Categorical(logits=l_tc); s_tc = dist_tc.sample()\n",
        "                actions['target_conv_ch_mult_idx'] = s_tc; lp_t += dist_tc.log_prob(s_tc); en_t += dist_tc.entropy().mean()\n",
        "            elif edit_type == EDIT_TYPE_RESIZE_LAYER:\n",
        "                stage=self.target_cnn.stages[s_ts.item()]; candidates=[]\n",
        "                for oi,op in enumerate(stage.ops):\n",
        "                    if isinstance(op, (nn.Conv2d, nn.Linear)):\n",
        "                        valid_idx = _valid_resize_indices(op.out_channels if isinstance(op, nn.Conv2d) else op.out_features)\n",
        "                        if valid_idx:\n",
        "                            gid=op_map.get((s_ts.item(),oi),-1)\n",
        "                            if gid!=-1 and gid<fne.size(0): candidates.append((oi,fne[gid],valid_idx))\n",
        "                a_op_idx_rsz = -1; l_tr = conditional_logits['resize_factor']; dist_rf = Categorical(logits=l_tr)\n",
        "                if candidates:\n",
        "                    scores = self.meta_agent.head_resize_op_selector_scorer(torch.stack([e for _,e,_ in candidates])).squeeze(-1)\n",
        "                    if scores.numel() > 0:\n",
        "                        dist_co = Categorical(logits=scores); s_kth = dist_co.sample(); a_op_idx_rsz = candidates[s_kth.item()][0]\n",
        "                        lp_t += dist_co.log_prob(s_kth); en_t += dist_co.entropy().mean()\n",
        "                        valid_rf_idx = candidates[s_kth.item()][2]\n",
        "                        masked_l_tr = _mask_logits(l_tr.squeeze(0), valid_rf_idx)\n",
        "                        dist_rf = Categorical(logits=masked_l_tr if not torch.all(torch.isinf(masked_l_tr)) else l_tr)\n",
        "                s_rf_idx = dist_rf.sample(); lp_t += dist_rf.log_prob(s_rf_idx); en_t += dist_rf.entropy().mean()\n",
        "                actions['target_resize_factor_idx'] = s_rf_idx; actions['target_actual_op_idx_in_stage'] = a_op_idx_rsz\n",
        "            elif edit_type == EDIT_TYPE_ADD_SKIP:\n",
        "                stage = self.target_cnn.stages[s_ts.item()]; valid_pairs = []\n",
        "                for i in range(-1, len(stage.ops)):\n",
        "                    for j in range(i + 1, len(stage.ops)):\n",
        "                        _, src_sp = stage.get_op_output_properties(i); _, dest_sp = stage.get_op_output_properties(j)\n",
        "                        if src_sp == dest_sp: valid_pairs.append((i, j))\n",
        "                if valid_pairs:\n",
        "                    source_gids = [s_out_gid_map.get(s_ts.item() - 1, -1) if p[0] == -1 else op_map[(s_ts.item(), p[0])] for p in valid_pairs]\n",
        "                    dest_gids = [op_map[(s_ts.item(), p[1])] for p in valid_pairs]\n",
        "                    source_scores = self.meta_agent.head_skip_source_scorer(fne[source_gids]).squeeze()\n",
        "                    dest_scores = self.meta_agent.head_skip_destination_scorer(fne[dest_gids]).squeeze()\n",
        "                    if source_scores.dim() == 0: source_scores = source_scores.unsqueeze(0); dest_scores = dest_scores.unsqueeze(0)\n",
        "                    pair_scores = source_scores + dest_scores; dist_pair = Categorical(logits=pair_scores); chosen_pair_idx = dist_pair.sample()\n",
        "                    actions['source_op_idx'], actions['dest_op_idx'] = valid_pairs[chosen_pair_idx.item()]\n",
        "                    lp_t += dist_pair.log_prob(chosen_pair_idx); en_t += dist_pair.entropy()\n",
        "                else: actions['source_op_idx'] = -1; actions['dest_op_idx'] = -1\n",
        "\n",
        "            log_parts = [f\"TargEdit:Typ={edit_type}\"]\n",
        "            if 'target_loc_stage' in actions: log_parts.append(f\"Stg={actions['target_loc_stage'].item()}\")\n",
        "            if edit_type==EDIT_TYPE_ADD_CONV_BLOCK: log_parts.append(f\"CHM={DISCRETE_CH_MULT_ADD[actions['target_conv_ch_mult_idx'].item()]}\")\n",
        "            elif edit_type==EDIT_TYPE_RESIZE_LAYER: log_parts.append(f\"Op={actions.get('target_actual_op_idx_in_stage',-1)},RszF={DISCRETE_RESIZE_FACTORS[actions.get('target_resize_factor_idx', 0).item()]}\")\n",
        "            elif edit_type==EDIT_TYPE_ADD_SKIP: log_parts.append(f\"Src={actions.get('source_op_idx', -1)}->Dest={actions.get('dest_op_idx', -1)}\")\n",
        "\n",
        "            print(\" \".join(log_parts))\n",
        "\n",
        "            param_ratio = 1.0\n",
        "            t_changed, new_bns = self._apply_target_cnn_edit(actions)\n",
        "\n",
        "            if t_changed:\n",
        "                is_edit_valid = self._validate_edit_with_dummy_pass()\n",
        "                if not is_edit_valid:\n",
        "                    print(\"  Edit rolled back due to dummy pass failure.\")\n",
        "                    self.target_cnn = pre_edit_model_backup\n",
        "                    t_changed = False\n",
        "\n",
        "                    self.consecutive_dummy_pass_failures += 1\n",
        "                    if self.consecutive_dummy_pass_failures >= 3:\n",
        "                        print(\"\\n!!! INSTABILITY DETECTED: 3 consecutive edits failed dummy pass. !!!\")\n",
        "                        print(\"  Attempting to prune (simplify) Meta-Agent...\")\n",
        "\n",
        "                        pruning_actions = [META_EDIT_SHRINK_GNN_HIDDEN, META_EDIT_PRUNE_GNN, META_EDIT_PRUNE_MLP_HEAD]\n",
        "                        valid_pruning_actions = [a for a in pruning_actions if a not in _invalid_meta_indices(self.meta_agent)]\n",
        "\n",
        "                        if valid_pruning_actions:\n",
        "                            chosen_self_edit = np.random.choice(valid_pruning_actions)\n",
        "                            self._apply_meta_self_edit(torch.tensor(chosen_self_edit, device=self.device))\n",
        "                        else:\n",
        "                            print(\"  Meta-Agent is at minimum complexity or below prune threshold. No pruning possible.\")\n",
        "\n",
        "                        self.consecutive_dummy_pass_failures = 0\n",
        "                else:\n",
        "                    self.consecutive_dummy_pass_failures = 0\n",
        "\n",
        "            if t_changed:\n",
        "                del pre_edit_model_backup\n",
        "                gc.collect()\n",
        "                new_params = sum(p.numel() for p in self.target_cnn.parameters() if p.requires_grad)\n",
        "                param_ratio = new_params / max(1, old_params)\n",
        "                print(f\"  TargetCNN arch changed. New Params: {new_params:,} (Ratio: {param_ratio:.2f})\")\n",
        "\n",
        "                print(\"  Creating fresh optimizer for new architecture.\")\n",
        "                del self.opt_target, self.sched_target; gc.collect(); torch.cuda.empty_cache()\n",
        "                self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "                self.amp_scaler = torch.amp.GradScaler(enabled=(self.device.type=='cuda'))\n",
        "\n",
        "                if param_ratio > 1.2:\n",
        "                    print(f\"  Large parameter jump. Activating LR warmup.\")\n",
        "                    self.warmup_state = {'active': True, 'original_lr': LEARNING_RATE, 'param_ratio': param_ratio}\n",
        "                else:\n",
        "                    self.warmup_state['active'] = False\n",
        "                self.frozen_bns = new_bns\n",
        "            else:\n",
        "                print(\"  Edit was invalid or a no-op. Restoring pre-edit model.\")\n",
        "                self.target_cnn = pre_edit_model_backup\n",
        "\n",
        "                del self.opt_target, self.sched_target; gc.collect(); torch.cuda.empty_cache()\n",
        "                self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "                self.amp_scaler = torch.amp.GradScaler(enabled=(self.device.type=='cuda'))\n",
        "\n",
        "            post_epochs = int(BASE_POST_EPOCHS * max(1.0, param_ratio))\n",
        "            post_epochs = min(post_epochs, 100)\n",
        "            print(f\"  Training for {post_epochs} post-edit epochs.\")\n",
        "            self.sched_target = CosineAnnealingLR(self.opt_target, T_max=post_epochs)\n",
        "\n",
        "            for post_ep in range(post_epochs):\n",
        "                train_loss, train_acc = self._train_target_one_epoch(self.train_loader,self.opt_target, self.sched_target, f\"PostE{post_ep+1}\", current_epoch=post_ep)\n",
        "                if (post_ep + 1) % 5 == 0 or post_ep == post_epochs - 1:\n",
        "                    print(f\"  PostE{post_ep+1}: TrainL={train_loss:.4f}, TrainA={train_acc:.4f}\")\n",
        "            val_loss_a, acc_a = self._validate_target(self.val_loader)\n",
        "            print(f\"PostVal: ValidL={val_loss_a:.4f}, ValidA={acc_a:.4f}\")\n",
        "\n",
        "            new_best_found = False\n",
        "            if acc_a > self.best_global_accuracy:\n",
        "                print(f\"  *** New Best Global Accuracy! {self.best_global_accuracy:.4f} -> {acc_a:.4f} ***\")\n",
        "                self.best_global_accuracy = acc_a\n",
        "                if self.best_global_model is not None:\n",
        "                    del self.best_global_model\n",
        "                self.best_global_model = copy.deepcopy(self.target_cnn)\n",
        "                self.iterations_without_improvement = 0\n",
        "                new_best_found = True\n",
        "            else:\n",
        "                self.iterations_without_improvement += 1\n",
        "                print(f\"  No improvement for {self.iterations_without_improvement} iterations.\")\n",
        "\n",
        "            reward = 100 * (acc_a - acc_b)\n",
        "            penalty = 0.0\n",
        "            current_params = sum(p.numel() for p in self.target_cnn.parameters())\n",
        "            if current_params > COMPLEXITY_PENALTY_THRESHOLD:\n",
        "                excess_params_M = (current_params - COMPLEXITY_PENALTY_THRESHOLD) / 1e6\n",
        "                penalty = (excess_params_M ** 2) * COMPLEXITY_PENALTY_ALPHA\n",
        "\n",
        "            final_reward = reward - penalty\n",
        "            print(f\"Reward: {reward:.4f} | Penalty: {penalty:.2f} | Final Reward: {final_reward:.4f}\")\n",
        "\n",
        "            advantage = final_reward - val_p.detach().squeeze().item()\n",
        "            actor_loss = -(lp_t)*advantage\n",
        "            critic_loss = F.mse_loss(val_p.squeeze(), torch.tensor(final_reward, device=self.device, dtype=torch.float32))\n",
        "            meta_loss=actor_loss.mean()+ 0.5 * critic_loss - 0.0005*(en_t)\n",
        "            if torch.isnan(meta_loss)or torch.isinf(meta_loss):\n",
        "                print(\"MetaLoss NaN/Inf! Skipping meta-update.\"); gc.collect(); continue\n",
        "\n",
        "            progress = (max(0, acc_a - LR_ACC_BASE_THRESHOLD)) / max(1e-6, LR_ACC_TARGET_THRESHOLD - LR_ACC_BASE_THRESHOLD)\n",
        "            progress = min(1.0, progress)\n",
        "            new_meta_lr = BASE_META_LR - progress * (BASE_META_LR - MIN_META_LR)\n",
        "            for param_group in self.opt_meta.param_groups: param_group['lr'] = new_meta_lr\n",
        "\n",
        "            self.opt_meta.zero_grad(); meta_loss.backward(); clip_grad_norm_(self.meta_agent.parameters(),MAX_GRAD_NORM); self.opt_meta.step()\n",
        "            print(f\"MetaL:{meta_loss.item():.4f}(A:{actor_loss.mean().item():.4f},C:{critic_loss.item():.4f},E:{en_t.item():.4f}) | MetaLR: {new_meta_lr:.2e}\")\n",
        "\n",
        "            if self.iterations_without_improvement >= 5:\n",
        "                print(\"\\n!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\")\n",
        "\n",
        "                print(f\"  Reverting Target CNN to best known model (Acc: {self.best_global_accuracy:.4f}).\")\n",
        "                if self.best_global_model is not None:\n",
        "                    self.target_cnn = copy.deepcopy(self.best_global_model)\n",
        "                    del self.opt_target; gc.collect()\n",
        "                    self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "\n",
        "                print(\"  Attempting to upgrade (grow) Meta-Agent...\")\n",
        "                growth_actions = [META_EDIT_DEEPEN_GNN, META_EDIT_WIDEN_GNN_HIDDEN, META_EDIT_DEEPEN_MLP_HEAD]\n",
        "                valid_growth_actions = [a for a in growth_actions if a not in _invalid_meta_indices(self.meta_agent)]\n",
        "\n",
        "                if valid_growth_actions:\n",
        "                    chosen_self_edit = np.random.choice(valid_growth_actions)\n",
        "                    self._apply_meta_self_edit(torch.tensor(chosen_self_edit, device=self.device))\n",
        "                else:\n",
        "                    print(\"  Meta-Agent cannot grow further. No self-edit possible.\")\n",
        "\n",
        "                self.iterations_without_improvement = 0\n",
        "                print(\"  Stagnation counter reset. Continuing search with upgraded agent.\\n\")\n",
        "\n",
        "            revert_threshold = 0.04\n",
        "            if self.best_global_model is not None and acc_a < (self.best_global_accuracy - revert_threshold) and not new_best_found:\n",
        "                print(f\"  !!! Accuracy dropped by >{revert_threshold:.0%}. Reverting to the global best model (Acc: {self.best_global_accuracy:.4f}). !!!\")\n",
        "\n",
        "                del self.target_cnn; gc.collect()\n",
        "                self.target_cnn = copy.deepcopy(self.best_global_model)\n",
        "\n",
        "                del self.opt_target, self.sched_target; gc.collect()\n",
        "                self.opt_target = optim.AdamW(self.target_cnn.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "                self.sched_target = CosineAnnealingLR(self.opt_target, T_max=BASE_POST_EPOCHS)\n",
        "                self.amp_scaler = torch.amp.GradScaler(enabled=(self.device.type=='cuda'))\n",
        "\n",
        "            gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY3Awdagg28s",
        "outputId": "d03cb025-c3df-4c9d-bfd6-f13c3d62df3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model checkpoints will be saved to: /content/drive/My Drive/DEITI_Checkpoints\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 4 workers for data loading (persistent: True).\n",
            "\n",
            "\n",
            "==================== STAGE 1: BROAD SEARCH ====================\n",
            "Init TargetCNN P: 373,834\n",
            "Init MetaAgentGNN: L=2,H=32,P=3,059\n",
            "\n",
            "--- Initial Validation ---\n",
            "InitVal: L=2.3016,A=0.1400\n",
            "\n",
            "===== Iteration 1/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.1400\n",
            "PreVal: ValidL=1.4054, ValidA=0.4963\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 392,730 (Ratio: 1.05)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=1.3996, TrainA=0.5050\n",
            "  PostE10: TrainL=1.2520, TrainA=0.5612\n",
            "  PostE15: TrainL=1.1563, TrainA=0.5950\n",
            "  PostE20: TrainL=1.0834, TrainA=0.6234\n",
            "  PostE25: TrainL=1.0494, TrainA=0.6370\n",
            "  PostE26: TrainL=1.0438, TrainA=0.6387\n",
            "PostVal: ValidL=0.6692, ValidA=0.7682\n",
            "  *** New Best Global Accuracy! 0.1400 -> 0.7682 ***\n",
            "Reward: 27.1935 | Penalty: 0.00 | Final Reward: 27.1935\n",
            "MetaL:501.4647(A:136.1982,C:730.5370,E:4.1394) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 2/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.7682\n",
            "PreVal: ValidL=0.6695, ValidA=0.7690\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 459,034 (Ratio: 1.17)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 29 post-edit epochs.\n",
            "  PostE5: TrainL=1.0911, TrainA=0.6163\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.9990, TrainA=0.6478\n",
            "  PostE15: TrainL=0.9203, TrainA=0.6769\n",
            "  PostE20: TrainL=0.8502, TrainA=0.6990\n",
            "  PostE25: TrainL=0.8097, TrainA=0.7166\n",
            "  PostE29: TrainL=0.8041, TrainA=0.7184\n",
            "PostVal: ValidL=0.4428, ValidA=0.8451\n",
            "  *** New Best Global Accuracy! 0.7682 -> 0.8451 ***\n",
            "Reward: 7.6022 | Penalty: 0.00 | Final Reward: 7.6022\n",
            "MetaL:37.6048(A:10.3774,C:54.4563,E:1.3822) | MetaLR: 3.30e-04\n",
            "\n",
            "===== Iteration 3/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.8451\n",
            "PreVal: ValidL=0.4424, ValidA=0.8453\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=1\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.9052, TrainA=0.6805\n",
            "  PostE10: TrainL=0.8496, TrainA=0.7022\n",
            "  PostE15: TrainL=0.7877, TrainA=0.7221\n",
            "  PostE20: TrainL=0.7444, TrainA=0.7383\n",
            "  PostE25: TrainL=0.7222, TrainA=0.7482\n",
            "PostVal: ValidL=0.3866, ValidA=0.8699\n",
            "  *** New Best Global Accuracy! 0.8451 -> 0.8699 ***\n",
            "Reward: 2.4639 | Penalty: 0.00 | Final Reward: 2.4639\n",
            "MetaL:9.8963(A:7.8704,C:4.0561,E:4.2495) | MetaLR: 2.37e-04\n",
            "\n",
            "===== Iteration 4/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.8699\n",
            "PreVal: ValidL=0.3862, ValidA=0.8693\n",
            "TargEdit:Typ=0 Stg=2 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 1,049,370 (Ratio: 2.29)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 57 post-edit epochs.\n",
            "  PostE5: TrainL=0.8154, TrainA=0.7139\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.8100, TrainA=0.7146\n",
            "  PostE15: TrainL=0.7565, TrainA=0.7350\n",
            "  PostE20: TrainL=0.7203, TrainA=0.7489\n",
            "  PostE25: TrainL=0.6816, TrainA=0.7627\n",
            "  PostE30: TrainL=0.6408, TrainA=0.7747\n",
            "  PostE35: TrainL=0.6056, TrainA=0.7877\n",
            "  PostE40: TrainL=0.5827, TrainA=0.7959\n",
            "  PostE45: TrainL=0.5488, TrainA=0.8073\n",
            "  PostE50: TrainL=0.5289, TrainA=0.8148\n",
            "  PostE55: TrainL=0.5075, TrainA=0.8228\n",
            "  PostE57: TrainL=0.5079, TrainA=0.8216\n",
            "PostVal: ValidL=0.2683, ValidA=0.9071\n",
            "  *** New Best Global Accuracy! 0.8699 -> 0.9071 ***\n",
            "Reward: 3.7760 | Penalty: 0.00 | Final Reward: 3.7760\n",
            "MetaL:20.6297(A:15.3608,C:10.5412,E:3.3869) | MetaLR: 9.65e-05\n",
            "\n",
            "===== Iteration 5/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9071\n",
            "PreVal: ValidL=0.2663, ValidA=0.9075\n",
            "TargEdit:Typ=1 Stg=2 Op=0,RszF=0.25\n",
            "  TargetCNN arch changed. New Params: 385,434 (Ratio: 0.37)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.7703, TrainA=0.7314\n",
            "  PostE10: TrainL=0.7184, TrainA=0.7494\n",
            "  PostE15: TrainL=0.6599, TrainA=0.7676\n",
            "  PostE20: TrainL=0.6230, TrainA=0.7832\n",
            "  PostE25: TrainL=0.5961, TrainA=0.7922\n",
            "PostVal: ValidL=0.3098, ValidA=0.8936\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -1.3822 | Penalty: 0.00 | Final Reward: -1.3822\n",
            "MetaL:-6.8065(A:-8.5118,C:3.4154,E:4.8624) | MetaLR: 1.47e-04\n",
            "\n",
            "===== Iteration 6/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9071\n",
            "PreVal: ValidL=0.3084, ValidA=0.8938\n",
            "TargEdit:Typ=1 Stg=2 Op=0,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 440,762 (Ratio: 1.14)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 28 post-edit epochs.\n",
            "  PostE5: TrainL=0.6941, TrainA=0.7577\n",
            "  PostE10: TrainL=0.6529, TrainA=0.7730\n",
            "  PostE15: TrainL=0.6128, TrainA=0.7867\n",
            "  PostE20: TrainL=0.5803, TrainA=0.7954\n",
            "  PostE25: TrainL=0.5509, TrainA=0.8081\n",
            "  PostE28: TrainL=0.5473, TrainA=0.8100\n",
            "PostVal: ValidL=0.2843, ValidA=0.9049\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 1.1118 | Penalty: 0.00 | Final Reward: 1.1118\n",
            "MetaL:2.9630(A:2.7622,C:0.4063,E:4.8490) | MetaLR: 1.04e-04\n",
            "\n",
            "===== Iteration 7/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9071\n",
            "PreVal: ValidL=0.2842, ValidA=0.9046\n",
            "TargEdit:Typ=0 Stg=0 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 648,442 (Ratio: 1.47)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 36 post-edit epochs.\n",
            "  PostE5: TrainL=0.6869, TrainA=0.7604\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.6645, TrainA=0.7643\n",
            "  PostE15: TrainL=0.6366, TrainA=0.7770\n",
            "  PostE20: TrainL=0.5948, TrainA=0.7920\n",
            "  PostE25: TrainL=0.5494, TrainA=0.8080\n",
            "  PostE30: TrainL=0.5126, TrainA=0.8223\n",
            "  PostE35: TrainL=0.4911, TrainA=0.8283\n",
            "  PostE36: TrainL=0.4847, TrainA=0.8292\n",
            "PostVal: ValidL=0.2613, ValidA=0.9140\n",
            "  *** New Best Global Accuracy! 0.9071 -> 0.9140 ***\n",
            "Reward: 0.9315 | Penalty: 0.00 | Final Reward: 0.9315\n",
            "MetaL:1.5237(A:1.4009,C:0.2491,E:3.3405) | MetaLR: 7.04e-05\n",
            "\n",
            "===== Iteration 8/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9140\n",
            "PreVal: ValidL=0.2620, ValidA=0.9132\n",
            "TargEdit:Typ=0 Stg=0 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 879,162 (Ratio: 1.36)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 33 post-edit epochs.\n",
            "  PostE5: TrainL=0.5967, TrainA=0.7916\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.5897, TrainA=0.7922\n",
            "  PostE15: TrainL=0.5469, TrainA=0.8100\n",
            "  PostE20: TrainL=0.5100, TrainA=0.8187\n",
            "  PostE25: TrainL=0.4591, TrainA=0.8399\n",
            "  PostE30: TrainL=0.4394, TrainA=0.8460\n",
            "  PostE33: TrainL=0.4249, TrainA=0.8514\n",
            "PostVal: ValidL=0.2402, ValidA=0.9211\n",
            "  *** New Best Global Accuracy! 0.9140 -> 0.9211 ***\n",
            "Reward: 0.7913 | Penalty: 0.00 | Final Reward: 0.7913\n",
            "MetaL:1.5265(A:1.4695,C:0.1174,E:3.3710) | MetaLR: 4.36e-05\n",
            "\n",
            "===== Iteration 9/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9211\n",
            "PreVal: ValidL=0.2405, ValidA=0.9214\n",
            "TargEdit:Typ=2 Stg=2 Src=-1->Dest=2\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.5134, TrainA=0.8193\n",
            "  PostE10: TrainL=0.4781, TrainA=0.8328\n",
            "  PostE15: TrainL=0.4321, TrainA=0.8467\n",
            "  PostE20: TrainL=0.3951, TrainA=0.8617\n",
            "  PostE25: TrainL=0.3872, TrainA=0.8639\n",
            "PostVal: ValidL=0.2320, ValidA=0.9241\n",
            "  *** New Best Global Accuracy! 0.9211 -> 0.9241 ***\n",
            "Reward: 0.2704 | Penalty: 0.00 | Final Reward: 0.2704\n",
            "MetaL:-0.6361(A:-0.6401,C:0.0134,E:5.4530) | MetaLR: 3.23e-05\n",
            "\n",
            "===== Iteration 10/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9241\n",
            "PreVal: ValidL=0.2297, ValidA=0.9239\n",
            "TargEdit:Typ=1 Stg=0 Op=4,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 1,052,122 (Ratio: 1.20)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 29 post-edit epochs.\n",
            "  PostE5: TrainL=0.4771, TrainA=0.8334\n",
            "  PostE10: TrainL=0.4527, TrainA=0.8410\n",
            "  PostE15: TrainL=0.4266, TrainA=0.8508\n",
            "  PostE20: TrainL=0.3923, TrainA=0.8621\n",
            "  PostE25: TrainL=0.3632, TrainA=0.8729\n",
            "  PostE29: TrainL=0.3579, TrainA=0.8749\n",
            "PostVal: ValidL=0.2180, ValidA=0.9281\n",
            "  *** New Best Global Accuracy! 0.9241 -> 0.9281 ***\n",
            "Reward: 0.4207 | Penalty: 0.00 | Final Reward: 0.4207\n",
            "MetaL:-0.0181(A:-0.0155,C:0.0000,E:5.2526) | MetaLR: 1.72e-05\n",
            "\n",
            "===== Iteration 11/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9281\n",
            "PreVal: ValidL=0.2183, ValidA=0.9280\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 1,118,426 (Ratio: 1.06)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.4633, TrainA=0.8381\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.4387, TrainA=0.8466\n",
            "  PostE15: TrainL=0.3918, TrainA=0.8621\n",
            "  PostE20: TrainL=0.3555, TrainA=0.8741\n",
            "  PostE25: TrainL=0.3387, TrainA=0.8823\n",
            "  PostE26: TrainL=0.3361, TrainA=0.8833\n",
            "PostVal: ValidL=0.2229, ValidA=0.9298\n",
            "  *** New Best Global Accuracy! 0.9281 -> 0.9298 ***\n",
            "Reward: 0.1803 | Penalty: 0.00 | Final Reward: 0.1803\n",
            "MetaL:-0.3818(A:-0.4122,C:0.0622,E:1.3678) | MetaLR: 1.08e-05\n",
            "\n",
            "===== Iteration 12/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9298\n",
            "PreVal: ValidL=0.2201, ValidA=0.9305\n",
            "TargEdit:Typ=1 Stg=1 Op=0,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 1,187,610 (Ratio: 1.06)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.4390, TrainA=0.8454\n",
            "  PostE10: TrainL=0.4094, TrainA=0.8572\n",
            "  PostE15: TrainL=0.3677, TrainA=0.8718\n",
            "  PostE20: TrainL=0.3392, TrainA=0.8811\n",
            "  PostE25: TrainL=0.3202, TrainA=0.8886\n",
            "  PostE26: TrainL=0.3249, TrainA=0.8870\n",
            "PostVal: ValidL=0.2185, ValidA=0.9319\n",
            "  *** New Best Global Accuracy! 0.9298 -> 0.9319 ***\n",
            "Reward: 0.1402 | Penalty: 0.00 | Final Reward: 0.1402\n",
            "MetaL:-1.2381(A:-1.2862,C:0.1004,E:4.1426) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 13/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9319\n",
            "PreVal: ValidL=0.2151, ValidA=0.9323\n",
            "TargEdit:Typ=2 Stg=1 Src=1->Dest=2\n",
            "  TargetCNN arch changed. New Params: 1,187,610 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4382, TrainA=0.8467\n",
            "  PostE10: TrainL=0.4079, TrainA=0.8560\n",
            "  PostE15: TrainL=0.3671, TrainA=0.8728\n",
            "  PostE20: TrainL=0.3379, TrainA=0.8822\n",
            "  PostE25: TrainL=0.3185, TrainA=0.8881\n",
            "PostVal: ValidL=0.2171, ValidA=0.9312\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.1102 | Penalty: 0.00 | Final Reward: -0.1102\n",
            "MetaL:-1.8711(A:-2.0263,C:0.3146,E:4.2116) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 14/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9319\n",
            "PreVal: ValidL=0.2156, ValidA=0.9315\n",
            "TargEdit:Typ=0 Stg=2 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 1,450,010 (Ratio: 1.22)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 30 post-edit epochs.\n",
            "  PostE5: TrainL=0.4641, TrainA=0.8382\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.4421, TrainA=0.8465\n",
            "  PostE15: TrainL=0.4154, TrainA=0.8546\n",
            "  PostE20: TrainL=0.3861, TrainA=0.8646\n",
            "  PostE25: TrainL=0.3417, TrainA=0.8807\n",
            "  PostE30: TrainL=0.3184, TrainA=0.8896\n",
            "PostVal: ValidL=0.2099, ValidA=0.9342\n",
            "  *** New Best Global Accuracy! 0.9319 -> 0.9342 ***\n",
            "Reward: 0.2704 | Penalty: 0.00 | Final Reward: 0.2704\n",
            "MetaL:-0.8817(A:-0.9000,C:0.0399,E:3.2872) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 15/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9342\n",
            "PreVal: ValidL=0.2095, ValidA=0.9326\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=2\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4038, TrainA=0.8592\n",
            "  PostE10: TrainL=0.3665, TrainA=0.8725\n",
            "  PostE15: TrainL=0.3318, TrainA=0.8842\n",
            "  PostE20: TrainL=0.2999, TrainA=0.8957\n",
            "  PostE25: TrainL=0.2912, TrainA=0.8994\n",
            "PostVal: ValidL=0.2053, ValidA=0.9378\n",
            "  *** New Best Global Accuracy! 0.9342 -> 0.9378 ***\n",
            "Reward: 0.5208 | Penalty: 0.00 | Final Reward: 0.5208\n",
            "MetaL:0.2554(A:0.2559,C:0.0038,E:4.7198) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 16/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9378\n",
            "PreVal: ValidL=0.2056, ValidA=0.9389\n",
            "TargEdit:Typ=1 Stg=2 Op=3,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 1,689,882 (Ratio: 1.17)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 29 post-edit epochs.\n",
            "  PostE5: TrainL=0.3822, TrainA=0.8673\n",
            "  PostE10: TrainL=0.3572, TrainA=0.8768\n",
            "  PostE15: TrainL=0.3284, TrainA=0.8867\n",
            "  PostE20: TrainL=0.2899, TrainA=0.8982\n",
            "  PostE25: TrainL=0.2716, TrainA=0.9049\n",
            "  PostE29: TrainL=0.2653, TrainA=0.9070\n",
            "PostVal: ValidL=0.1997, ValidA=0.9414\n",
            "  *** New Best Global Accuracy! 0.9378 -> 0.9414 ***\n",
            "Reward: 0.2504 | Penalty: 0.00 | Final Reward: 0.2504\n",
            "MetaL:-1.0314(A:-1.0533,C:0.0491,E:5.2199) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 17/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9414\n",
            "PreVal: ValidL=0.1992, ValidA=0.9408\n",
            "TargEdit:Typ=2 Stg=1 Src=0->Dest=2\n",
            "  TargetCNN arch changed. New Params: 1,689,882 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3665, TrainA=0.8722\n",
            "  PostE10: TrainL=0.3426, TrainA=0.8817\n",
            "  PostE15: TrainL=0.3067, TrainA=0.8927\n",
            "  PostE20: TrainL=0.2793, TrainA=0.9024\n",
            "  PostE25: TrainL=0.2668, TrainA=0.9063\n",
            "PostVal: ValidL=0.1998, ValidA=0.9400\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.0801 | Penalty: 0.00 | Final Reward: -0.0801\n",
            "MetaL:-2.0947(A:-2.2414,C:0.2982,E:4.7188) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 18/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9414\n",
            "PreVal: ValidL=0.1996, ValidA=0.9418\n",
            "TargEdit:Typ=2 Stg=1 Src=3->Dest=4\n",
            "  TargetCNN arch changed. New Params: 1,689,882 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3439, TrainA=0.8798\n",
            "  PostE10: TrainL=0.3241, TrainA=0.8863\n",
            "  PostE15: TrainL=0.2929, TrainA=0.8980\n",
            "  PostE20: TrainL=0.2636, TrainA=0.9084\n",
            "  PostE25: TrainL=0.2525, TrainA=0.9132\n",
            "PostVal: ValidL=0.2014, ValidA=0.9407\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -0.1102 | Penalty: 0.00 | Final Reward: -0.1102\n",
            "MetaL:-2.5550(A:-2.7313,C:0.3577,E:5.1261) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 19/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9414\n",
            "PreVal: ValidL=0.2016, ValidA=0.9401\n",
            "TargEdit:Typ=0 Stg=2 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 2,018,074 (Ratio: 1.19)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 29 post-edit epochs.\n",
            "  PostE5: TrainL=0.3583, TrainA=0.8743\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3328, TrainA=0.8834\n",
            "  PostE15: TrainL=0.2985, TrainA=0.8962\n",
            "  PostE20: TrainL=0.2719, TrainA=0.9052\n",
            "  PostE25: TrainL=0.2504, TrainA=0.9135\n",
            "  PostE29: TrainL=0.2455, TrainA=0.9155\n",
            "PostVal: ValidL=0.1951, ValidA=0.9416\n",
            "  *** New Best Global Accuracy! 0.9414 -> 0.9416 ***\n",
            "Reward: 0.1502 | Penalty: 0.00 | Final Reward: 0.1502\n",
            "MetaL:-1.0729(A:-1.1275,C:0.1124,E:3.1935) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 20/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9416\n",
            "PreVal: ValidL=0.1960, ValidA=0.9415\n",
            "TargEdit:Typ=0 Stg=1 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 2,075,834 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3790, TrainA=0.8670\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3354, TrainA=0.8826\n",
            "  PostE15: TrainL=0.2963, TrainA=0.8978\n",
            "  PostE20: TrainL=0.2613, TrainA=0.9086\n",
            "  PostE25: TrainL=0.2486, TrainA=0.9134\n",
            "PostVal: ValidL=0.1937, ValidA=0.9418\n",
            "  *** New Best Global Accuracy! 0.9416 -> 0.9418 ***\n",
            "Reward: 0.0300 | Penalty: 0.00 | Final Reward: 0.0300\n",
            "MetaL:-1.8502(A:-1.9532,C:0.2091,E:3.1860) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 21/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9418\n",
            "PreVal: ValidL=0.1957, ValidA=0.9424\n",
            "TargEdit:Typ=2 Stg=1 Src=0->Dest=2\n",
            "  TargetCNN arch changed. New Params: 2,075,994 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4290, TrainA=0.8478\n",
            "  PostE10: TrainL=0.3794, TrainA=0.8662\n",
            "  PostE15: TrainL=0.3239, TrainA=0.8865\n",
            "  PostE20: TrainL=0.2893, TrainA=0.8991\n",
            "  PostE25: TrainL=0.2711, TrainA=0.9049\n",
            "PostVal: ValidL=0.1866, ValidA=0.9404\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.2003 | Penalty: 0.00 | Final Reward: -0.2003\n",
            "MetaL:-3.2348(A:-3.4680,C:0.4721,E:5.7031) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 22/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9418\n",
            "PreVal: ValidL=0.1883, ValidA=0.9396\n",
            "TargEdit:Typ=0 Stg=1 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 2,249,114 (Ratio: 1.08)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 27 post-edit epochs.\n",
            "  PostE5: TrainL=0.3886, TrainA=0.8647\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3436, TrainA=0.8792\n",
            "  PostE15: TrainL=0.3047, TrainA=0.8932\n",
            "  PostE20: TrainL=0.2678, TrainA=0.9063\n",
            "  PostE25: TrainL=0.2480, TrainA=0.9128\n",
            "  PostE27: TrainL=0.2456, TrainA=0.9149\n",
            "PostVal: ValidL=0.1821, ValidA=0.9443\n",
            "  *** New Best Global Accuracy! 0.9418 -> 0.9443 ***\n",
            "Reward: 0.4708 | Penalty: 0.00 | Final Reward: 0.4708\n",
            "MetaL:-0.0693(A:-0.0680,C:0.0006,E:3.1381) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 23/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9443\n",
            "PreVal: ValidL=0.1839, ValidA=0.9443\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,315,418 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3565, TrainA=0.8763\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3241, TrainA=0.8875\n",
            "  PostE15: TrainL=0.2827, TrainA=0.9013\n",
            "  PostE20: TrainL=0.2496, TrainA=0.9142\n",
            "  PostE25: TrainL=0.2314, TrainA=0.9188\n",
            "PostVal: ValidL=0.1933, ValidA=0.9453\n",
            "  *** New Best Global Accuracy! 0.9443 -> 0.9453 ***\n",
            "Reward: 0.1002 | Penalty: 0.00 | Final Reward: 0.1002\n",
            "MetaL:-0.6202(A:-0.7021,C:0.1651,E:1.3542) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 24/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9453\n",
            "PreVal: ValidL=0.1919, ValidA=0.9448\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=1.75\n",
            "  TargetCNN arch changed. New Params: 2,868,570 (Ratio: 1.24)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 30 post-edit epochs.\n",
            "  PostE5: TrainL=0.3254, TrainA=0.8871\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  PostE10: TrainL=0.3345, TrainA=0.8835\n",
            "  PostE15: TrainL=0.3097, TrainA=0.8928\n",
            "  PostE20: TrainL=0.2738, TrainA=0.9041\n",
            "  PostE25: TrainL=0.2451, TrainA=0.9145\n",
            "  PostE30: TrainL=0.2175, TrainA=0.9246\n",
            "PostVal: ValidL=0.1916, ValidA=0.9461\n",
            "  *** New Best Global Accuracy! 0.9453 -> 0.9461 ***\n",
            "Reward: 0.1302 | Penalty: 0.00 | Final Reward: 0.1302\n",
            "MetaL:-2.0993(A:-2.1697,C:0.1463,E:5.4357) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 25/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9461\n",
            "PreVal: ValidL=0.1858, ValidA=0.9476\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=0.75\n",
            "  TargetCNN arch changed. New Params: 2,545,898 (Ratio: 0.89)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3131, TrainA=0.8911\n",
            "  PostE10: TrainL=0.2858, TrainA=0.9006\n",
            "  PostE15: TrainL=0.2485, TrainA=0.9126\n",
            "  PostE20: TrainL=0.2163, TrainA=0.9244\n",
            "  PostE25: TrainL=0.2066, TrainA=0.9287\n",
            "PostVal: ValidL=0.1955, ValidA=0.9475\n",
            "  *** New Best Global Accuracy! 0.9461 -> 0.9475 ***\n",
            "Reward: -0.0100 | Penalty: 0.00 | Final Reward: -0.0100\n",
            "MetaL:-3.1647(A:-3.2918,C:0.2596,E:5.4198) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 26/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9475\n",
            "PreVal: ValidL=0.1930, ValidA=0.9485\n",
            "TargEdit:Typ=2 Stg=2 Src=5->Dest=7\n",
            "  TargetCNN arch changed. New Params: 2,610,570 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3216, TrainA=0.8891\n",
            "  PostE10: TrainL=0.2879, TrainA=0.9001\n",
            "  PostE15: TrainL=0.2521, TrainA=0.9123\n",
            "  PostE20: TrainL=0.2192, TrainA=0.9230\n",
            "  PostE25: TrainL=0.2081, TrainA=0.9283\n",
            "PostVal: ValidL=0.1835, ValidA=0.9492\n",
            "  *** New Best Global Accuracy! 0.9475 -> 0.9492 ***\n",
            "Reward: 0.0701 | Penalty: 0.00 | Final Reward: 0.0701\n",
            "MetaL:-3.0215(A:-3.1284,C:0.2204,E:6.7590) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 27/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.1810, ValidA=0.9498\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,676,874 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3081, TrainA=0.8947\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2839, TrainA=0.9016\n",
            "  PostE15: TrainL=0.2495, TrainA=0.9122\n",
            "  PostE20: TrainL=0.2139, TrainA=0.9254\n",
            "  PostE25: TrainL=0.2033, TrainA=0.9296\n",
            "PostVal: ValidL=0.1936, ValidA=0.9479\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.1903 | Penalty: 0.00 | Final Reward: -0.1903\n",
            "MetaL:-1.0251(A:-1.2889,C:0.5289,E:1.3393) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 28/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.1917, ValidA=0.9484\n",
            "TargEdit:Typ=2 Stg=0 Src=6->Dest=9\n",
            "  TargetCNN arch changed. New Params: 2,715,594 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3305, TrainA=0.8849\n",
            "  PostE10: TrainL=0.2893, TrainA=0.9000\n",
            "  PostE15: TrainL=0.2434, TrainA=0.9156\n",
            "  PostE20: TrainL=0.2119, TrainA=0.9259\n",
            "  PostE25: TrainL=0.1981, TrainA=0.9317\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.8417 | Penalty: 0.00 | Final Reward: -94.8417\n",
            "MetaL:4007.5234(A:-544.1631,C:9103.3789,E:5.6924) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9492). !!!\n",
            "\n",
            "===== Iteration 29/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2308, ValidA=0.9300\n",
            "TargEdit:Typ=0 Stg=0 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 3,302,410 (Ratio: 1.27)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 31 post-edit epochs.\n",
            "  PostE5: TrainL=0.3357, TrainA=0.8834\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3181, TrainA=0.8884\n",
            "  PostE15: TrainL=0.2982, TrainA=0.8960\n",
            "  PostE20: TrainL=0.2628, TrainA=0.9081\n",
            "  PostE25: TrainL=0.2343, TrainA=0.9182\n",
            "  PostE30: TrainL=0.2037, TrainA=0.9304\n",
            "  PostE31: TrainL=0.2039, TrainA=0.9285\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -92.9988 | Penalty: 0.00 | Final Reward: -92.9988\n",
            "MetaL:4109.2075(A:-262.8628,C:8744.1436,E:2.9807) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9492). !!!\n",
            "\n",
            "===== Iteration 30/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2348, ValidA=0.9331\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,676,874 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3185, TrainA=0.8899\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2814, TrainA=0.9011\n",
            "  PostE15: TrainL=0.2507, TrainA=0.9125\n",
            "  PostE20: TrainL=0.2143, TrainA=0.9257\n",
            "  PostE25: TrainL=0.2028, TrainA=0.9295\n",
            "PostVal: ValidL=0.1885, ValidA=0.9474\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 1.4323 | Penalty: 0.00 | Final Reward: 1.4323\n",
            "MetaL:2.0691(A:1.6405,C:0.8587,E:1.3406) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 31/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.1911, ValidA=0.9481\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 2,720,654 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2933, TrainA=0.8995\n",
            "  PostE10: TrainL=0.2667, TrainA=0.9063\n",
            "  PostE15: TrainL=0.2341, TrainA=0.9192\n",
            "  PostE20: TrainL=0.2115, TrainA=0.9275\n",
            "  PostE25: TrainL=0.1971, TrainA=0.9319\n",
            "PostVal: ValidL=0.1851, ValidA=0.9488\n",
            "  No improvement for 5 iterations.\n",
            "Reward: 0.0701 | Penalty: 0.00 | Final Reward: 0.0701\n",
            "MetaL:-2.2081(A:-2.3067,C:0.2021,E:5.1075) | MetaLR: 1.00e-05\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9492).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_resize_factor' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 3101. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 32/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,101\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2530, ValidA=0.9286\n",
            "TargEdit:Typ=2 Stg=2 Src=3->Dest=4\n",
            "  TargetCNN arch changed. New Params: 3,141,434 (Ratio: 1.20)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 30 post-edit epochs.\n",
            "  PostE5: TrainL=0.3944, TrainA=0.8619\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  PostE10: TrainL=0.3574, TrainA=0.8752\n",
            "  PostE15: TrainL=0.3276, TrainA=0.8847\n",
            "  PostE20: TrainL=0.2944, TrainA=0.8975\n",
            "  PostE25: TrainL=0.2593, TrainA=0.9078\n",
            "  PostE30: TrainL=0.2429, TrainA=0.9159\n",
            "PostVal: ValidL=0.1983, ValidA=0.9398\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 1.1218 | Penalty: 0.00 | Final Reward: 1.1218\n",
            "MetaL:4.3703(A:4.1862,C:0.3751,E:6.8932) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 33/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,101\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2009, ValidA=0.9399\n",
            "TargEdit:Typ=2 Stg=2 Src=-1->Dest=5\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3171, TrainA=0.8896\n",
            "  PostE10: TrainL=0.2893, TrainA=0.8993\n",
            "  PostE15: TrainL=0.2572, TrainA=0.9100\n",
            "  PostE20: TrainL=0.2366, TrainA=0.9179\n",
            "  PostE25: TrainL=0.2240, TrainA=0.9225\n",
            "PostVal: ValidL=0.1972, ValidA=0.9423\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.2404 | Penalty: 0.00 | Final Reward: 0.2404\n",
            "MetaL:-1.8059(A:-1.8356,C:0.0664,E:7.0392) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 34/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,101\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2003, ValidA=0.9429\n",
            "TargEdit:Typ=1 Stg=0 Op=7,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 3,285,514 (Ratio: 1.05)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2967, TrainA=0.8967\n",
            "  PostE10: TrainL=0.2764, TrainA=0.9037\n",
            "  PostE15: TrainL=0.2515, TrainA=0.9123\n",
            "  PostE20: TrainL=0.2242, TrainA=0.9225\n",
            "  PostE25: TrainL=0.2125, TrainA=0.9262\n",
            "  PostE26: TrainL=0.2186, TrainA=0.9248\n",
            "PostVal: ValidL=0.1937, ValidA=0.9431\n",
            "  No improvement for 3 iterations.\n",
            "Reward: 0.0200 | Penalty: 0.00 | Final Reward: 0.0200\n",
            "MetaL:-2.4810(A:-2.6079,C:0.2589,E:5.0816) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 35/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,101\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.1969, ValidA=0.9432\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,351,818 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2915, TrainA=0.8989\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2701, TrainA=0.9059\n",
            "  PostE15: TrainL=0.2455, TrainA=0.9140\n",
            "  PostE20: TrainL=0.2252, TrainA=0.9216\n",
            "  PostE25: TrainL=0.2067, TrainA=0.9280\n",
            "PostVal: ValidL=0.2041, ValidA=0.9453\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 0.2103 | Penalty: 0.00 | Final Reward: 0.2103\n",
            "MetaL:-0.5018(A:-0.5489,C:0.0955,E:1.3354) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 36/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,101\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2072, ValidA=0.9445\n",
            "TargEdit:Typ=1 Stg=2 Op=3,RszF=0.25\n",
            "  TargetCNN arch changed. New Params: 1,922,186 (Ratio: 0.57)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3981, TrainA=0.8605\n",
            "  PostE10: TrainL=0.3599, TrainA=0.8747\n",
            "  PostE15: TrainL=0.3223, TrainA=0.8867\n",
            "  PostE20: TrainL=0.2912, TrainA=0.8987\n",
            "  PostE25: TrainL=0.2775, TrainA=0.9034\n",
            "PostVal: ValidL=0.2347, ValidA=0.9323\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -1.2220 | Penalty: 0.00 | Final Reward: -1.2220\n",
            "MetaL:-6.9471(A:-8.5341,C:3.1792,E:5.3330) | MetaLR: 1.00e-05\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9492).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 32 -> 48\n",
            "MetaAgentGNN arch changed. New Params: 4915. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 37/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9492\n",
            "PreVal: ValidL=0.2491, ValidA=0.9309\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,676,874 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3163, TrainA=0.8908\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2826, TrainA=0.9011\n",
            "  PostE15: TrainL=0.2507, TrainA=0.9143\n",
            "  PostE20: TrainL=0.2161, TrainA=0.9248\n",
            "  PostE25: TrainL=0.1994, TrainA=0.9299\n",
            "PostVal: ValidL=0.1867, ValidA=0.9498\n",
            "  *** New Best Global Accuracy! 0.9492 -> 0.9498 ***\n",
            "Reward: 1.8930 | Penalty: 0.00 | Final Reward: 1.8930\n",
            "MetaL:2.6450(A:1.3550,C:2.5813,E:1.2455) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 38/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9498\n",
            "PreVal: ValidL=0.1885, ValidA=0.9498\n",
            "TargEdit:Typ=2 Stg=2 Src=1->Dest=10\n",
            "  TargetCNN arch changed. New Params: 2,697,866 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2981, TrainA=0.8978\n",
            "  PostE10: TrainL=0.2644, TrainA=0.9089\n",
            "  PostE15: TrainL=0.2347, TrainA=0.9180\n",
            "  PostE20: TrainL=0.2070, TrainA=0.9286\n",
            "  PostE25: TrainL=0.1953, TrainA=0.9331\n",
            "PostVal: ValidL=0.1904, ValidA=0.9489\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.0901 | Penalty: 0.00 | Final Reward: -0.0901\n",
            "MetaL:-2.5366(A:-2.6092,C:0.1519,E:6.6158) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 39/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9498\n",
            "PreVal: ValidL=0.1857, ValidA=0.9480\n",
            "TargEdit:Typ=1 Stg=1 Op=0,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 2,784,426 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2825, TrainA=0.9014\n",
            "  PostE10: TrainL=0.2580, TrainA=0.9108\n",
            "  PostE15: TrainL=0.2217, TrainA=0.9231\n",
            "  PostE20: TrainL=0.1999, TrainA=0.9307\n",
            "  PostE25: TrainL=0.1936, TrainA=0.9336\n",
            "PostVal: ValidL=0.1849, ValidA=0.9499\n",
            "  *** New Best Global Accuracy! 0.9498 -> 0.9499 ***\n",
            "Reward: 0.1903 | Penalty: 0.00 | Final Reward: 0.1903\n",
            "MetaL:-0.2847(A:-0.2839,C:0.0034,E:5.0839) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 40/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9499\n",
            "PreVal: ValidL=0.1871, ValidA=0.9490\n",
            "TargEdit:Typ=1 Stg=1 Op=11,RszF=1.25\n",
            "  TargetCNN arch changed. New Params: 2,842,106 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2761, TrainA=0.9032\n",
            "  PostE10: TrainL=0.2497, TrainA=0.9139\n",
            "  PostE15: TrainL=0.2198, TrainA=0.9233\n",
            "  PostE20: TrainL=0.1974, TrainA=0.9323\n",
            "  PostE25: TrainL=0.1801, TrainA=0.9380\n",
            "PostVal: ValidL=0.1929, ValidA=0.9487\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -0.0300 | Penalty: 0.00 | Final Reward: -0.0300\n",
            "MetaL:-1.6618(A:-1.7208,C:0.1231,E:5.0971) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 41/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9499\n",
            "PreVal: ValidL=0.1882, ValidA=0.9491\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,908,410 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2735, TrainA=0.9058\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2490, TrainA=0.9136\n",
            "  PostE15: TrainL=0.2135, TrainA=0.9261\n",
            "  PostE20: TrainL=0.1904, TrainA=0.9341\n",
            "  PostE25: TrainL=0.1792, TrainA=0.9384\n",
            "PostVal: ValidL=0.1855, ValidA=0.9519\n",
            "  *** New Best Global Accuracy! 0.9499 -> 0.9519 ***\n",
            "Reward: 0.2804 | Penalty: 0.00 | Final Reward: 0.2804\n",
            "MetaL:0.0392(A:0.0389,C:0.0019,E:1.2753) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 42/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1887, ValidA=0.9515\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,974,714 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2728, TrainA=0.9067\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2470, TrainA=0.9142\n",
            "  PostE15: TrainL=0.2181, TrainA=0.9243\n",
            "  PostE20: TrainL=0.1863, TrainA=0.9362\n",
            "  PostE25: TrainL=0.1749, TrainA=0.9384\n",
            "PostVal: ValidL=0.1845, ValidA=0.9518\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0300 | Penalty: 0.00 | Final Reward: 0.0300\n",
            "MetaL:-0.1724(A:-0.1965,C:0.0496,E:1.2709) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 43/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1819, ValidA=0.9529\n",
            "TargEdit:Typ=1 Stg=1 Op=11,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,118,914 (Ratio: 1.05)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2615, TrainA=0.9099\n",
            "  PostE10: TrainL=0.2390, TrainA=0.9179\n",
            "  PostE15: TrainL=0.2077, TrainA=0.9285\n",
            "  PostE20: TrainL=0.1866, TrainA=0.9364\n",
            "  PostE25: TrainL=0.1767, TrainA=0.9396\n",
            "  PostE26: TrainL=0.1716, TrainA=0.9391\n",
            "PostVal: ValidL=0.1931, ValidA=0.9510\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -0.1903 | Penalty: 0.00 | Final Reward: -0.1903\n",
            "MetaL:-2.4447(A:-2.5404,C:0.1966,E:5.1074) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 44/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1922, ValidA=0.9505\n",
            "TargEdit:Typ=1 Stg=2 Op=3,RszF=0.75\n",
            "  TargetCNN arch changed. New Params: 2,888,322 (Ratio: 0.93)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2653, TrainA=0.9101\n",
            "  PostE10: TrainL=0.2427, TrainA=0.9159\n",
            "  PostE15: TrainL=0.2203, TrainA=0.9242\n",
            "  PostE20: TrainL=0.1858, TrainA=0.9347\n",
            "  PostE25: TrainL=0.1817, TrainA=0.9355\n",
            "PostVal: ValidL=0.1904, ValidA=0.9504\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -0.0100 | Penalty: 0.00 | Final Reward: -0.0100\n",
            "MetaL:-1.3140(A:-1.3476,C:0.0725,E:5.3842) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 45/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1918, ValidA=0.9498\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=0.5\n",
            "  TargetCNN arch changed. New Params: 2,800,762 (Ratio: 0.97)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2889, TrainA=0.8997\n",
            "  PostE10: TrainL=0.2655, TrainA=0.9103\n",
            "  PostE15: TrainL=0.2342, TrainA=0.9187\n",
            "  PostE20: TrainL=0.2073, TrainA=0.9282\n",
            "  PostE25: TrainL=0.1953, TrainA=0.9318\n",
            "PostVal: ValidL=0.1960, ValidA=0.9475\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -0.2304 | Penalty: 0.00 | Final Reward: -0.2304\n",
            "MetaL:-2.7596(A:-2.8783,C:0.2425,E:5.0904) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 46/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1955, ValidA=0.9475\n",
            "TargEdit:Typ=1 Stg=1 Op=8,RszF=0.25\n",
            "  TargetCNN arch changed. New Params: 2,530,762 (Ratio: 0.90)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3551, TrainA=0.8753\n",
            "  PostE10: TrainL=0.3095, TrainA=0.8921\n",
            "  PostE15: TrainL=0.2758, TrainA=0.9045\n",
            "  PostE20: TrainL=0.2416, TrainA=0.9164\n",
            "  PostE25: TrainL=0.2300, TrainA=0.9195\n",
            "PostVal: ValidL=0.2032, ValidA=0.9433\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -0.4207 | Penalty: 0.00 | Final Reward: -0.4207\n",
            "MetaL:-2.9081(A:-3.1502,C:0.4894,E:5.1013) | MetaLR: 1.00e-05\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9519).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 48 -> 72\n",
            "MetaAgentGNN arch changed. New Params: 8659. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 47/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=72, Params: 8,659\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.2373, ValidA=0.9335\n",
            "TargEdit:Typ=0 Stg=1 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,016,610 (Ratio: 1.04)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2897, TrainA=0.8991\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2534, TrainA=0.9122\n",
            "  PostE15: TrainL=0.2235, TrainA=0.9228\n",
            "  PostE20: TrainL=0.1911, TrainA=0.9339\n",
            "  PostE25: TrainL=0.1833, TrainA=0.9363\n",
            "PostVal: ValidL=0.1882, ValidA=0.9498\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 1.6326 | Penalty: 0.00 | Final Reward: 1.6326\n",
            "MetaL:6.9261(A:5.8719,C:2.1117,E:3.5375) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 48/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=72, Params: 8,659\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1885, ValidA=0.9494\n",
            "TargEdit:Typ=2 Stg=2 Src=5->Dest=10\n",
            "  TargetCNN arch changed. New Params: 3,115,426 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2733, TrainA=0.9061\n",
            "  PostE10: TrainL=0.2420, TrainA=0.9158\n",
            "  PostE15: TrainL=0.2129, TrainA=0.9264\n",
            "  PostE20: TrainL=0.1878, TrainA=0.9351\n",
            "  PostE25: TrainL=0.1730, TrainA=0.9406\n",
            "PostVal: ValidL=0.1841, ValidA=0.9513\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.1903 | Penalty: 0.00 | Final Reward: 0.1903\n",
            "MetaL:-0.0332(A:-0.0297,C:0.0000,E:7.1203) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 49/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=72, Params: 8,659\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1849, ValidA=0.9526\n",
            "TargEdit:Typ=0 Stg=1 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,205,626 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2686, TrainA=0.9068\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2528, TrainA=0.9130\n",
            "  PostE15: TrainL=0.2158, TrainA=0.9235\n",
            "  PostE20: TrainL=0.1878, TrainA=0.9353\n",
            "  PostE25: TrainL=0.1745, TrainA=0.9395\n",
            "PostVal: ValidL=0.1867, ValidA=0.9500\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -0.2604 | Penalty: 0.00 | Final Reward: -0.2604\n",
            "MetaL:-1.4599(A:-1.5611,C:0.2060,E:3.5355) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 50/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=72, Params: 8,659\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1865, ValidA=0.9512\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,271,930 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2654, TrainA=0.9080\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2413, TrainA=0.9158\n",
            "  PostE15: TrainL=0.2097, TrainA=0.9278\n",
            "  PostE20: TrainL=0.1823, TrainA=0.9370\n",
            "  PostE25: TrainL=0.1757, TrainA=0.9404\n",
            "PostVal: ValidL=0.1943, ValidA=0.9509\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -0.0300 | Penalty: 0.00 | Final Reward: -0.0300\n",
            "MetaL:-0.2542(A:-0.2779,C:0.0489,E:1.3816) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 51/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=72, Params: 8,659\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1919, ValidA=0.9510\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,338,234 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2659, TrainA=0.9086\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2365, TrainA=0.9169\n",
            "  PostE15: TrainL=0.2051, TrainA=0.9302\n",
            "  PostE20: TrainL=0.1751, TrainA=0.9401\n",
            "  PostE25: TrainL=0.1721, TrainA=0.9404\n",
            "PostVal: ValidL=0.1900, ValidA=0.9508\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -0.0200 | Penalty: 0.00 | Final Reward: -0.0200\n",
            "MetaL:-0.2625(A:-0.2883,C:0.0529,E:1.3814) | MetaLR: 1.00e-05\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9519).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepening MetaAgentGNN: GNN Layers 2 -> 3\n",
            "MetaAgentGNN arch changed. New Params: 13915. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 52/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.2262, ValidA=0.9378\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 2,974,714 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2679, TrainA=0.9074\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2457, TrainA=0.9156\n",
            "  PostE15: TrainL=0.2129, TrainA=0.9269\n",
            "  PostE20: TrainL=0.1882, TrainA=0.9352\n",
            "  PostE25: TrainL=0.1796, TrainA=0.9381\n",
            "PostVal: ValidL=0.1875, ValidA=0.9513\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 1.3522 | Penalty: 0.00 | Final Reward: 1.3522\n",
            "MetaL:2.1504(A:1.4671,C:1.3680,E:1.3824) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 53/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1901, ValidA=0.9518\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=13\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2568, TrainA=0.9120\n",
            "  PostE10: TrainL=0.2389, TrainA=0.9183\n",
            "  PostE15: TrainL=0.2078, TrainA=0.9276\n",
            "  PostE20: TrainL=0.1865, TrainA=0.9353\n",
            "  PostE25: TrainL=0.1775, TrainA=0.9393\n",
            "PostVal: ValidL=0.1908, ValidA=0.9509\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -0.0901 | Penalty: 0.00 | Final Reward: -0.0901\n",
            "MetaL:-2.1886(A:-2.2358,C:0.1012,E:6.8319) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 54/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1868, ValidA=0.9514\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,041,018 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2594, TrainA=0.9123\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2339, TrainA=0.9207\n",
            "  PostE15: TrainL=0.2075, TrainA=0.9281\n",
            "  PostE20: TrainL=0.1826, TrainA=0.9359\n",
            "  PostE25: TrainL=0.1719, TrainA=0.9408\n",
            "PostVal: ValidL=0.1832, ValidA=0.9512\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -0.0200 | Penalty: 0.00 | Final Reward: -0.0200\n",
            "MetaL:-0.2949(A:-0.3280,C:0.0675,E:1.3832) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 55/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1825, ValidA=0.9511\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,107,322 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2523, TrainA=0.9129\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2337, TrainA=0.9196\n",
            "  PostE15: TrainL=0.2025, TrainA=0.9299\n",
            "  PostE20: TrainL=0.1793, TrainA=0.9376\n",
            "  PostE25: TrainL=0.1715, TrainA=0.9401\n",
            "PostVal: ValidL=0.1910, ValidA=0.9504\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -0.0701 | Penalty: 0.00 | Final Reward: -0.0701\n",
            "MetaL:-0.3441(A:-0.3905,C:0.0941,E:1.3835) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 56/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9519\n",
            "PreVal: ValidL=0.1907, ValidA=0.9512\n",
            "TargEdit:Typ=0 Stg=1 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,215,522 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2716, TrainA=0.9066\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2544, TrainA=0.9110\n",
            "  PostE15: TrainL=0.2108, TrainA=0.9283\n",
            "  PostE20: TrainL=0.1830, TrainA=0.9366\n",
            "  PostE25: TrainL=0.1694, TrainA=0.9420\n",
            "PostVal: ValidL=0.1814, ValidA=0.9527\n",
            "  *** New Best Global Accuracy! 0.9519 -> 0.9527 ***\n",
            "Reward: 0.1502 | Penalty: 0.00 | Final Reward: 0.1502\n",
            "MetaL:-0.3944(A:-0.3974,C:0.0093,E:3.5307) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 57/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9527\n",
            "PreVal: ValidL=0.1801, ValidA=0.9525\n",
            "TargEdit:Typ=2 Stg=1 Src=13->Dest=16\n",
            "  TargetCNN arch changed. New Params: 3,235,722 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2569, TrainA=0.9120\n",
            "  PostE10: TrainL=0.2355, TrainA=0.9180\n",
            "  PostE15: TrainL=0.1997, TrainA=0.9315\n",
            "  PostE20: TrainL=0.1762, TrainA=0.9392\n",
            "  PostE25: TrainL=0.1660, TrainA=0.9418\n",
            "PostVal: ValidL=0.1790, ValidA=0.9533\n",
            "  *** New Best Global Accuracy! 0.9527 -> 0.9533 ***\n",
            "Reward: 0.0801 | Penalty: 0.00 | Final Reward: 0.0801\n",
            "MetaL:-1.2612(A:-1.2722,C:0.0292,E:7.2612) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 58/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1778, ValidA=0.9525\n",
            "TargEdit:Typ=2 Stg=1 Src=11->Dest=16\n",
            "  TargetCNN arch changed. New Params: 3,255,922 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2519, TrainA=0.9140\n",
            "  PostE10: TrainL=0.2290, TrainA=0.9219\n",
            "  PostE15: TrainL=0.1984, TrainA=0.9303\n",
            "  PostE20: TrainL=0.1710, TrainA=0.9399\n",
            "  PostE25: TrainL=0.1638, TrainA=0.9423\n",
            "PostVal: ValidL=0.1825, ValidA=0.9526\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0100 | Penalty: 0.00 | Final Reward: 0.0100\n",
            "MetaL:-1.7399(A:-1.7635,C:0.0545,E:7.3844) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 59/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1814, ValidA=0.9521\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,343,482 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2544, TrainA=0.9127\n",
            "  PostE10: TrainL=0.2235, TrainA=0.9234\n",
            "  PostE15: TrainL=0.1984, TrainA=0.9325\n",
            "  PostE20: TrainL=0.1728, TrainA=0.9408\n",
            "  PostE25: TrainL=0.1596, TrainA=0.9452\n",
            "PostVal: ValidL=0.1893, ValidA=0.9529\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.0801 | Penalty: 0.00 | Final Reward: 0.0801\n",
            "MetaL:-0.6017(A:-0.6126,C:0.0268,E:4.9827) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 60/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1850, ValidA=0.9537\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,409,786 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2397, TrainA=0.9196\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2310, TrainA=0.9202\n",
            "  PostE15: TrainL=0.2124, TrainA=0.9255\n",
            "  PostE20: TrainL=0.2105, TrainA=0.9316\n",
            "  PostE25: TrainL=0.1987, TrainA=0.9332\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -95.3726 | Penalty: 0.00 | Final Reward: -95.3726\n",
            "MetaL:4450.8804(A:-121.1323,C:9144.0264,E:1.3824) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9533). !!!\n",
            "\n",
            "===== Iteration 61/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.2086, ValidA=0.9415\n",
            "TargEdit:Typ=1 Stg=2 Op=0,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,420,282 (Ratio: 1.06)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2502, TrainA=0.9131\n",
            "  PostE10: TrainL=0.2287, TrainA=0.9217\n",
            "  PostE15: TrainL=0.2001, TrainA=0.9314\n",
            "  PostE20: TrainL=0.1757, TrainA=0.9391\n",
            "  PostE25: TrainL=0.1648, TrainA=0.9436\n",
            "  PostE26: TrainL=0.1575, TrainA=0.9449\n",
            "PostVal: ValidL=0.1782, ValidA=0.9531\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 1.1619 | Penalty: 0.00 | Final Reward: 1.1619\n",
            "MetaL:5.3360(A:4.8853,C:0.9066,E:5.2638) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 62/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=72, Params: 13,915\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1790, ValidA=0.9531\n",
            "TargEdit:Typ=0 Stg=0 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 4,169,722 (Ratio: 1.22)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 30 post-edit epochs.\n",
            "  PostE5: TrainL=0.0000, TrainA=0.0000\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE30: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -95.3125 | Penalty: 0.00 | Final Reward: -95.3125\n",
            "MetaL:4213.9482(A:-350.3328,C:9128.5664,E:3.5298) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9533).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepening MetaAgentGNN: GNN Layers 3 -> 4\n",
            "MetaAgentGNN arch changed. New Params: 19171. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9533). !!!\n",
            "\n",
            "===== Iteration 63/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.2382, ValidA=0.9359\n",
            "TargEdit:Typ=2 Stg=0 Src=6->Dest=8\n",
            "  TargetCNN arch changed. New Params: 3,274,442 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2732, TrainA=0.9066\n",
            "  PostE10: TrainL=0.2389, TrainA=0.9172\n",
            "  PostE15: TrainL=0.2051, TrainA=0.9290\n",
            "  PostE20: TrainL=0.1817, TrainA=0.9366\n",
            "  PostE25: TrainL=0.1679, TrainA=0.9420\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.5897 | Penalty: 0.00 | Final Reward: -93.5897\n",
            "MetaL:3863.7393(A:-533.4502,C:8794.3848,E:5.7624) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9533). !!!\n",
            "\n",
            "===== Iteration 64/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.2125, ValidA=0.9403\n",
            "TargEdit:Typ=0 Stg=0 CHM=2.0\n",
            "  TargetCNN arch changed. New Params: 3,985,162 (Ratio: 1.23)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 30 post-edit epochs.\n",
            "  PostE5: TrainL=0.0000, TrainA=0.0000\n",
            "  Warmup complete. Restoring LR to 1.00e-03.\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE30: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.0304 | Penalty: 0.00 | Final Reward: -94.0304\n",
            "MetaL:4083.4128(A:-351.5572,C:8869.9434,E:3.5175) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9533). !!!\n",
            "\n",
            "===== Iteration 65/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1997, ValidA=0.9418\n",
            "TargEdit:Typ=0 Stg=0 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,466,442 (Ratio: 1.07)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.0000, TrainA=0.0000\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE26: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.1807 | Penalty: 0.00 | Final Reward: -94.1807\n",
            "MetaL:4138.5332(A:-306.0222,C:8889.1152,E:3.5175) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9533). !!!\n",
            "\n",
            "===== Iteration 66/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.2126, ValidA=0.9421\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,302,026 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2573, TrainA=0.9119\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2398, TrainA=0.9178\n",
            "  PostE15: TrainL=0.2008, TrainA=0.9315\n",
            "  PostE20: TrainL=0.1730, TrainA=0.9398\n",
            "  PostE25: TrainL=0.1679, TrainA=0.9419\n",
            "PostVal: ValidL=0.1842, ValidA=0.9526\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 1.0517 | Penalty: 0.00 | Final Reward: 1.0517\n",
            "MetaL:1.7521(A:1.2308,C:1.0439,E:1.3746) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 67/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9533\n",
            "PreVal: ValidL=0.1855, ValidA=0.9519\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,368,330 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2502, TrainA=0.9148\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2241, TrainA=0.9231\n",
            "  PostE15: TrainL=0.1944, TrainA=0.9333\n",
            "  PostE20: TrainL=0.1665, TrainA=0.9410\n",
            "  PostE25: TrainL=0.1646, TrainA=0.9440\n",
            "PostVal: ValidL=0.1813, ValidA=0.9543\n",
            "  *** New Best Global Accuracy! 0.9533 -> 0.9543 ***\n",
            "Reward: 0.2404 | Penalty: 0.00 | Final Reward: 0.2404\n",
            "MetaL:0.2497(A:0.2318,C:0.0372,E:1.3724) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 68/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1832, ValidA=0.9536\n",
            "TargEdit:Typ=0 Stg=2 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,958,666 (Ratio: 1.18)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 29 post-edit epochs.\n",
            "  PostE5: TrainL=0.2777, TrainA=0.9043\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2525, TrainA=0.9137\n",
            "  PostE15: TrainL=0.2393, TrainA=0.9200\n",
            "  PostE20: TrainL=0.2059, TrainA=0.9298\n",
            "  PostE25: TrainL=0.1890, TrainA=0.9351\n",
            "  PostE29: TrainL=0.1918, TrainA=0.9349\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -95.3626 | Penalty: 0.00 | Final Reward: -95.3626\n",
            "MetaL:4244.0088(A:-307.4417,C:9102.9053,E:3.5073) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 69/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2169, ValidA=0.9389\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2598, TrainA=0.9097\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2266, TrainA=0.9297\n",
            "  PostE15: TrainL=0.2970, TrainA=0.9040\n",
            "  PostE20: TrainL=0.2190, TrainA=0.9260\n",
            "  PostE25: TrainL=0.2609, TrainA=0.9076\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.8902 | Penalty: 0.00 | Final Reward: -93.8902\n",
            "MetaL:4300.1460(A:-109.2897,C:8818.8721,E:1.3675) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 70/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1995, ValidA=0.9391\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2726, TrainA=0.9075\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2957, TrainA=0.8994\n",
            "  PostE15: TrainL=0.2235, TrainA=0.9223\n",
            "  PostE20: TrainL=0.2261, TrainA=0.9262\n",
            "  PostE25: TrainL=0.1716, TrainA=0.9437\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.9103 | Penalty: 0.00 | Final Reward: -93.9103\n",
            "MetaL:4301.5444(A:-106.7809,C:8816.6514,E:1.3635) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 71/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2186, ValidA=0.9372\n",
            "TargEdit:Typ=0 Stg=1 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,458,530 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2667, TrainA=0.9076\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2418, TrainA=0.9169\n",
            "  PostE15: TrainL=0.2082, TrainA=0.9284\n",
            "  PostE20: TrainL=0.1778, TrainA=0.9388\n",
            "  PostE25: TrainL=0.1726, TrainA=0.9399\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.7200 | Penalty: 0.00 | Final Reward: -93.7200\n",
            "MetaL:4061.2524(A:-325.7693,C:8774.0469,E:3.5036) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 72/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,171\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2300, ValidA=0.9382\n",
            "TargEdit:Typ=0 Stg=0 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,599,050 (Ratio: 1.07)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.0000, TrainA=0.0000\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE26: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.8201 | Penalty: 0.00 | Final Reward: -93.8201\n",
            "MetaL:4064.7637(A:-327.5676,C:8784.6660,E:3.5051) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_conv_ch_mult' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 19183. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 73/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,183\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2285, ValidA=0.9401\n",
            "TargEdit:Typ=2 Stg=2 Src=6->Dest=9\n",
            "  TargetCNN arch changed. New Params: 3,361,114 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2503, TrainA=0.9134\n",
            "  PostE10: TrainL=0.2302, TrainA=0.9202\n",
            "  PostE15: TrainL=0.2040, TrainA=0.9286\n",
            "  PostE20: TrainL=0.1902, TrainA=0.9343\n",
            "  PostE25: TrainL=0.1734, TrainA=0.9388\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -94.0104 | Penalty: 0.00 | Final Reward: -94.0104\n",
            "MetaL:3699.1677(A:-707.0399,C:8812.4229,E:7.1049) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 74/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,183\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2231, ValidA=0.9404\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=0.75\n",
            "  TargetCNN arch changed. New Params: 3,324,550 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2508, TrainA=0.9127\n",
            "  PostE10: TrainL=0.2269, TrainA=0.9227\n",
            "  PostE15: TrainL=0.1976, TrainA=0.9316\n",
            "  PostE20: TrainL=0.1730, TrainA=0.9411\n",
            "  PostE25: TrainL=0.1686, TrainA=0.9425\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.0405 | Penalty: 0.00 | Final Reward: -94.0405\n",
            "MetaL:3958.7219(A:-444.0735,C:8805.5957,E:4.9508) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 75/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,183\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2255, ValidA=0.9368\n",
            "TargEdit:Typ=1 Stg=0 Op=7,RszF=1.75\n",
            "  TargetCNN arch changed. New Params: 3,843,770 (Ratio: 1.14)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 28 post-edit epochs.\n",
            "  PostE5: TrainL=0.3320, TrainA=0.8730\n",
            "  PostE10: TrainL=0.3085, TrainA=0.9062\n",
            "  PostE15: TrainL=0.2112, TrainA=0.9336\n",
            "  PostE20: TrainL=0.2140, TrainA=0.9263\n",
            "  PostE25: TrainL=0.2079, TrainA=0.9323\n",
            "  PostE28: TrainL=0.2524, TrainA=0.9167\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.6799 | Penalty: 0.00 | Final Reward: -93.6799\n",
            "MetaL:3845.2056(A:-517.8443,C:8726.1045,E:4.9381) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 76/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,183\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2035, ValidA=0.9447\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2749, TrainA=0.9036\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2511, TrainA=0.9134\n",
            "  PostE15: TrainL=0.2234, TrainA=0.9219\n",
            "  PostE20: TrainL=0.2289, TrainA=0.9215\n",
            "  PostE25: TrainL=0.2080, TrainA=0.9283\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -94.4712 | Penalty: 0.00 | Final Reward: -94.4712\n",
            "MetaL:4335.3408(A:-95.6846,C:8862.0518,E:1.3384) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 77/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,183\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2159, ValidA=0.9386\n",
            "TargEdit:Typ=1 Stg=0 Op=4,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,627,770 (Ratio: 1.08)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2276, TrainA=0.9261\n",
            "  PostE10: TrainL=0.2823, TrainA=0.8996\n",
            "  PostE15: TrainL=0.2125, TrainA=0.9244\n",
            "  PostE20: TrainL=0.2174, TrainA=0.9224\n",
            "  PostE25: TrainL=0.2227, TrainA=0.9239\n",
            "  PostE26: TrainL=0.2151, TrainA=0.9195\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.8602 | Penalty: 0.00 | Final Reward: -93.8602\n",
            "MetaL:4021.8215(A:-345.7479,C:8735.1436,E:4.9180) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_loc_stage' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 19195. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 78/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,195\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2083, ValidA=0.9381\n",
            "TargEdit:Typ=2 Stg=1 Src=4->Dest=11\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2458, TrainA=0.9164\n",
            "  PostE10: TrainL=0.2219, TrainA=0.9237\n",
            "  PostE15: TrainL=0.1932, TrainA=0.9339\n",
            "  PostE20: TrainL=0.1645, TrainA=0.9444\n",
            "  PostE25: TrainL=0.1592, TrainA=0.9446\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.8101 | Penalty: 0.00 | Final Reward: -93.8101\n",
            "MetaL:3642.3240(A:-714.1368,C:8712.9287,E:7.3420) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 79/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,195\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2308, ValidA=0.9407\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,884,930 (Ratio: 1.15)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 28 post-edit epochs.\n",
            "  PostE5: TrainL=0.2510, TrainA=0.9123\n",
            "  PostE10: TrainL=0.2856, TrainA=0.9040\n",
            "  PostE15: TrainL=0.2589, TrainA=0.9124\n",
            "  PostE20: TrainL=0.2385, TrainA=0.9174\n",
            "  PostE25: TrainL=0.1940, TrainA=0.9304\n",
            "  PostE28: TrainL=0.2028, TrainA=0.9313\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.0705 | Penalty: 0.00 | Final Reward: -94.0705\n",
            "MetaL:3920.3020(A:-453.8695,C:8748.3486,E:5.1857) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 80/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,195\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2278, ValidA=0.9384\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2564, TrainA=0.9144\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2367, TrainA=0.9169\n",
            "  PostE15: TrainL=0.1977, TrainA=0.9296\n",
            "  PostE20: TrainL=0.2145, TrainA=0.9323\n",
            "  PostE25: TrainL=0.1862, TrainA=0.9369\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.8401 | Penalty: 0.00 | Final Reward: -93.8401\n",
            "MetaL:4259.7739(A:-86.3733,C:8692.2959,E:1.3168) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 81/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,195\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2124, ValidA=0.9410\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2491, TrainA=0.9128\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2369, TrainA=0.9119\n",
            "  PostE15: TrainL=0.2281, TrainA=0.9148\n",
            "  PostE20: TrainL=0.1991, TrainA=0.9286\n",
            "  PostE25: TrainL=0.2315, TrainA=0.9271\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -94.1006 | Penalty: 0.00 | Final Reward: -94.1006\n",
            "MetaL:4277.5728(A:-86.2631,C:8727.6729,E:1.3152) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 82/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=72, Params: 19,195\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2127, ValidA=0.9375\n",
            "TargEdit:Typ=2 Stg=0 Src=7->Dest=9\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2395, TrainA=0.9185\n",
            "  PostE10: TrainL=0.2176, TrainA=0.9256\n",
            "  PostE15: TrainL=0.1893, TrainA=0.9350\n",
            "  PostE20: TrainL=0.1653, TrainA=0.9422\n",
            "  PostE25: TrainL=0.1588, TrainA=0.9462\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.7500 | Penalty: 0.00 | Final Reward: -93.7500\n",
            "MetaL:3746.0742(A:-578.0097,C:8648.1738,E:5.7005) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 72 -> 108\n",
            "MetaAgentGNN arch changed. New Params: 39979. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 83/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,979\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2393, ValidA=0.9341\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2672, TrainA=0.9128\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2664, TrainA=0.9120\n",
            "  PostE15: TrainL=0.2108, TrainA=0.9276\n",
            "  PostE20: TrainL=0.1963, TrainA=0.9305\n",
            "  PostE25: TrainL=0.1965, TrainA=0.9304\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.4095 | Penalty: 0.00 | Final Reward: -93.4095\n",
            "MetaL:4308.3906(A:-98.2140,C:8813.2100,E:1.3264) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 84/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,979\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2237, ValidA=0.9407\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2950, TrainA=0.9057\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2409, TrainA=0.9252\n",
            "  PostE15: TrainL=0.2217, TrainA=0.9264\n",
            "  PostE20: TrainL=0.1979, TrainA=0.9321\n",
            "  PostE25: TrainL=0.2151, TrainA=0.9261\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.0705 | Penalty: 0.00 | Final Reward: -94.0705\n",
            "MetaL:4327.0371(A:-117.7235,C:8889.5225,E:1.3455) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 85/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,979\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2282, ValidA=0.9391\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2505, TrainA=0.9151\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2274, TrainA=0.9225\n",
            "  PostE15: TrainL=0.2106, TrainA=0.9269\n",
            "  PostE20: TrainL=0.1818, TrainA=0.9370\n",
            "  PostE25: TrainL=0.1671, TrainA=0.9430\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.9103 | Penalty: 0.00 | Final Reward: -93.9103\n",
            "MetaL:4269.7769(A:-135.7358,C:8811.0264,E:1.3468) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 86/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,979\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2245, ValidA=0.9368\n",
            "TargEdit:Typ=0 Stg=2 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,630,730 (Ratio: 1.08)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.3279, TrainA=0.8915\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2571, TrainA=0.9122\n",
            "  PostE15: TrainL=0.2311, TrainA=0.9220\n",
            "  PostE20: TrainL=0.2053, TrainA=0.9290\n",
            "  PostE25: TrainL=0.1817, TrainA=0.9383\n",
            "  PostE26: TrainL=0.1919, TrainA=0.9342\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.6799 | Penalty: 0.00 | Final Reward: -93.6799\n",
            "MetaL:3946.0132(A:-414.9921,C:8722.0137,E:2.7720) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 87/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,979\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2386, ValidA=0.9356\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=0.75\n",
            "  TargetCNN arch changed. New Params: 3,324,550 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2681, TrainA=0.9075\n",
            "  PostE10: TrainL=0.2423, TrainA=0.9173\n",
            "  PostE15: TrainL=0.2104, TrainA=0.9307\n",
            "  PostE20: TrainL=0.1718, TrainA=0.9400\n",
            "  PostE25: TrainL=0.1701, TrainA=0.9407\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.5597 | Penalty: 0.00 | Final Reward: -93.5597\n",
            "MetaL:3977.8008(A:-350.4311,C:8656.4688,E:4.8464) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_conv_ch_mult' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 39991. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 88/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,991\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=3.0916, ValidA=0.9170\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,455,890 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2490, TrainA=0.9122\n",
            "  PostE10: TrainL=0.2334, TrainA=0.9197\n",
            "  PostE15: TrainL=0.2063, TrainA=0.9297\n",
            "  PostE20: TrainL=0.1803, TrainA=0.9372\n",
            "  PostE25: TrainL=0.1707, TrainA=0.9410\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -91.6967 | Penalty: 0.00 | Final Reward: -91.6967\n",
            "MetaL:3788.7437(A:-339.1017,C:8255.6953,E:4.7574) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 89/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,991\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2110, ValidA=0.9424\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2473, TrainA=0.9129\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2765, TrainA=0.9049\n",
            "  PostE15: TrainL=0.2030, TrainA=0.9294\n",
            "  PostE20: TrainL=0.2209, TrainA=0.9273\n",
            "  PostE25: TrainL=0.2239, TrainA=0.9242\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.2408 | Penalty: 0.00 | Final Reward: -94.2408\n",
            "MetaL:4190.6436(A:-183.2486,C:8747.7852,E:1.3243) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 90/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,991\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2186, ValidA=0.9401\n",
            "TargEdit:Typ=2 Stg=0 Src=5->Dest=9\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2421, TrainA=0.9176\n",
            "  PostE10: TrainL=0.2178, TrainA=0.9256\n",
            "  PostE15: TrainL=0.1891, TrainA=0.9348\n",
            "  PostE20: TrainL=0.1694, TrainA=0.9418\n",
            "  PostE25: TrainL=0.1587, TrainA=0.9440\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.0104 | Penalty: 0.00 | Final Reward: -94.0104\n",
            "MetaL:3928.7820(A:-398.8932,C:8655.3555,E:5.2902) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 91/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,991\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2181, ValidA=0.9390\n",
            "TargEdit:Typ=2 Stg=1 Src=16->Dest=17\n",
            "  TargetCNN arch changed. New Params: 3,368,330 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2385, TrainA=0.9186\n",
            "  PostE10: TrainL=0.2166, TrainA=0.9249\n",
            "  PostE15: TrainL=0.1918, TrainA=0.9347\n",
            "  PostE20: TrainL=0.1675, TrainA=0.9425\n",
            "  PostE25: TrainL=0.1622, TrainA=0.9448\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.9002 | Penalty: 0.00 | Final Reward: -93.9002\n",
            "MetaL:3603.2957(A:-676.5227,C:8559.6436,E:7.0441) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 92/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=4, GNN Hidden=108, Params: 39,991\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2232, ValidA=0.9379\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2585, TrainA=0.9105\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2624, TrainA=0.9115\n",
            "  PostE15: TrainL=0.2190, TrainA=0.9281\n",
            "  PostE20: TrainL=0.1992, TrainA=0.9329\n",
            "  PostE25: TrainL=0.1832, TrainA=0.9367\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.7901 | Penalty: 0.00 | Final Reward: -93.7901\n",
            "MetaL:4076.7058(A:-175.4825,C:8504.3779,E:1.3097) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepening MetaAgentGNN: GNN Layers 4 -> 5\n",
            "MetaAgentGNN arch changed. New Params: 51763. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 93/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=5, GNN Hidden=108, Params: 51,763\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2113, ValidA=0.9408\n",
            "TargEdit:Typ=1 Stg=0 Op=4,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,627,770 (Ratio: 1.08)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2434, TrainA=0.9190\n",
            "  PostE10: TrainL=0.2663, TrainA=0.9062\n",
            "  PostE15: TrainL=0.2381, TrainA=0.9196\n",
            "  PostE20: TrainL=0.2267, TrainA=0.9178\n",
            "  PostE25: TrainL=0.2036, TrainA=0.9317\n",
            "  PostE26: TrainL=0.2139, TrainA=0.9294\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -94.0805 | Penalty: 0.00 | Final Reward: -94.0805\n",
            "MetaL:3776.1794(A:-477.7224,C:8507.8086,E:4.9665) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 94/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=5, GNN Hidden=108, Params: 51,763\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2170, ValidA=0.9360\n",
            "TargEdit:Typ=0 Stg=1 CHM=1.0\n",
            "  TargetCNN arch changed. New Params: 3,458,530 (Ratio: 1.03)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2666, TrainA=0.9095\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2389, TrainA=0.9173\n",
            "  PostE15: TrainL=0.2117, TrainA=0.9264\n",
            "  PostE20: TrainL=0.1778, TrainA=0.9392\n",
            "  PostE25: TrainL=0.1671, TrainA=0.9416\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.5998 | Penalty: 0.00 | Final Reward: -93.5998\n",
            "MetaL:3824.6016(A:-357.2368,C:8363.6797,E:2.8918) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 95/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=5, GNN Hidden=108, Params: 51,763\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2085, ValidA=0.9420\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2641, TrainA=0.9091\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2394, TrainA=0.9198\n",
            "  PostE15: TrainL=0.2276, TrainA=0.9257\n",
            "  PostE20: TrainL=0.2248, TrainA=0.9245\n",
            "  PostE25: TrainL=0.2176, TrainA=0.9241\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.2007 | Penalty: 0.00 | Final Reward: -94.2007\n",
            "MetaL:4004.1912(A:-204.5070,C:8417.3975,E:1.1827) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 96/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=5, GNN Hidden=108, Params: 51,763\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2191, ValidA=0.9372\n",
            "TargEdit:Typ=0 Stg=0 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,339,690 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.3376, TrainA=0.8789\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.3428, TrainA=0.8789\n",
            "  PostE15: TrainL=0.2430, TrainA=0.9141\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.7200 | Penalty: 0.00 | Final Reward: -93.7200\n",
            "MetaL:3898.5754(A:-237.1292,C:8271.4121,E:2.6916) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 97/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=5, GNN Hidden=108, Params: 51,763\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2183, ValidA=0.9367\n",
            "TargEdit:Typ=1 Stg=1 Op=14,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 3,504,530 (Ratio: 1.04)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2467, TrainA=0.9160\n",
            "  PostE10: TrainL=0.2398, TrainA=0.9180\n",
            "  PostE15: TrainL=0.2435, TrainA=0.9163\n",
            "  PostE20: TrainL=0.1976, TrainA=0.9287\n",
            "  PostE25: TrainL=0.1924, TrainA=0.9314\n",
            "  PostE26: TrainL=0.2310, TrainA=0.9186\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.6699 | Penalty: 0.00 | Final Reward: -93.6699\n",
            "MetaL:3497.4937(A:-605.1347,C:8205.2617,E:5.0244) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepening MetaAgentGNN: GNN Layers 5 -> 6\n",
            "MetaAgentGNN arch changed. New Params: 63535. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 98/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,535\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2275, ValidA=0.9367\n",
            "TargEdit:Typ=2 Stg=0 Src=0->Dest=2\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2364, TrainA=0.9191\n",
            "  PostE10: TrainL=0.2188, TrainA=0.9249\n",
            "  PostE15: TrainL=0.1946, TrainA=0.9333\n",
            "  PostE20: TrainL=0.1717, TrainA=0.9411\n",
            "  PostE25: TrainL=0.1582, TrainA=0.9452\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.6699 | Penalty: 0.00 | Final Reward: -93.6699\n",
            "MetaL:3690.8572(A:-383.5687,C:8148.8569,E:5.1683) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 99/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,535\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2260, ValidA=0.9391\n",
            "TargEdit:Typ=2 Stg=0 Src=4->Dest=9\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2394, TrainA=0.9194\n",
            "  PostE10: TrainL=0.2122, TrainA=0.9269\n",
            "  PostE15: TrainL=0.1909, TrainA=0.9340\n",
            "  PostE20: TrainL=0.1721, TrainA=0.9404\n",
            "  PostE25: TrainL=0.1585, TrainA=0.9449\n",
            "PostVal: ValidL=0.1754, ValidA=0.9529\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 1.3822 | Penalty: 0.00 | Final Reward: 1.3822\n",
            "MetaL:38.2495(A:23.9934,C:28.5176,E:5.3338) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 100/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,535\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1785, ValidA=0.9524\n",
            "TargEdit:Typ=2 Stg=2 Src=5->Dest=12\n",
            "  TargetCNN arch changed. New Params: 3,433,178 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2189, TrainA=0.9167\n",
            "  PostE10: TrainL=0.2342, TrainA=0.9245\n",
            "  PostE15: TrainL=0.2742, TrainA=0.9023\n",
            "  PostE20: TrainL=0.3079, TrainA=0.9036\n",
            "  PostE25: TrainL=0.2548, TrainA=0.9141\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -95.2424 | Penalty: 0.00 | Final Reward: -95.2424\n",
            "MetaL:3558.8086(A:-609.1338,C:8335.8916,E:6.7157) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 101/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,535\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2183, ValidA=0.9418\n",
            "TargEdit:Typ=2 Stg=0 Src=8->Dest=9\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2429, TrainA=0.9177\n",
            "  PostE10: TrainL=0.2169, TrainA=0.9255\n",
            "  PostE15: TrainL=0.1870, TrainA=0.9352\n",
            "  PostE20: TrainL=0.1653, TrainA=0.9429\n",
            "  PostE25: TrainL=0.1591, TrainA=0.9455\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -94.1807 | Penalty: 0.00 | Final Reward: -94.1807\n",
            "MetaL:3649.0122(A:-407.3967,C:8112.8232,E:5.3101) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 102/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,535\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2026, ValidA=0.9403\n",
            "TargEdit:Typ=1 Stg=2 Op=10,RszF=1.75\n",
            "  TargetCNN arch changed. New Params: 3,723,530 (Ratio: 1.11)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 27 post-edit epochs.\n",
            "  PostE5: TrainL=0.2384, TrainA=0.9189\n",
            "  PostE10: TrainL=0.2209, TrainA=0.9242\n",
            "  PostE15: TrainL=0.2479, TrainA=0.9128\n",
            "  PostE20: TrainL=0.1974, TrainA=0.9364\n",
            "  PostE25: TrainL=0.3002, TrainA=0.8922\n",
            "  PostE27: TrainL=0.2193, TrainA=0.9336\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.0304 | Penalty: 0.00 | Final Reward: -94.0304\n",
            "MetaL:3477.9182(A:-539.6777,C:8035.1968,E:5.0428) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_loc_stage' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 63547. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 103/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,547\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2398, ValidA=0.9379\n",
            "TargEdit:Typ=0 Stg=0 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,339,690 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4327, TrainA=0.8359\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.3192, TrainA=0.8828\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.7901 | Penalty: 0.00 | Final Reward: -93.7901\n",
            "MetaL:3746.1829(A:-220.3974,C:7933.1631,E:2.6753) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 104/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,547\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2298, ValidA=0.9398\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=14\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2370, TrainA=0.9185\n",
            "  PostE10: TrainL=0.2191, TrainA=0.9254\n",
            "  PostE15: TrainL=0.1881, TrainA=0.9356\n",
            "  PostE20: TrainL=0.1721, TrainA=0.9406\n",
            "  PostE25: TrainL=0.1541, TrainA=0.9469\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.9804 | Penalty: 0.00 | Final Reward: -93.9804\n",
            "MetaL:3404.2493(A:-535.1884,C:7878.8823,E:6.8255) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 105/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,547\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2058, ValidA=0.9400\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2505, TrainA=0.9146\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2343, TrainA=0.9191\n",
            "  PostE15: TrainL=0.2258, TrainA=0.9207\n",
            "  PostE20: TrainL=0.2125, TrainA=0.9324\n",
            "  PostE25: TrainL=0.1999, TrainA=0.9311\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.0004 | Penalty: 0.00 | Final Reward: -94.0004\n",
            "MetaL:3659.5439(A:-226.5210,C:7772.1309,E:0.9207) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 106/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,547\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2502, ValidA=0.9312\n",
            "TargEdit:Typ=2 Stg=0 Src=0->Dest=2\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2351, TrainA=0.9189\n",
            "  PostE10: TrainL=0.2246, TrainA=0.9230\n",
            "  PostE15: TrainL=0.1913, TrainA=0.9341\n",
            "  PostE20: TrainL=0.1679, TrainA=0.9428\n",
            "  PostE25: TrainL=0.1606, TrainA=0.9431\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.1190 | Penalty: 0.00 | Final Reward: -93.1190\n",
            "MetaL:3325.9258(A:-429.2093,C:7510.2749,E:5.0672) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 107/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,547\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2307, ValidA=0.9381\n",
            "TargEdit:Typ=0 Stg=0 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,339,690 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4465, TrainA=0.8438\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE15: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE20: TrainL=0.0000, TrainA=0.0000\n",
            "  PostE25: TrainL=0.3814, TrainA=0.8672\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.8101 | Penalty: 0.00 | Final Reward: -93.8101\n",
            "MetaL:3429.6272(A:-329.4499,C:7518.1567,E:2.4661) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_resize_factor' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 63589. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 108/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,589\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2161, ValidA=0.9404\n",
            "TargEdit:Typ=2 Stg=0 Src=3->Dest=6\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2396, TrainA=0.9189\n",
            "  PostE10: TrainL=0.2204, TrainA=0.9247\n",
            "  PostE15: TrainL=0.1874, TrainA=0.9356\n",
            "  PostE20: TrainL=0.1661, TrainA=0.9424\n",
            "  PostE25: TrainL=0.1572, TrainA=0.9457\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -94.0405 | Penalty: 0.00 | Final Reward: -94.0405\n",
            "MetaL:3313.7632(A:-407.3076,C:7442.1465,E:4.8957) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 109/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,589\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2213, ValidA=0.9423\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=0\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2376, TrainA=0.9177\n",
            "  PostE10: TrainL=0.2237, TrainA=0.9246\n",
            "  PostE15: TrainL=0.1999, TrainA=0.9318\n",
            "  PostE20: TrainL=0.1740, TrainA=0.9425\n",
            "  PostE25: TrainL=0.1588, TrainA=0.9452\n",
            "PostVal: ValidL=0.1872, ValidA=0.9496\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.7312 | Penalty: 0.00 | Final Reward: 0.7312\n",
            "MetaL:93.8081(A:50.9880,C:85.6467,E:6.5175) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 110/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,589\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1918, ValidA=0.9500\n",
            "TargEdit:Typ=2 Stg=1 Src=5->Dest=6\n",
            "  TargetCNN arch changed. New Params: 3,636,330 (Ratio: 1.08)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 26 post-edit epochs.\n",
            "  PostE5: TrainL=0.2594, TrainA=0.9116\n",
            "  PostE10: TrainL=0.2346, TrainA=0.9186\n",
            "  PostE15: TrainL=0.2110, TrainA=0.9292\n",
            "  PostE20: TrainL=0.1827, TrainA=0.9366\n",
            "  PostE25: TrainL=0.1763, TrainA=0.9389\n",
            "  PostE26: TrainL=0.1761, TrainA=0.9394\n",
            "PostVal: ValidL=0.1879, ValidA=0.9502\n",
            "  No improvement for 3 iterations.\n",
            "Reward: 0.0200 | Penalty: 0.00 | Final Reward: 0.0200\n",
            "MetaL:83.1400(A:46.6945,C:72.8975,E:6.5152) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 111/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,589\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1863, ValidA=0.9506\n",
            "TargEdit:Typ=2 Stg=1 Src=7->Dest=12\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2395, TrainA=0.9173\n",
            "  PostE10: TrainL=0.2159, TrainA=0.9254\n",
            "  PostE15: TrainL=0.1983, TrainA=0.9323\n",
            "  PostE20: TrainL=0.1765, TrainA=0.9395\n",
            "  PostE25: TrainL=0.1639, TrainA=0.9441\n",
            "PostVal: ValidL=0.1918, ValidA=0.9503\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -0.0300 | Penalty: 0.00 | Final Reward: -0.0300\n",
            "MetaL:81.3211(A:43.8220,C:75.0045,E:6.2739) | MetaLR: 1.00e-05\n",
            "\n",
            "===== Iteration 112/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,589\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.1944, ValidA=0.9503\n",
            "TargEdit:Typ=2 Stg=1 Src=0->Dest=7\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2280, TrainA=0.9215\n",
            "  PostE10: TrainL=0.2135, TrainA=0.9267\n",
            "  PostE15: TrainL=0.1933, TrainA=0.9325\n",
            "  PostE20: TrainL=0.1624, TrainA=0.9439\n",
            "  PostE25: TrainL=0.1657, TrainA=0.9425\n",
            "PostVal: ValidL=0.1816, ValidA=0.9530\n",
            "  No improvement for 5 iterations.\n",
            "Reward: 0.2704 | Penalty: 0.00 | Final Reward: 0.2704\n",
            "MetaL:90.0949(A:49.8572,C:80.4815,E:6.2533) | MetaLR: 1.00e-05\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened Seq head 'head_target_loc_stage'.\n",
            "MetaAgentGNN arch changed. New Params: 63601. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 113/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,601\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2130, ValidA=0.9392\n",
            "TargEdit:Typ=2 Stg=0 Src=5->Dest=6\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "\n",
            "!!! INSTABILITY DETECTED: 3 consecutive edits failed dummy pass. !!!\n",
            "  Attempting to prune (simplify) Meta-Agent...\n",
            "  Shrinking MetaAgentGNN: GNN Hidden Dim 108 -> 72\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 108 -> 72\n",
            "MetaAgentGNN arch changed. New Params: 29683. Re-init optimizer.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2345, TrainA=0.9179\n",
            "  PostE10: TrainL=0.2159, TrainA=0.9251\n",
            "  PostE15: TrainL=0.1919, TrainA=0.9345\n",
            "  PostE20: TrainL=0.1659, TrainA=0.9420\n",
            "  PostE25: TrainL=0.1569, TrainA=0.9457\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.9203 | Penalty: 0.00 | Final Reward: -93.9203\n",
            "MetaL:3184.1877(A:-462.1833,C:7292.7471,E:4.8382) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 114/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=72, Params: 29,683\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2227, ValidA=0.9390\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=14\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2309, TrainA=0.9224\n",
            "  PostE10: TrainL=0.2190, TrainA=0.9244\n",
            "  PostE15: TrainL=0.1856, TrainA=0.9359\n",
            "  PostE20: TrainL=0.1659, TrainA=0.9432\n",
            "  PostE25: TrainL=0.1607, TrainA=0.9453\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.9002 | Penalty: 0.00 | Final Reward: -93.9002\n",
            "MetaL:3695.8525(A:-695.8762,C:8783.4648,E:7.2088) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 115/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=72, Params: 29,683\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2175, ValidA=0.9351\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2846, TrainA=0.9056\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2468, TrainA=0.9205\n",
            "  PostE15: TrainL=0.2003, TrainA=0.9296\n",
            "  PostE20: TrainL=0.1935, TrainA=0.9328\n",
            "  PostE25: TrainL=0.1857, TrainA=0.9373\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.5096 | Penalty: 0.00 | Final Reward: -93.5096\n",
            "MetaL:4271.0449(A:-70.2420,C:8682.5752,E:1.2527) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 116/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=72, Params: 29,683\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2362, ValidA=0.9364\n",
            "TargEdit:Typ=2 Stg=0 Src=7->Dest=9\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2410, TrainA=0.9165\n",
            "  PostE10: TrainL=0.2173, TrainA=0.9250\n",
            "  PostE15: TrainL=0.1910, TrainA=0.9332\n",
            "  PostE20: TrainL=0.1687, TrainA=0.9420\n",
            "  PostE25: TrainL=0.1584, TrainA=0.9451\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.6398 | Penalty: 0.00 | Final Reward: -93.6398\n",
            "MetaL:3697.2107(A:-642.9186,C:8680.2637,E:5.5870) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 117/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=72, Params: 29,683\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2045, ValidA=0.9406\n",
            "TargEdit:Typ=0 Stg=1 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 3,377,430 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2777, TrainA=0.9045\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2479, TrainA=0.9152\n",
            "  PostE15: TrainL=0.2075, TrainA=0.9286\n",
            "  PostE20: TrainL=0.1851, TrainA=0.9362\n",
            "  PostE25: TrainL=0.1690, TrainA=0.9414\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.0605 | Penalty: 0.00 | Final Reward: -94.0605\n",
            "MetaL:4043.6816(A:-326.3181,C:8740.0029,E:3.3520) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 72 -> 108\n",
            "MetaAgentGNN arch changed. New Params: 63523. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 118/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,523\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2383, ValidA=0.9317\n",
            "TargEdit:Typ=2 Stg=2 Src=0->Dest=6\n",
            "  TargetCNN arch changed. New Params: 3,374,890 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2512, TrainA=0.9147\n",
            "  PostE10: TrainL=0.2273, TrainA=0.9211\n",
            "  PostE15: TrainL=0.2129, TrainA=0.9272\n",
            "  PostE20: TrainL=0.1819, TrainA=0.9382\n",
            "  PostE25: TrainL=0.1747, TrainA=0.9381\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.1691 | Penalty: 0.00 | Final Reward: -93.1691\n",
            "MetaL:3693.9233(A:-618.4598,C:8624.7725,E:6.3581) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 119/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,523\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2264, ValidA=0.9385\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2534, TrainA=0.9161\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2374, TrainA=0.9167\n",
            "  PostE15: TrainL=0.2131, TrainA=0.9272\n",
            "  PostE20: TrainL=0.2020, TrainA=0.9316\n",
            "  PostE25: TrainL=0.1955, TrainA=0.9262\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.8502 | Penalty: 0.00 | Final Reward: -93.8502\n",
            "MetaL:4210.3145(A:-85.7555,C:8592.1406,E:1.1220) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 120/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,523\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2085, ValidA=0.9432\n",
            "TargEdit:Typ=1 Stg=0 Op=0,RszF=0.75\n",
            "  TargetCNN arch changed. New Params: 3,324,550 (Ratio: 0.99)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2653, TrainA=0.9093\n",
            "  PostE10: TrainL=0.2353, TrainA=0.9185\n",
            "  PostE15: TrainL=0.2052, TrainA=0.9291\n",
            "  PostE20: TrainL=0.1817, TrainA=0.9374\n",
            "  PostE25: TrainL=0.1789, TrainA=0.9382\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.3209 | Penalty: 0.00 | Final Reward: -94.3209\n",
            "MetaL:3987.7122(A:-265.7639,C:8506.9551,E:3.0815) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 121/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,523\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2247, ValidA=0.9374\n",
            "TargEdit:Typ=2 Stg=0 Src=-1->Dest=1\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2373, TrainA=0.9176\n",
            "  PostE10: TrainL=0.2212, TrainA=0.9255\n",
            "  PostE15: TrainL=0.1947, TrainA=0.9326\n",
            "  PostE20: TrainL=0.1636, TrainA=0.9451\n",
            "  PostE25: TrainL=0.1584, TrainA=0.9453\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.7400 | Penalty: 0.00 | Final Reward: -93.7400\n",
            "MetaL:3840.4346(A:-271.7934,C:8224.4609,E:4.7459) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 122/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=108, Params: 63,523\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2152, ValidA=0.9403\n",
            "TargEdit:Typ=2 Stg=0 Src=5->Dest=8\n",
            "  TargetCNN arch changed. New Params: 3,407,050 (Ratio: 1.01)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.4044, TrainA=0.8610\n",
            "  PostE10: TrainL=0.3887, TrainA=0.8750\n",
            "  PostE15: TrainL=0.3073, TrainA=0.8848\n",
            "  PostE20: TrainL=0.3488, TrainA=0.8763\n",
            "  PostE25: TrainL=0.3915, TrainA=0.8685\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.0304 | Penalty: 0.00 | Final Reward: -94.0304\n",
            "MetaL:3665.4819(A:-382.4300,C:8095.8286,E:4.9592) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 108 -> 162\n",
            "MetaAgentGNN arch changed. New Params: 138583. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 123/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=162, Params: 138,583\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2110, ValidA=0.9384\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2562, TrainA=0.9129\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2326, TrainA=0.9204\n",
            "  PostE15: TrainL=0.2120, TrainA=0.9274\n",
            "  PostE20: TrainL=0.1877, TrainA=0.9363\n",
            "  PostE25: TrainL=0.1947, TrainA=0.9334\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.8401 | Penalty: 0.00 | Final Reward: -93.8401\n",
            "MetaL:2078.7227(A:0.0000,C:4157.4453,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 124/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=162, Params: 138,583\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2210, ValidA=0.9395\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2538, TrainA=0.9153\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2567, TrainA=0.9079\n",
            "  PostE15: TrainL=0.2243, TrainA=0.9220\n",
            "  PostE20: TrainL=0.1962, TrainA=0.9311\n",
            "  PostE25: TrainL=0.1774, TrainA=0.9382\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.9503 | Penalty: 0.00 | Final Reward: -93.9503\n",
            "MetaL:1395.4479(A:0.0000,C:2790.8958,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 125/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=162, Params: 138,583\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2203, ValidA=0.9406\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2699, TrainA=0.9091\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2464, TrainA=0.9142\n",
            "  PostE15: TrainL=0.2625, TrainA=0.9075\n",
            "  PostE20: TrainL=0.2363, TrainA=0.9176\n",
            "  PostE25: TrainL=0.2061, TrainA=0.9297\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -94.0605 | Penalty: 0.00 | Final Reward: -94.0605\n",
            "MetaL:848.1912(A:0.0000,C:1696.3824,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 126/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=162, Params: 138,583\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2126, ValidA=0.9391\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2641, TrainA=0.9060\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2357, TrainA=0.9185\n",
            "  PostE15: TrainL=0.2326, TrainA=0.9189\n",
            "  PostE20: TrainL=0.2204, TrainA=0.9309\n",
            "  PostE25: TrainL=0.1984, TrainA=0.9338\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.9103 | Penalty: 0.00 | Final Reward: -93.9103\n",
            "MetaL:419.4086(A:0.0000,C:838.8172,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 127/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=162, Params: 138,583\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2436, ValidA=0.9315\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2677, TrainA=0.9087\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2348, TrainA=0.9207\n",
            "  PostE15: TrainL=0.2084, TrainA=0.9290\n",
            "  PostE20: TrainL=0.1889, TrainA=0.9368\n",
            "  PostE25: TrainL=0.1874, TrainA=0.9348\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.1490 | Penalty: 0.00 | Final Reward: -93.1490\n",
            "MetaL:119.9398(A:0.0000,C:239.8795,E:0.0000) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 162 -> 243\n",
            "MetaAgentGNN arch changed. New Params: 305848. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 128/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,848\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2083, ValidA=0.9396\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2530, TrainA=0.9135\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2410, TrainA=0.9174\n",
            "  PostE15: TrainL=0.2324, TrainA=0.9238\n",
            "  PostE20: TrainL=0.2339, TrainA=0.9167\n",
            "  PostE25: TrainL=0.1984, TrainA=0.9313\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.9603 | Penalty: 0.00 | Final Reward: -93.9603\n",
            "MetaL:1428.7145(A:0.0000,C:2857.4290,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 129/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,848\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2313, ValidA=0.9382\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2458, TrainA=0.9179\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2479, TrainA=0.9164\n",
            "  PostE15: TrainL=0.2169, TrainA=0.9228\n",
            "  PostE20: TrainL=0.2093, TrainA=0.9306\n",
            "  PostE25: TrainL=0.2036, TrainA=0.9263\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.8201 | Penalty: 0.00 | Final Reward: -93.8201\n",
            "MetaL:2.0866(A:0.0000,C:4.1733,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 130/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,848\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2294, ValidA=0.9366\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2543, TrainA=0.9181\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2496, TrainA=0.9141\n",
            "  PostE15: TrainL=0.2112, TrainA=0.9235\n",
            "  PostE20: TrainL=0.2111, TrainA=0.9239\n",
            "  PostE25: TrainL=0.1802, TrainA=0.9389\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.6599 | Penalty: 0.00 | Final Reward: -93.6599\n",
            "MetaL:1262.7548(A:0.0000,C:2525.5095,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 131/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,848\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2127, ValidA=0.9407\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2416, TrainA=0.9219\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2826, TrainA=0.9023\n",
            "  PostE15: TrainL=0.2333, TrainA=0.9252\n",
            "  PostE20: TrainL=0.2593, TrainA=0.9089\n",
            "  PostE25: TrainL=0.1869, TrainA=0.9375\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -94.0705 | Penalty: 0.00 | Final Reward: -94.0705\n",
            "MetaL:1833.2318(A:0.0000,C:3666.4636,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 132/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,848\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2026, ValidA=0.9396\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2576, TrainA=0.9126\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2358, TrainA=0.9170\n",
            "  PostE15: TrainL=0.2061, TrainA=0.9278\n",
            "  PostE20: TrainL=0.1756, TrainA=0.9382\n",
            "  PostE25: TrainL=0.1712, TrainA=0.9411\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -93.9603 | Penalty: 0.00 | Final Reward: -93.9603\n",
            "MetaL:1377.3116(A:0.0000,C:2754.6233,E:0.0000) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_conv_ch_mult' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 305860. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 133/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,860\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=3\n",
            "  !!! Dummy pass failed: NaN/Inf detected in output. Edit is invalid. !!!\n",
            "  Edit rolled back due to dummy pass failure.\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2384, TrainA=0.9187\n",
            "  PostE10: TrainL=0.2190, TrainA=0.9248\n",
            "  PostE15: TrainL=0.1870, TrainA=0.9374\n",
            "  PostE20: TrainL=0.1670, TrainA=0.9425\n",
            "  PostE25: TrainL=0.1563, TrainA=0.9470\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:8262.4697(A:0.0000,C:16524.9395,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 134/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,860\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2238, ValidA=0.9367\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2667, TrainA=0.9085\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2333, TrainA=0.9222\n",
            "  PostE15: TrainL=0.2067, TrainA=0.9284\n",
            "  PostE20: TrainL=0.1886, TrainA=0.9367\n",
            "  PostE25: TrainL=0.1792, TrainA=0.9388\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.6699 | Penalty: 0.00 | Final Reward: -93.6699\n",
            "MetaL:74.9046(A:0.0000,C:149.8091,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 135/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,860\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2311, ValidA=0.9324\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2687, TrainA=0.9086\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2377, TrainA=0.9203\n",
            "  PostE15: TrainL=0.2205, TrainA=0.9254\n",
            "  PostE20: TrainL=0.1969, TrainA=0.9325\n",
            "  PostE25: TrainL=0.1812, TrainA=0.9377\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.2392 | Penalty: 0.00 | Final Reward: -93.2392\n",
            "MetaL:47.8763(A:0.0000,C:95.7526,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 136/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,860\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2251, ValidA=0.9385\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2604, TrainA=0.9138\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2546, TrainA=0.9180\n",
            "  PostE15: TrainL=0.2323, TrainA=0.9233\n",
            "  PostE20: TrainL=0.2174, TrainA=0.9256\n",
            "  PostE25: TrainL=0.2298, TrainA=0.9188\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.8502 | Penalty: 0.00 | Final Reward: -93.8502\n",
            "MetaL:24.4424(A:0.0000,C:48.8847,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 137/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,860\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2210, ValidA=0.9405\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2537, TrainA=0.9142\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2338, TrainA=0.9169\n",
            "  PostE15: TrainL=0.2304, TrainA=0.9209\n",
            "  PostE20: TrainL=0.2057, TrainA=0.9323\n",
            "  PostE25: TrainL=0.1954, TrainA=0.9320\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.0505 | Penalty: 0.00 | Final Reward: -94.0505\n",
            "MetaL:18.7155(A:0.0000,C:37.4310,E:0.0000) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_loc_stage' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 305872. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 138/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,872\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2138, ValidA=0.9405\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2529, TrainA=0.9154\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2450, TrainA=0.9138\n",
            "  PostE15: TrainL=0.2188, TrainA=0.9282\n",
            "  PostE20: TrainL=0.2034, TrainA=0.9322\n",
            "  PostE25: TrainL=0.2121, TrainA=0.9309\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -94.0505 | Penalty: 0.00 | Final Reward: -94.0505\n",
            "MetaL:12.3786(A:0.0000,C:24.7571,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 139/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,872\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2154, ValidA=0.9404\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2547, TrainA=0.9114\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2327, TrainA=0.9242\n",
            "  PostE15: TrainL=0.2180, TrainA=0.9234\n",
            "  PostE20: TrainL=0.2025, TrainA=0.9306\n",
            "  PostE25: TrainL=0.1988, TrainA=0.9311\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.0405 | Penalty: 0.00 | Final Reward: -94.0405\n",
            "MetaL:790.3133(A:0.0000,C:1580.6266,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 140/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,872\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2998, ValidA=0.9384\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2496, TrainA=0.9132\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2352, TrainA=0.9197\n",
            "  PostE15: TrainL=0.2145, TrainA=0.9241\n",
            "  PostE20: TrainL=0.1894, TrainA=0.9334\n",
            "  PostE25: TrainL=0.1918, TrainA=0.9361\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.8401 | Penalty: 0.00 | Final Reward: -93.8401\n",
            "MetaL:666.3832(A:0.0000,C:1332.7664,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 141/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,872\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2518, ValidA=0.9349\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2603, TrainA=0.9115\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2321, TrainA=0.9212\n",
            "  PostE15: TrainL=0.2143, TrainA=0.9255\n",
            "  PostE20: TrainL=0.1829, TrainA=0.9377\n",
            "  PostE25: TrainL=0.1838, TrainA=0.9370\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -93.4896 | Penalty: 0.00 | Final Reward: -93.4896\n",
            "MetaL:171.3428(A:0.0000,C:342.6857,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 142/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,872\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2212, ValidA=0.9402\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2558, TrainA=0.9137\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2274, TrainA=0.9190\n",
            "  PostE15: TrainL=0.2342, TrainA=0.9208\n",
            "  PostE20: TrainL=0.2194, TrainA=0.9180\n",
            "  PostE25: TrainL=0.2083, TrainA=0.9250\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.0204 | Penalty: 0.00 | Final Reward: -94.0204\n",
            "MetaL:20.6082(A:0.0000,C:41.2164,E:0.0000) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepened MLP head 'head_target_resize_factor' (Linear -> Sequential)\n",
            "MetaAgentGNN arch changed. New Params: 305914. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 143/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,914\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2196, ValidA=0.9406\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2502, TrainA=0.9133\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2806, TrainA=0.9036\n",
            "  PostE15: TrainL=0.2734, TrainA=0.9036\n",
            "  PostE20: TrainL=0.2321, TrainA=0.9152\n",
            "  PostE25: TrainL=0.2301, TrainA=0.9115\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -94.0605 | Penalty: 0.00 | Final Reward: -94.0605\n",
            "MetaL:103.9858(A:0.0000,C:207.9716,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 144/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,914\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2118, ValidA=0.9413\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2569, TrainA=0.9156\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2688, TrainA=0.9076\n",
            "  PostE15: TrainL=0.2342, TrainA=0.9180\n",
            "  PostE20: TrainL=0.2078, TrainA=0.9276\n",
            "  PostE25: TrainL=0.1968, TrainA=0.9331\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -94.1306 | Penalty: 0.00 | Final Reward: -94.1306\n",
            "MetaL:360.3342(A:0.0000,C:720.6685,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 145/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,914\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2213, ValidA=0.9393\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2810, TrainA=0.9126\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2510, TrainA=0.9126\n",
            "  PostE15: TrainL=0.2487, TrainA=0.9141\n",
            "  PostE20: TrainL=0.2163, TrainA=0.9272\n",
            "  PostE25: TrainL=0.2127, TrainA=0.9256\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.9303 | Penalty: 0.00 | Final Reward: -93.9303\n",
            "MetaL:285.5850(A:0.0000,C:571.1700,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 146/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,914\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2159, ValidA=0.9422\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2625, TrainA=0.9079\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2548, TrainA=0.9124\n",
            "  PostE15: TrainL=0.2114, TrainA=0.9283\n",
            "  PostE20: TrainL=0.1931, TrainA=0.9321\n",
            "  PostE25: TrainL=0.1781, TrainA=0.9383\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: -94.2208 | Penalty: 0.00 | Final Reward: -94.2208\n",
            "MetaL:21.9746(A:0.0000,C:43.9493,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 147/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=243, Params: 305,914\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2131, ValidA=0.9439\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 3,434,634 (Ratio: 1.02)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2606, TrainA=0.9137\n",
            "  Unfreezing 1 new BatchNorm layers.\n",
            "  PostE10: TrainL=0.2328, TrainA=0.9224\n",
            "  PostE15: TrainL=0.1980, TrainA=0.9331\n",
            "  PostE20: TrainL=0.1888, TrainA=0.9346\n",
            "  PostE25: TrainL=0.1860, TrainA=0.9362\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: -94.3910 | Penalty: 0.00 | Final Reward: -94.3910\n",
            "MetaL:129.0409(A:0.0000,C:258.0818,E:0.0000) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.9543).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 243 -> 364\n",
            "MetaAgentGNN arch changed. New Params: 677923. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 148/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=364, Params: 677,923\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2168, ValidA=0.9385\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=0.5\n",
            "  TargetCNN arch changed. New Params: 2,851,730 (Ratio: 0.85)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2618, TrainA=0.9098\n",
            "  PostE10: TrainL=0.2697, TrainA=0.9062\n",
            "  PostE15: TrainL=0.2533, TrainA=0.9116\n",
            "  PostE20: TrainL=0.2347, TrainA=0.9187\n",
            "  PostE25: TrainL=0.2216, TrainA=0.9208\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: -93.8502 | Penalty: 0.00 | Final Reward: -93.8502\n",
            "MetaL:721481.6875(A:0.0000,C:1442963.3750,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 149/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=364, Params: 677,923\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2467, ValidA=0.9311\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=0.5\n",
            "  TargetCNN arch changed. New Params: 2,851,730 (Ratio: 0.85)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2862, TrainA=0.9029\n",
            "  PostE10: TrainL=0.2547, TrainA=0.9137\n",
            "  PostE15: TrainL=0.2169, TrainA=0.9262\n",
            "  PostE20: TrainL=0.1946, TrainA=0.9321\n",
            "  PostE25: TrainL=0.1788, TrainA=0.9381\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: -93.1090 | Penalty: 0.00 | Final Reward: -93.1090\n",
            "MetaL:410724.1875(A:0.0000,C:821448.3750,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "===== Iteration 150/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=6, GNN Hidden=364, Params: 677,923\n",
            "Current Global Best Accuracy: 0.9543\n",
            "PreVal: ValidL=0.2249, ValidA=0.9392\n",
            "TargEdit:Typ=1 Stg=2 Op=6,RszF=0.5\n",
            "  TargetCNN arch changed. New Params: 2,851,730 (Ratio: 0.85)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 25 post-edit epochs.\n",
            "  PostE5: TrainL=0.2728, TrainA=0.9053\n",
            "  PostE10: TrainL=0.2665, TrainA=0.9112\n",
            "  PostE15: TrainL=0.2515, TrainA=0.9165\n",
            "  PostE20: TrainL=0.2179, TrainA=0.9237\n",
            "  PostE25: TrainL=0.2068, TrainA=0.9289\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: -93.9203 | Penalty: 0.00 | Final Reward: -93.9203\n",
            "MetaL:198600.1094(A:0.0000,C:397200.2188,E:0.0000) | MetaLR: 5.00e-04\n",
            "  !!! Accuracy dropped by >4%. Reverting to the global best model (Acc: 0.9543). !!!\n",
            "\n",
            "\n",
            "==================== SAVING STAGE 1 CHECKPOINT ====================\n",
            "Saving best TargetCNN from search with accuracy: 0.9543\n",
            "Successfully saved Stage 1 best TargetCNN object to: /content/drive/My Drive/DEITI_Checkpoints/target_cnn_model_no_self.pth\n",
            "Saving final Meta-Agent state...\n",
            "Successfully saved Meta-Agent object to: /content/drive/My Drive/DEITI_Checkpoints/meta_agent_model_no_self.pth\n",
            "Saved best accuracy (0.9543) to: /content/drive/My Drive/DEITI_Checkpoints/best_accuracy_no_self.txt\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# ==============================================================================\n",
        "#  ENTRY POINT 1: STAGE 1 - BROAD SEARCH AND SAVING (Saves both models)\n",
        "# ==============================================================================\n",
        "#\n",
        "if __name__ == '__main__':\n",
        "    if not PYG_AVAILABLE:\n",
        "        print(\"Exiting: PyTorch Geometric is required for this script.\")\n",
        "        exit()\n",
        "\n",
        "    torch.manual_seed(4)\n",
        "    np.random.seed(4)\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # --- Mount Google Drive for saving checkpoints ---\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        SAVE_DIR = \"/content/drive/My Drive/DEITI_Checkpoints\"\n",
        "    except ImportError:\n",
        "        print(\"Not running in Google Colab. Models will be saved locally to './checkpoints'.\")\n",
        "        SAVE_DIR = \"./checkpoints\"\n",
        "\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "    print(f\"Model checkpoints will be saved to: {SAVE_DIR}\")\n",
        "\n",
        "    deiti_system = DEITI()\n",
        "\n",
        "    # --- STAGE 1: Broad Search ---\n",
        "    print(\"\\n\\n\" + \"=\"*20 + \" STAGE 1: BROAD SEARCH \" + \"=\"*20)\n",
        "    try:\n",
        "        print(f\"Init TargetCNN P: {sum(p.numel() for p in deiti_system.target_cnn.parameters() if p.requires_grad):,}\")\n",
        "        print(f\"Init MetaAgentGNN: L={deiti_system.meta_agent.current_num_gnn_layers},H={deiti_system.meta_agent.current_gnn_hidden_dim},P={sum(p.numel() for p in deiti_system.meta_agent.parameters()):,}\")\n",
        "\n",
        "        print(\"\\n--- Initial Validation ---\")\n",
        "        initial_loss, initial_acc = deiti_system._validate_target(deiti_system.val_loader)\n",
        "        print(f\"InitVal: L={initial_loss:.4f},A={initial_acc:.4f}\")\n",
        "\n",
        "        deiti_system.best_global_accuracy = initial_acc\n",
        "        deiti_system.best_global_model = copy.deepcopy(deiti_system.target_cnn)\n",
        "\n",
        "        deiti_system.train_loop(iterations=150)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nFATAL RUNTIME ERROR in STAGE 1: {e}\")\n",
        "        traceback.print_exc()\n",
        "        print(\"Stopping execution.\")\n",
        "        raise e\n",
        "\n",
        "    # --- Save the Stage 1 checkpoint ---\n",
        "    print(\"\\n\\n\" + \"=\"*20 + \" SAVING STAGE 1 CHECKPOINT \" + \"=\"*20)\n",
        "    target_cnn_path = os.path.join(SAVE_DIR, \"target_cnn_model_no_self.pth\")\n",
        "    meta_agent_path = os.path.join(SAVE_DIR, \"meta_agent_model_no_self.pth\") # New path for meta-agent\n",
        "    acc_path = os.path.join(SAVE_DIR, \"best_accuracy_no_self.txt\")\n",
        "\n",
        "    try:\n",
        "        if deiti_system.best_global_model:\n",
        "            print(f\"Saving best TargetCNN from search with accuracy: {deiti_system.best_global_accuracy:.4f}\")\n",
        "            torch.save(deiti_system.best_global_model, target_cnn_path)\n",
        "            print(f\"Successfully saved Stage 1 best TargetCNN object to: {target_cnn_path}\")\n",
        "\n",
        "            # Save the final meta-agent from the end of the search\n",
        "            print(\"Saving final Meta-Agent state...\")\n",
        "            torch.save(deiti_system.meta_agent, meta_agent_path)\n",
        "            print(f\"Successfully saved Meta-Agent object to: {meta_agent_path}\")\n",
        "\n",
        "            # Save the best validation accuracy from the search loop\n",
        "            with open(acc_path, \"w\") as f:\n",
        "                f.write(str(deiti_system.best_global_accuracy))\n",
        "            print(f\"Saved best accuracy ({deiti_system.best_global_accuracy:.4f}) to: {acc_path}\")\n",
        "        else:\n",
        "            print(\"No best model was tracked during Stage 1. Cannot save checkpoint.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!!! FAILED to save checkpoint: {e} !!!\")\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGf_cqedmfZP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c71dbb86-2649-432e-ff06-5e3d6a3660eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "\n",
            "==================== LOADING PREVIOUS BEST MODELS ====================\n",
            "Successfully loaded TargetCNN from: /content/drive/My Drive/DEITI_Checkpoints/target_cnn_model_no_self.pth\n",
            "Successfully loaded Meta-Agent from: /content/drive/My Drive/DEITI_Checkpoints/meta_agent_model_no_self.pth\n",
            "Loaded previous best accuracy: 0.0000\n",
            "\n",
            "\n",
            "==================== STAGE 2: FOCUSED SEARCH ====================\n",
            "Using 4 workers for data loading (persistent: True).\n",
            "Resetting global best trackers for this search session.\n",
            "Starting Stage 2 with TargetCNN params: 373,834, Acc: 0.0000\n",
            "Continuing with Meta-Agent params: 3,059\n",
            "\n",
            "===== Iteration 1/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=0 Src=0->Dest=1\n",
            "  TargetCNN arch changed. New Params: 373,834 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MetaL:0.4358(A:0.4336,C:0.0088,E:4.2444) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 2/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=1 Stg=2 Op=0,RszF=1.5\n",
            "  TargetCNN arch changed. New Params: 522,826 (Ratio: 1.40)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Large parameter jump. Activating LR warmup.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:0.2183(A:0.2188,C:0.0034,E:4.2400) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 3/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=1 Src=-1->Dest=0\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:0.2504(A:0.2512,C:0.0028,E:4.2392) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 4/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=0 Src=1->Dest=3\n",
            "  TargetCNN arch changed. New Params: 522,826 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.1587(A:-0.1568,C:0.0009,E:4.7508) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 5/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=32, Params: 3,059\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=1 Src=1->Dest=2\n",
            "  TargetCNN arch changed. New Params: 522,826 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.0862(A:-0.0843,C:0.0003,E:4.2437) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.0000).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Widening MetaAgentGNN: GNN Hidden Dim 32 -> 48\n",
            "MetaAgentGNN arch changed. New Params: 4915. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 6/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=0 Stg=1 CHM=0.5\n",
            "  TargetCNN arch changed. New Params: 300,234 (Ratio: 0.80)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.4938(A:-0.5010,C:0.0180,E:3.5486) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 7/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=1 Src=4->Dest=6\n",
            "  TargetCNN arch changed. New Params: 300,234 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.5145(A:-0.5176,C:0.0112,E:4.9437) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 8/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=1 Stg=1 Op=0,RszF=0.25\n",
            "  TargetCNN arch changed. New Params: 189,450 (Ratio: 0.63)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.4767(A:-0.4799,C:0.0112,E:4.9477) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 9/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=0 Src=0->Dest=1\n",
            "  TargetCNN arch changed. New Params: 189,450 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 4 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.3420(A:-0.3440,C:0.0083,E:4.2377) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 10/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=2, GNN Hidden=48, Params: 4,915\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=0 Src=-1->Dest=0\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 5 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.5827(A:-0.5888,C:0.0169,E:4.7498) | MetaLR: 5.00e-04\n",
            "\n",
            "!!! STAGNATION DETECTED: 5 iterations without improvement. !!!\n",
            "  Reverting Target CNN to best known model (Acc: 0.0000).\n",
            "  Attempting to upgrade (grow) Meta-Agent...\n",
            "  Deepening MetaAgentGNN: GNN Layers 2 -> 3\n",
            "MetaAgentGNN arch changed. New Params: 7267. Re-init optimizer.\n",
            "  Stagnation counter reset. Continuing search with upgraded agent.\n",
            "\n",
            "\n",
            "===== Iteration 11/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=48, Params: 7,267\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=2 Src=-1->Dest=0\n",
            "  Edit was invalid or a no-op. Restoring pre-edit model.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 1 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.4408(A:-0.4436,C:0.0100,E:4.2564) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 12/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=48, Params: 7,267\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=3\n",
            "  TargetCNN arch changed. New Params: 440,138 (Ratio: 1.18)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 2 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.0946(A:-0.0962,C:0.0045,E:1.3859) | MetaLR: 5.00e-04\n",
            "\n",
            "===== Iteration 13/150 =====\n",
            "Current MetaAgentGNN: GNN Layers=3, GNN Hidden=48, Params: 7,267\n",
            "Current Global Best Accuracy: 0.0000\n",
            "PreVal: ValidL=0.0000, ValidA=0.0000\n",
            "TargEdit:Typ=2 Stg=1 Src=0->Dest=1\n",
            "  TargetCNN arch changed. New Params: 440,138 (Ratio: 1.00)\n",
            "  Creating fresh optimizer for new architecture.\n",
            "  Training for 1 post-edit epochs.\n",
            "  PostE1: TrainL=0.0000, TrainA=0.0000\n",
            "PostVal: ValidL=0.0000, ValidA=0.0000\n",
            "  No improvement for 3 iterations.\n",
            "Reward: 0.0000 | Penalty: 0.00 | Final Reward: 0.0000\n",
            "MetaL:-0.2893(A:-0.2893,C:0.0043,E:4.2470) | MetaLR: 5.00e-04\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-1940140707.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;31m# Run the training loop for Stage 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdeiti_system_stage2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n\\nFATAL RUNTIME ERROR in STAGE 2: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4-1107290061.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, iterations)\u001b[0m\n\u001b[1;32m   1275\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1277\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#\n",
        "# ==============================================================================\n",
        "#  ENTRY POINT 2: STAGE 2 - LOADING AND FOCUSED, REPEATABLE SEARCH\n",
        "# ==============================================================================\n",
        "#\n",
        "if __name__ == '__main__':\n",
        "    if not PYG_AVAILABLE:\n",
        "        print(\"Exiting: PyTorch Geometric is required for this script.\")\n",
        "        exit()\n",
        "\n",
        "    torch.manual_seed(1337) # Use a different seed for Stage 2 if desired\n",
        "    np.random.seed(1337)\n",
        "    print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "    # --- Mount Google Drive to load checkpoints ---\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        SAVE_DIR = \"/content/drive/My Drive/DEITI_Checkpoints\"\n",
        "    except ImportError:\n",
        "        print(\"Not running in Google Colab. Loading models from local './checkpoints'.\")\n",
        "        SAVE_DIR = \"./checkpoints\"\n",
        "\n",
        "    if not os.path.exists(SAVE_DIR):\n",
        "        print(f\"ERROR: Save directory '{SAVE_DIR}' does not exist. Cannot load model.\")\n",
        "        exit()\n",
        "\n",
        "    # --- Define checkpoint paths ---\n",
        "    target_cnn_path = os.path.join(SAVE_DIR, \"target_cnn_model_no_self.pth\")\n",
        "    meta_agent_path = os.path.join(SAVE_DIR, \"meta_agent_model_no_self.pth\")\n",
        "    acc_path = os.path.join(SAVE_DIR, \"best_accuracy_no_self.txt\")\n",
        "\n",
        "    # --- Load the saved models and accuracy from previous run ---\n",
        "    print(\"\\n\\n\" + \"=\"*20 + \" LOADING PREVIOUS BEST MODELS \" + \"=\"*20)\n",
        "    best_target_cnn_previous = None\n",
        "    loaded_meta_agent = None\n",
        "    previous_best_acc = 0.0\n",
        "\n",
        "    try:\n",
        "        # Load the TargetCNN\n",
        "        best_target_cnn_previous = torch.load(target_cnn_path, map_location=DEVICE, weights_only=False)\n",
        "        best_target_cnn_previous.to(DEVICE)\n",
        "        print(f\"Successfully loaded TargetCNN from: {target_cnn_path}\")\n",
        "\n",
        "        # Load the Meta-Agent\n",
        "        loaded_meta_agent = torch.load(meta_agent_path, map_location=DEVICE, weights_only=False)\n",
        "        loaded_meta_agent.to(DEVICE)\n",
        "        print(f\"Successfully loaded Meta-Agent from: {meta_agent_path}\")\n",
        "\n",
        "        # Load the accuracy\n",
        "        with open(acc_path, \"r\") as f:\n",
        "            previous_best_acc = float(f.read())\n",
        "        print(f\"Loaded previous best accuracy: {previous_best_acc:.4f}\")\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"!!! CHECKPOINT FILE NOT FOUND: {e}. Cannot proceed. !!!\")\n",
        "        exit()\n",
        "    except Exception as e:\n",
        "        print(f\"!!! FAILED to load checkpoint: {e} !!!\")\n",
        "        traceback.print_exc()\n",
        "        exit()\n",
        "\n",
        "    # --- STAGE 2: Focused Search ---\n",
        "    print(\"\\n\\n\" + \"=\"*20 + \" STAGE 2: FOCUSED SEARCH \" + \"=\"*20)\n",
        "\n",
        "    # Initialize a new DEITI system\n",
        "    deiti_system_stage2 = DEITI()\n",
        "\n",
        "    # Replace the default models with the loaded ones\n",
        "    del deiti_system_stage2.target_cnn\n",
        "    del deiti_system_stage2.meta_agent\n",
        "    gc.collect()\n",
        "    deiti_system_stage2.target_cnn = best_target_cnn_previous\n",
        "    deiti_system_stage2.meta_agent = loaded_meta_agent\n",
        "\n",
        "    # Reset optimizer, as it's tied to the new model parameters\n",
        "    deiti_system_stage2.opt_target = None\n",
        "    deiti_system_stage2.opt_meta = optim.Adam(deiti_system_stage2.meta_agent.parameters(), lr=BASE_META_LR) # Re-create optimizer for loaded agent\n",
        "\n",
        "    print(\"Resetting global best trackers for this search session.\")\n",
        "    deiti_system_stage2.best_global_accuracy = previous_best_acc\n",
        "    if deiti_system_stage2.best_global_model is not None:\n",
        "        del deiti_system_stage2.best_global_model\n",
        "    deiti_system_stage2.best_global_model = copy.deepcopy(deiti_system_stage2.target_cnn)\n",
        "\n",
        "    print(f\"Starting Stage 2 with TargetCNN params: {sum(p.numel() for p in deiti_system_stage2.target_cnn.parameters()):,}, Acc: {previous_best_acc:.4f}\")\n",
        "    print(f\"Continuing with Meta-Agent params: {sum(p.numel() for p in deiti_system_stage2.meta_agent.parameters()):,}\")\n",
        "\n",
        "    # Run the training loop for Stage 2\n",
        "    try:\n",
        "        deiti_system_stage2.train_loop(iterations=150)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\\nFATAL RUNTIME ERROR in STAGE 2: {e}\")\n",
        "        traceback.print_exc()\n",
        "        print(\"Stopping execution.\")\n",
        "        raise e\n",
        "\n",
        "    # --- Save the final best model and accuracy from Stage 2 ---\n",
        "    print(\"\\n\\n\" + \"=\"*20 + \" SAVING FINAL CHECKPOINT FOR THIS STAGE \" + \"=\"*20)\n",
        "\n",
        "    try:\n",
        "        if deiti_system_stage2.best_global_model:\n",
        "            print(f\"Saving final best TargetCNN with accuracy: {deiti_system_stage2.best_global_accuracy:.4f}\")\n",
        "            torch.save(deiti_system_stage2.best_global_model, target_cnn_path)\n",
        "            print(f\"Successfully saved final TargetCNN object to: {target_cnn_path}\")\n",
        "\n",
        "            # Save the final meta-agent state from this run\n",
        "            print(\"Saving final Meta-Agent state...\")\n",
        "            torch.save(deiti_system_stage2.meta_agent, meta_agent_path)\n",
        "            print(f\"Successfully saved Meta-Agent object to: {meta_agent_path}\")\n",
        "\n",
        "            # Overwrite the accuracy file with the new best accuracy for the next run\n",
        "            with open(acc_path, \"w\") as f:\n",
        "                f.write(str(deiti_system_stage2.best_global_accuracy))\n",
        "            print(f\"Updated accuracy file for next run: {acc_path}\")\n",
        "        else:\n",
        "            print(\"No better model was found in this run. Checkpoint remains unchanged.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"!!! FAILED to save final checkpoint: {e} !!!\")\n",
        "        traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMTazetnfDkhQwSWM3ZCoqX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}